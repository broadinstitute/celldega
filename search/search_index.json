{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Celldega's Documentation","text":"Celldega Landscape visualization of a human skin cancer Xenium dataset obtained from 10X Genomics.  <p>Celldega is a spatial analysis and visualization library that is being developed by the Spatial Technology Platform at the Broad Institute of MIT and Harvard. This project enables researchers to easily visualize large ST datasets (e.g., datasets with &gt;100M transcripts) alongside single-cell and spatial analysis notebook workflows (e.g., sverse tools and novel spatial analysis approaches).</p> <ul> <li>Getting Started</li> <li>Installation</li> <li>Usage</li> </ul>"},{"location":"#whats-new","title":"What's New","text":"<p>The project was recently presented at the Broad Retreat Data Visualization Breakout Session -</p> <p> </p>"},{"location":"#about","title":"About","text":"<p>Celldega is named after a bodega, a small shop with all the essentials that is part of the fabric of a neighborhood.</p>"},{"location":"examples/","title":"Jupyter Notebook Examples","text":""},{"location":"examples/#brief-notebooks","title":"Brief Notebooks","text":"<p>Landscape View Xenium</p> <p>Mouse-Brain_Alpha-Shape-Neighborhood</p>"},{"location":"examples/brief_notebooks/Celldega-heatmap/","title":"Celldega heatmap","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n%env ANYWIDGET_HMR=1\n</pre> %load_ext autoreload %autoreload 2 %env ANYWIDGET_HMR=1 <pre>env: ANYWIDGET_HMR=1\n</pre> In\u00a0[2]: Copied! <pre># macOS requirement\nimport os\nos.environ['DYLD_LIBRARY_PATH'] = '/opt/homebrew/lib:' + os.environ.get('DYLD_LIBRARY_PATH', '')\n</pre> # macOS requirement import os os.environ['DYLD_LIBRARY_PATH'] = '/opt/homebrew/lib:' + os.environ.get('DYLD_LIBRARY_PATH', '') In\u00a0[3]: Copied! <pre>from ipywidgets import HBox, Layout, GridBox\n</pre> from ipywidgets import HBox, Layout, GridBox In\u00a0[4]: Copied! <pre>import celldega as dega\nfrom ipywidgets import Widget\n</pre> import celldega as dega from ipywidgets import Widget In\u00a0[5]: Copied! <pre>from clustergrammer2 import Network, CGM2\nimport pandas as pd\nimport numpy as np\n</pre> from clustergrammer2 import Network, CGM2 import pandas as pd import numpy as np <pre>&gt;&gt; clustergrammer2 backend version 0.18.0\n</pre> In\u00a0[6]: Copied! <pre># generate random matrix\nnum_rows = 10\nnum_cols = 10\n\nnp.random.seed(seed=100)\nmat = np.random.rand(num_rows, num_cols)\n\n# make row and col labels\nrows = range(num_rows)\ncols = range(num_cols)\nrows = ['row-' + str(i) for i in rows]\ncols = ['col-' + str(i) for i in cols]\n\n# make dataframe\ndf = pd.DataFrame(data=mat, columns=cols, index=rows)\ndf.shape\n\nnet = Network(CGM2)\nnet.load_df(df)\nnet.cluster()\nnetwork = net.viz\n</pre> # generate random matrix num_rows = 10 num_cols = 10  np.random.seed(seed=100) mat = np.random.rand(num_rows, num_cols)  # make row and col labels rows = range(num_rows) cols = range(num_cols) rows = ['row-' + str(i) for i in rows] cols = ['col-' + str(i) for i in cols]  # make dataframe df = pd.DataFrame(data=mat, columns=cols, index=rows) df.shape  net = Network(CGM2) net.load_df(df) net.cluster() network = net.viz In\u00a0[7]: Copied! <pre>base_path = 'data/visium-hd_data/Visium_HD_Mouse_Lung_Fresh_Frozen_binned_outputs/square_008um/landscape_files'\n\ndf_sig = pd.read_parquet(base_path + '/df_sig_marker.parquet')\ndf_sig.shape\n\nnet = Network(CGM2)\nnet.load_df(df_sig)\nnet.filter_N_top(axis='row', N_top=5000)\nnet.normalize(axis='col', norm_type='umi')\nnet.normalize(axis='row', norm_type='zscore')\nnet.cluster()\nnetwork = net.viz\n</pre> base_path = 'data/visium-hd_data/Visium_HD_Mouse_Lung_Fresh_Frozen_binned_outputs/square_008um/landscape_files'  df_sig = pd.read_parquet(base_path + '/df_sig_marker.parquet') df_sig.shape  net = Network(CGM2) net.load_df(df_sig) net.filter_N_top(axis='row', N_top=5000) net.normalize(axis='col', norm_type='umi') net.normalize(axis='row', norm_type='zscore') net.cluster() network = net.viz In\u00a0[10]: Copied! <pre>Widget.close_all()\nmat = dega.viz.MatrixNew(network=network, width=500, height=500)\nmat\n</pre> Widget.close_all() mat = dega.viz.MatrixNew(network=network, width=500, height=500) mat Out[10]: <pre>MatrixNew(height=500, network={'row_nodes': [{'name': 'Scgb1a1', 'ini': 635, 'clust': 149, 'rank': 224, 'rankv\u2026</pre> In\u00a0[12]: Copied! <pre>mat.click_info\n</pre> mat.click_info Out[12]: <pre>{'type': 'row_label', 'value': {'name': 'Actc1'}}</pre> In\u00a0[13]: Copied! <pre># # Example: Setting width to 'auto' or a specific value\n# mat_1.layout = Layout(width='500px')  # Adjust as needed\n# mat_2.layout = Layout(width='500px')  # Adjust as needed\n# widgets_side_by_side = HBox([mat_1, mat_2])\n# display(widgets_side_by_side)\n</pre> # # Example: Setting width to 'auto' or a specific value # mat_1.layout = Layout(width='500px')  # Adjust as needed # mat_2.layout = Layout(width='500px')  # Adjust as needed # widgets_side_by_side = HBox([mat_1, mat_2]) # display(widgets_side_by_side) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/brief_notebooks/Landscape-Matrix_Xenium/","title":"Landscape-Matrix Xenium","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n%env ANYWIDGET_HMR=1\n</pre> %load_ext autoreload %autoreload 2 %env ANYWIDGET_HMR=1 <pre>env: ANYWIDGET_HMR=1\n</pre> In\u00a0[8]: Copied! <pre>import pandas as pd\nimport celldega as dega\n</pre> import pandas as pd import celldega as dega In\u00a0[9]: Copied! <pre>base_url = 'https://raw.githubusercontent.com/broadinstitute/celldega_Xenium_Prime_Human_Skin_FFPE_outs/main/Xenium_Prime_Human_Skin_FFPE_outs'\n</pre> base_url = 'https://raw.githubusercontent.com/broadinstitute/celldega_Xenium_Prime_Human_Skin_FFPE_outs/main/Xenium_Prime_Human_Skin_FFPE_outs' <p>Make Landscape Widget</p> In\u00a0[10]: Copied! <pre>landscape_ist = dega.viz.Landscape(\n    technology='Xenium',\n    ini_zoom = -4.5,\n    ini_x=6000,\n    ini_y=8000,\n    base_url = base_url,\n    height = 700,\n    width= 600\n)\n</pre> landscape_ist = dega.viz.Landscape(     technology='Xenium',     ini_zoom = -4.5,     ini_x=6000,     ini_y=8000,     base_url = base_url,     height = 700,     width= 600 ) <p>Make Matrix widget</p> In\u00a0[11]: Copied! <pre>file_path = 'https://raw.githubusercontent.com/broadinstitute/celldega_Xenium_Prime_Human_Skin_FFPE_outs/main/Xenium_Prime_Human_Skin_FFPE_outs/df_sig.parquet'\ndf = pd.read_parquet(file_path)\nnetwork = dega.clust.hc(df)\nmat = dega.viz.Matrix(network=network, width=500, height=500)\n</pre> file_path = 'https://raw.githubusercontent.com/broadinstitute/celldega_Xenium_Prime_Human_Skin_FFPE_outs/main/Xenium_Prime_Human_Skin_FFPE_outs/df_sig.parquet' df = pd.read_parquet(file_path) network = dega.clust.hc(df) mat = dega.viz.Matrix(network=network, width=500, height=500) In\u00a0[12]: Copied! <pre>dega.viz.landscape_matrix(landscape_ist, mat)\n</pre> dega.viz.landscape_matrix(landscape_ist, mat) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/brief_notebooks/Landscape-Matrix_Xenium/#landscape-matrix-xenium","title":"Landscape-Matrix Xenium\u00b6","text":""},{"location":"examples/brief_notebooks/Landscape-Matrix_Xenium/#ist-landscape-view","title":"iST Landscape View\u00b6","text":""},{"location":"examples/brief_notebooks/Landscape-Matrix_Xenium/#landscape-matrix-view","title":"Landscape-Matrix View\u00b6","text":""},{"location":"examples/brief_notebooks/Landscape_View_Xenium/","title":"Landscape View Xenium","text":"In\u00a0[2]: Copied! <pre># %load_ext autoreload\n# %autoreload 2\n# %env ANYWIDGET_HMR=1\n</pre> # %load_ext autoreload # %autoreload 2 # %env ANYWIDGET_HMR=1 In\u00a0[3]: Copied! <pre>import celldega as dega\ndega.__version__\n</pre> import celldega as dega dega.__version__ Out[3]: <pre>'0.0.0'</pre> In\u00a0[6]: Copied! <pre>from observable_jupyter import embed\n</pre> from observable_jupyter import embed In\u00a0[11]: Copied! <pre>base_url = 'https://raw.githubusercontent.com/broadinstitute/celldega_Xenium_Prime_Mouse_Brain_Coronal_FF_outs/main/Xenium_Prime_Mouse_Brain_Coronal_FF_outs'\n</pre> base_url = 'https://raw.githubusercontent.com/broadinstitute/celldega_Xenium_Prime_Mouse_Brain_Coronal_FF_outs/main/Xenium_Prime_Mouse_Brain_Coronal_FF_outs' In\u00a0[14]: Copied! <pre>embed('@cornhundred/celldega-landscape-ist', inputs={'base_url': base_url}, cells=['landscape_container'], display_logo=False)\n</pre> embed('@cornhundred/celldega-landscape-ist', inputs={'base_url': base_url}, cells=['landscape_container'], display_logo=False) In\u00a0[13]: Copied! <pre># base_url = 'https://raw.githubusercontent.com/broadinstitute/celldega_Xenium_Prime_Human_Skin_FFPE_outs/main/Xenium_Prime_Human_Skin_FFPE_outs'\n\n# landscape_ist = dega.viz.Landscape(\n#     technology='Xenium',\n#     ini_zoom = -4.5,\n#     ini_x=6000,\n#     ini_y=8000,\n#     base_url = base_url,\n\n# )\n\n# landscape_ist\n</pre> # base_url = 'https://raw.githubusercontent.com/broadinstitute/celldega_Xenium_Prime_Human_Skin_FFPE_outs/main/Xenium_Prime_Human_Skin_FFPE_outs'  # landscape_ist = dega.viz.Landscape( #     technology='Xenium', #     ini_zoom = -4.5, #     ini_x=6000, #     ini_y=8000, #     base_url = base_url,  # )  # landscape_ist In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/brief_notebooks/Landscape_View_Xenium/#landscape-view-xenium","title":"Landscape View Xenium\u00b6","text":""},{"location":"examples/brief_notebooks/Mouse-Brain_Alpha-Shape-Neighborhood/","title":"Mouse Brain Alpha Shape Neighborhoods","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n%env ANYWIDGET_HMR=1\n</pre> %load_ext autoreload %autoreload 2 %env ANYWIDGET_HMR=1 <pre>env: ANYWIDGET_HMR=1\n</pre> In\u00a0[2]: Copied! <pre># macOS requirement\nimport os\nos.environ['DYLD_LIBRARY_PATH'] = '/opt/homebrew/lib:' + os.environ.get('DYLD_LIBRARY_PATH', '')\n</pre> # macOS requirement import os os.environ['DYLD_LIBRARY_PATH'] = '/opt/homebrew/lib:' + os.environ.get('DYLD_LIBRARY_PATH', '') In\u00a0[3]: Copied! <pre>from shapely import Point, MultiPoint, MultiPolygon\nimport geopandas as gpd\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nfrom libpysal.cg import alpha_shape\nimport matplotlib.pyplot as plt\nimport json\nfrom ipywidgets import Widget\nimport celldega as dega\n</pre> from shapely import Point, MultiPoint, MultiPolygon import geopandas as gpd import numpy as np import pandas as pd import geopandas as gpd from libpysal.cg import alpha_shape import matplotlib.pyplot as plt import json from ipywidgets import Widget import celldega as dega In\u00a0[4]: Copied! <pre>base_path = 'https://raw.githubusercontent.com/broadinstitute/celldega_Xenium_Prime_Mouse_Brain_Coronal_FF_outs/main/Xenium_Prime_Mouse_Brain_Coronal_FF_outs/'\n</pre> base_path = 'https://raw.githubusercontent.com/broadinstitute/celldega_Xenium_Prime_Mouse_Brain_Coronal_FF_outs/main/Xenium_Prime_Mouse_Brain_Coronal_FF_outs/' In\u00a0[5]: Copied! <pre>meta_cell_ini = pd.read_parquet(base_path + 'cell_metadata.parquet')\ncluster = pd.read_parquet(base_path + 'cell_clusters/cluster.parquet')\nmeta_cluster = pd.read_parquet(base_path + 'cell_clusters/meta_cluster.parquet')\nmeta_cell = pd.concat([meta_cell_ini, cluster], axis=1)\n</pre> meta_cell_ini = pd.read_parquet(base_path + 'cell_metadata.parquet') cluster = pd.read_parquet(base_path + 'cell_clusters/cluster.parquet') meta_cluster = pd.read_parquet(base_path + 'cell_clusters/meta_cluster.parquet') meta_cell = pd.concat([meta_cell_ini, cluster], axis=1) In\u00a0[6]: Copied! <pre>gdf_alpha = dega.nbhd.alpha_shape_cell_clusters(meta_cell, cat='cluster', alphas=[100, 150, 200, 250, 300, 350])\ngeojson_alpha = dega.nbhd.alpha_shape_geojson(gdf_alpha, meta_cluster, inst_alpha=250)\n</pre> gdf_alpha = dega.nbhd.alpha_shape_cell_clusters(meta_cell, cat='cluster', alphas=[100, 150, 200, 250, 300, 350]) geojson_alpha = dega.nbhd.alpha_shape_geojson(gdf_alpha, meta_cluster, inst_alpha=250) In\u00a0[7]: Copied! <pre>Widget.close_all()\nbase_url = base_path.rstrip('/')\nlandscape_ist = dega.viz.Landscape(\n    technology='Xenium',\n    ini_zoom = -4.5,\n    ini_x=6000,\n    ini_y=8000,\n    base_url = base_url,\n    nbhd=geojson_alpha\n)\n\nlandscape_ist\n</pre> Widget.close_all() base_url = base_path.rstrip('/') landscape_ist = dega.viz.Landscape(     technology='Xenium',     ini_zoom = -4.5,     ini_x=6000,     ini_y=8000,     base_url = base_url,     nbhd=geojson_alpha )  landscape_ist Out[7]: In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/brief_notebooks/Mouse-Brain_Alpha-Shape-Neighborhood/#mouse-brain-alpha-shape-neighborhoods","title":"Mouse Brain Alpha Shape Neighborhoods\u00b6","text":""},{"location":"examples/brief_notebooks/Mouse-Brain_Alpha-Shape-Neighborhood/#load-data","title":"Load Data\u00b6","text":""},{"location":"examples/brief_notebooks/Mouse-Brain_Alpha-Shape-Neighborhood/#calculate-alpha-shape-neighborhoods","title":"Calculate Alpha Shape Neighborhoods\u00b6","text":""},{"location":"examples/brief_notebooks/Pre-process_Xenium_V1_human_Pancreas_FFPE_outs/","title":"Pre-process_Xenium_V1_human_Pancreas_FFPE_outs","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n%env ANYWIDGET_HMR=1\n</pre> %load_ext autoreload %autoreload 2 %env ANYWIDGET_HMR=1 <pre>env: ANYWIDGET_HMR=1\n</pre> In\u00a0[2]: Copied! <pre>import numpy as np\nimport pandas as pd\n\n# macOS requirement\nimport os\nos.environ['DYLD_LIBRARY_PATH'] = '/opt/homebrew/lib:' + os.environ.get('DYLD_LIBRARY_PATH', '')\n\nimport celldega as dega\n\nimport tifffile\nimport zarr\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import to_hex\n\nimport geopandas as gpd\nimport shapely\n\nimport tarfile\ndega.__version__\n</pre> import numpy as np import pandas as pd  # macOS requirement import os os.environ['DYLD_LIBRARY_PATH'] = '/opt/homebrew/lib:' + os.environ.get('DYLD_LIBRARY_PATH', '')  import celldega as dega  import tifffile import zarr  import matplotlib.pyplot as plt from matplotlib.colors import to_hex  import geopandas as gpd import shapely  import tarfile dega.__version__ <pre>merged in latest changes\n</pre> Out[2]: <pre>'0.5.4'</pre> In\u00a0[3]: Copied! <pre>ls ../data/xenium_data/Xenium_V1_human_Pancreas_FFPE_outs/\n</pre> ls ../data/xenium_data/Xenium_V1_human_Pancreas_FFPE_outs/ <pre>ls: ../data/xenium_data/Xenium_V1_human_Pancreas_FFPE_outs/: No such file or directory\n</pre> In\u00a0[4]: Copied! <pre>ls ../data/xenium_landscapes/\n</pre> ls ../data/xenium_landscapes/ <pre>Landscape_Xenium_V1_human_Pancreas_FFPE_outs_backup/\nLandscape_Xenium_V1_human_Pancreas_FFPE_outs_png/\nLandscape_Xenium_V1_human_Pancreas_FFPE_outs_webp/\nXenium_Prime_Human_Lymph_Node_Reactive_FFPE_outs/\nXenium_Prime_Human_Lymph_Node_Reactive_FFPE_outs_landscape_files/\nXenium_Prime_Human_Prostate_FFPE_outs/\nXenium_Prime_Human_Skin_FFPE_outs_original/\nXenium_V1_hBoneMarrow_nondiseased_section_outs_landscape_files/\nXenium_V1_hBoneMarrow_nondiseased_section_outs_unscaled/\n</pre> In\u00a0[5]: Copied! <pre>dataset_name = 'Xenium_V1_human_Pancreas_FFPE_outs'\n</pre> dataset_name = 'Xenium_V1_human_Pancreas_FFPE_outs' In\u00a0[6]: Copied! <pre>base_path = 'data/xenium_data/' + dataset_name + '/'\n</pre> base_path = 'data/xenium_data/' + dataset_name + '/' In\u00a0[7]: Copied! <pre>path_landscape_files = 'data/xenium_landscapes/' + dataset_name + '_sparse/'\n</pre> path_landscape_files = 'data/xenium_landscapes/' + dataset_name + '_sparse/' In\u00a0[8]: Copied! <pre>base_path\n</pre> base_path Out[8]: <pre>'data/xenium_data/Xenium_V1_human_Pancreas_FFPE_outs/'</pre> In\u00a0[9]: Copied! <pre>path_landscape_files\n</pre> path_landscape_files Out[9]: <pre>'data/xenium_landscapes/Xenium_V1_human_Pancreas_FFPE_outs_sparse/'</pre> In\u00a0[10]: Copied! <pre>if not os.path.exists(path_landscape_files):\n    os.mkdir(path_landscape_files)\n</pre> if not os.path.exists(path_landscape_files):     os.mkdir(path_landscape_files) In\u00a0[11]: Copied! <pre># # Path to the tar.gz file you want to decompress\n# tar_file_path = base_path + 'cell_feature_matrix.tar.gz'\n# # Path to the directory where you want to extract the contents\n# output_directory = path_landscape_files\n\n# # Open the tar.gz file\n# with tarfile.open(tar_file_path, \"r:gz\") as tar:\n#     # Extract all contents to the specified directory\n#     tar.extractall(path=output_directory)\n\n# print(f\"File {tar_file_path} has been decompressed to {output_directory}\")\n</pre> # # Path to the tar.gz file you want to decompress # tar_file_path = base_path + 'cell_feature_matrix.tar.gz' # # Path to the directory where you want to extract the contents # output_directory = path_landscape_files  # # Open the tar.gz file # with tarfile.open(tar_file_path, \"r:gz\") as tar: #     # Extract all contents to the specified directory #     tar.extractall(path=output_directory)  # print(f\"File {tar_file_path} has been decompressed to {output_directory}\")  In\u00a0[12]: Copied! <pre># # Path to the tar.gz file you want to decompress\n# tar_file_path = base_path + 'analysis.tar.gz'\n# # Path to the directory where you want to extract the contents\n# output_directory = path_landscape_files\n\n# # Open the tar.gz file\n# with tarfile.open(tar_file_path, \"r:gz\") as tar:\n#     # Extract all contents to the specified directory\n#     tar.extractall(path=output_directory)\n\n# print(f\"File {tar_file_path} has been decompressed to {output_directory}\")\n</pre> # # Path to the tar.gz file you want to decompress # tar_file_path = base_path + 'analysis.tar.gz' # # Path to the directory where you want to extract the contents # output_directory = path_landscape_files  # # Open the tar.gz file # with tarfile.open(tar_file_path, \"r:gz\") as tar: #     # Extract all contents to the specified directory #     tar.extractall(path=output_directory)  # print(f\"File {tar_file_path} has been decompressed to {output_directory}\")  In\u00a0[13]: Copied! <pre>cbg = dega.pre.read_cbg_mtx(base_path + 'cell_feature_matrix/')\ncbg\n</pre> cbg = dega.pre.read_cbg_mtx(base_path + 'cell_feature_matrix/') cbg <pre>Reading mtx file from  data/xenium_data/Xenium_V1_human_Pancreas_FFPE_outs/cell_feature_matrix/\n</pre> Out[13]: __index_level_0__ ABCC11 ACE2 ACKR1 ACTA2 ACTG2 ADAM28 ADAMTS1 ADGRE1 ADGRL4 ADH1C ... UnassignedCodeword_0490 UnassignedCodeword_0491 UnassignedCodeword_0492 UnassignedCodeword_0493 UnassignedCodeword_0494 UnassignedCodeword_0495 UnassignedCodeword_0496 UnassignedCodeword_0497 UnassignedCodeword_0498 UnassignedCodeword_0499 0 aaaadnje-1 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 aaacalai-1 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 aaacjgil-1 0 0 0 0 1 1 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 aaacpcil-1 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 aaadhocp-1 0 0 0 1 2 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... oiloppgp-1 0 0 0 0 1 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 oilpccne-1 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 oimacfoj-1 0 0 0 0 0 0 1 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 oimaiaae-1 0 0 1 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 oimajkkk-1 0 0 0 0 0 0 1 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 <p>140702 rows \u00d7 541 columns</p> In\u00a0[14]: Copied! <pre>meta_gene_exp = dega.pre.calc_meta_gene_data(cbg)\n</pre> meta_gene_exp = dega.pre.calc_meta_gene_data(cbg) <pre>calculating mean expression from sparse float data\ncalculating variance by looping over rows\n</pre> In\u00a0[15]: Copied! <pre>path_cbg = base_path + 'cell_feature_matrix/'\npath_output = path_landscape_files + 'meta_gene.parquet'\ndega.pre.make_meta_gene('Xenium', path_cbg, path_output)\n</pre> path_cbg = base_path + 'cell_feature_matrix/' path_output = path_landscape_files + 'meta_gene.parquet' dega.pre.make_meta_gene('Xenium', path_cbg, path_output) <pre>Reading mtx file from  data/xenium_data/Xenium_V1_human_Pancreas_FFPE_outs/cell_feature_matrix/\ncalculating mean expression from sparse float data\ncalculating variance by looping over rows\n</pre> In\u00a0[16]: Copied! <pre>dega.pre.save_cbg_gene_parquets(path_landscape_files, cbg, verbose=True)\n</pre> dega.pre.save_cbg_gene_parquets(path_landscape_files, cbg, verbose=True) <pre>Processing gene 0: ABCC11\nProcessing gene 100: CLECL1\nProcessing gene 200: IL1RL1\nProcessing gene 300: RGS16\nProcessing gene 400: NegControlCodeword_0503\nProcessing gene 500: UnassignedCodeword_0459\n</pre> In\u00a0[17]: Copied! <pre>import tifffile\n\n# Path to your OME-TIFF file\nfile_path = base_path + 'morphology_focus/morphology_focus_0000.ome.tif'\n\n# Open the OME-TIFF file and read the image data\nwith tifffile.TiffFile(file_path) as tif:\n    series = tif.series[0]  # Assuming you are interested in the first series\n    image_data = series.asarray()\n</pre> import tifffile  # Path to your OME-TIFF file file_path = base_path + 'morphology_focus/morphology_focus_0000.ome.tif'  # Open the OME-TIFF file and read the image data with tifffile.TiffFile(file_path) as tif:     series = tif.series[0]  # Assuming you are interested in the first series     image_data = series.asarray()  <pre>&lt;tifffile.TiffFile 'morphology_focus_0000.ome.tif'&gt; OME series cannot read multi-file pyramids\n</pre> In\u00a0[18]: Copied! <pre>image_data.shape\n</pre> image_data.shape Out[18]: <pre>(4, 13770, 34155)</pre> In\u00a0[19]: Copied! <pre># from skimage.io import imread\n</pre> # from skimage.io import imread In\u00a0[20]: Copied! <pre># image_scale = 1\n# # file_path = f\"{data_dir}/morphology_focus_0000.ome.tif\"\n# file_path = base_path + 'morphology_focus/morphology_focus_0000.ome.tif'\n\n# img = imread(file_path)[...,0]\n\n# img_8bit = dega.pre.check_and_convert_16_to_8_bit(img)\n</pre> # image_scale = 1 # # file_path = f\"{data_dir}/morphology_focus_0000.ome.tif\" # file_path = base_path + 'morphology_focus/morphology_focus_0000.ome.tif'  # img = imread(file_path)[...,0]  # img_8bit = dega.pre.check_and_convert_16_to_8_bit(img) <p>how can this be adapted to additional channels?</p> In\u00a0[21]: Copied! <pre># img = imread(file_path)[...,0]\n# img_8bit = dega.pre.check_and_convert_16_to_8_bit(img)\n# dega.pre.make_deepzoom_pyramid(\n#     img_8bit, \n#     f\"{path_landscape_files}/pyramid_images\", \n#     'dapi', \n#     clahe_tile_size=32, \n#     clahe_contrast_limit=60, \n#     suffix=\".webp[Q=100]\"\n# )\n</pre> # img = imread(file_path)[...,0] # img_8bit = dega.pre.check_and_convert_16_to_8_bit(img) # dega.pre.make_deepzoom_pyramid( #     img_8bit,  #     f\"{path_landscape_files}/pyramid_images\",  #     'dapi',  #     clahe_tile_size=32,  #     clahe_contrast_limit=60,  #     suffix=\".webp[Q=100]\" # ) In\u00a0[22]: Copied! <pre># img = imread(file_path)[...,1]\n# img_8bit = dega.pre.check_and_convert_16_to_8_bit(img)\n# dega.pre.make_deepzoom_pyramid(\n#     img_8bit, \n#     f\"{path_landscape_files}/pyramid_images\", \n#     'bound', \n#     clahe_tile_size=32, \n#     clahe_contrast_limit=60, \n#     suffix=\".webp[Q=100]\"\n# )\n</pre> # img = imread(file_path)[...,1] # img_8bit = dega.pre.check_and_convert_16_to_8_bit(img) # dega.pre.make_deepzoom_pyramid( #     img_8bit,  #     f\"{path_landscape_files}/pyramid_images\",  #     'bound',  #     clahe_tile_size=32,  #     clahe_contrast_limit=60,  #     suffix=\".webp[Q=100]\" # ) In\u00a0[23]: Copied! <pre># img = imread(file_path)[...,2]\n# img_8bit = dega.pre.check_and_convert_16_to_8_bit(img)\n# dega.pre.make_deepzoom_pyramid(\n#     img_8bit, \n#     f\"{path_landscape_files}/pyramid_images\", \n#     'rna', \n#     clahe_tile_size=32, \n#     clahe_contrast_limit=60, \n#     suffix=\".webp[Q=100]\"\n# )\n</pre> # img = imread(file_path)[...,2] # img_8bit = dega.pre.check_and_convert_16_to_8_bit(img) # dega.pre.make_deepzoom_pyramid( #     img_8bit,  #     f\"{path_landscape_files}/pyramid_images\",  #     'rna',  #     clahe_tile_size=32,  #     clahe_contrast_limit=60,  #     suffix=\".webp[Q=100]\" # ) In\u00a0[24]: Copied! <pre># img = imread(file_path)[...,3]\n# img_8bit = dega.pre.check_and_convert_16_to_8_bit(img)\n# dega.pre.make_deepzoom_pyramid(\n#     img_8bit, \n#     f\"{path_landscape_files}/pyramid_images\", \n#     'prot', \n#     clahe_tile_size=32, \n#     clahe_contrast_limit=60, \n#     suffix=\".webp[Q=100]\"\n# )\n</pre> # img = imread(file_path)[...,3] # img_8bit = dega.pre.check_and_convert_16_to_8_bit(img) # dega.pre.make_deepzoom_pyramid( #     img_8bit,  #     f\"{path_landscape_files}/pyramid_images\",  #     'prot',  #     clahe_tile_size=32,  #     clahe_contrast_limit=60,  #     suffix=\".webp[Q=100]\" # ) In\u00a0[25]: Copied! <pre>image_scale = 1.0\n</pre> image_scale = 1.0 In\u00a0[26]: Copied! <pre>suffix = '.webp[Q=100]'\n</pre> suffix = '.webp[Q=100]' In\u00a0[27]: Copied! <pre>image_data_scaled = image_data[0,:,:] * 2\n\n# Save the image data to a regular TIFF file without compression\ntifffile.imwrite(path_landscape_files + 'output_regular.tif', image_data_scaled, compression=None)\nimage_ds = dega.pre.reduce_image_size(path_landscape_files + 'output_regular.tif', image_scale, path_landscape_files)\nimage_png = dega.pre.convert_to_png(image_ds)\ndega.pre.make_deepzoom_pyramid(image_png, path_landscape_files + 'pyramid_images/', 'dapi', suffix=suffix)\n</pre> image_data_scaled = image_data[0,:,:] * 2  # Save the image data to a regular TIFF file without compression tifffile.imwrite(path_landscape_files + 'output_regular.tif', image_data_scaled, compression=None) image_ds = dega.pre.reduce_image_size(path_landscape_files + 'output_regular.tif', image_scale, path_landscape_files) image_png = dega.pre.convert_to_png(image_ds) dega.pre.make_deepzoom_pyramid(image_png, path_landscape_files + 'pyramid_images/', 'dapi', suffix=suffix) In\u00a0[28]: Copied! <pre>image_data_scaled = image_data[1,:,:] * 2\n\n# Save the image data to a regular TIFF file without compression\ntifffile.imwrite(path_landscape_files + 'output_regular.tif', image_data_scaled, compression=None)\nimage_ds = dega.pre.reduce_image_size(path_landscape_files + 'output_regular.tif', image_scale, path_landscape_files)\nimage_png = dega.pre.convert_to_png(image_ds)\ndega.pre.make_deepzoom_pyramid(image_png, path_landscape_files + 'pyramid_images/', 'bound', suffix=suffix)\n</pre> image_data_scaled = image_data[1,:,:] * 2  # Save the image data to a regular TIFF file without compression tifffile.imwrite(path_landscape_files + 'output_regular.tif', image_data_scaled, compression=None) image_ds = dega.pre.reduce_image_size(path_landscape_files + 'output_regular.tif', image_scale, path_landscape_files) image_png = dega.pre.convert_to_png(image_ds) dega.pre.make_deepzoom_pyramid(image_png, path_landscape_files + 'pyramid_images/', 'bound', suffix=suffix) In\u00a0[29]: Copied! <pre>image_data_scaled = image_data[2,:,:] * 2\n\n# Save the image data to a regular TIFF file without compression\ntifffile.imwrite(path_landscape_files + 'output_regular.tif', image_data_scaled, compression=None)\nimage_ds = dega.pre.reduce_image_size(path_landscape_files + 'output_regular.tif', image_scale, path_landscape_files)\nimage_png = dega.pre.convert_to_png(image_ds)\ndega.pre.make_deepzoom_pyramid(image_png, path_landscape_files + 'pyramid_images/', 'rna', suffix=suffix)\n</pre> image_data_scaled = image_data[2,:,:] * 2  # Save the image data to a regular TIFF file without compression tifffile.imwrite(path_landscape_files + 'output_regular.tif', image_data_scaled, compression=None) image_ds = dega.pre.reduce_image_size(path_landscape_files + 'output_regular.tif', image_scale, path_landscape_files) image_png = dega.pre.convert_to_png(image_ds) dega.pre.make_deepzoom_pyramid(image_png, path_landscape_files + 'pyramid_images/', 'rna', suffix=suffix) In\u00a0[30]: Copied! <pre>image_data_scaled = image_data[3,:,:] * 2\n\n# Save the image data to a regular TIFF file without compression\ntifffile.imwrite(path_landscape_files + 'output_regular.tif', image_data_scaled, compression=None)\nimage_ds = dega.pre.reduce_image_size(path_landscape_files + 'output_regular.tif', image_scale, path_landscape_files)\nimage_png = dega.pre.convert_to_png(image_ds)\ndega.pre.make_deepzoom_pyramid(image_png, path_landscape_files + 'pyramid_images/', 'prot', suffix=suffix)\n</pre> image_data_scaled = image_data[3,:,:] * 2  # Save the image data to a regular TIFF file without compression tifffile.imwrite(path_landscape_files + 'output_regular.tif', image_data_scaled, compression=None) image_ds = dega.pre.reduce_image_size(path_landscape_files + 'output_regular.tif', image_scale, path_landscape_files) image_png = dega.pre.convert_to_png(image_ds) dega.pre.make_deepzoom_pyramid(image_png, path_landscape_files + 'pyramid_images/', 'prot', suffix=suffix) In\u00a0[31]: Copied! <pre># Function to open a Zarr file\ndef open_zarr(path: str) -&gt; zarr.Group:\n    store = (zarr.ZipStore(path, mode=\"r\")\n    if path.endswith(\".zip\")\n    else zarr.DirectoryStore(path)\n    )\n    return zarr.group(store=store)\n\n# For example, use the above function to open the cells Zarr file, which contains segmentation mask Zarr arrays\nroot = open_zarr(base_path + \"cells.zarr.zip\")\n\n# # Look at group array info and structure\n# root.info\n# root.tree() # shows structure, array dimensions, data types\n</pre> # Function to open a Zarr file def open_zarr(path: str) -&gt; zarr.Group:     store = (zarr.ZipStore(path, mode=\"r\")     if path.endswith(\".zip\")     else zarr.DirectoryStore(path)     )     return zarr.group(store=store)  # For example, use the above function to open the cells Zarr file, which contains segmentation mask Zarr arrays root = open_zarr(base_path + \"cells.zarr.zip\")  # # Look at group array info and structure # root.info # root.tree() # shows structure, array dimensions, data types  In\u00a0[32]: Copied! <pre>transformation_matrix = root['masks']['homogeneous_transform'][:]\ntransformation_matrix\n</pre> transformation_matrix = root['masks']['homogeneous_transform'][:] transformation_matrix Out[32]: <pre>array([[4.705882, 0.      , 0.      , 0.      ],\n       [0.      , 4.705882, 0.      , 0.      ],\n       [0.      , 0.      , 1.      , 0.      ],\n       [0.      , 0.      , 0.      , 1.      ]], dtype=float32)</pre> In\u00a0[33]: Copied! <pre>pd.DataFrame(transformation_matrix[:3,:3]).to_csv(\n    path_landscape_files + 'xenium_transform.csv', \n    sep=' ', \n    header=False, \n    index=False\n)\n</pre> pd.DataFrame(transformation_matrix[:3,:3]).to_csv(     path_landscape_files + 'xenium_transform.csv',      sep=' ',      header=False,      index=False ) In\u00a0[34]: Copied! <pre>path_transformation_matrix = path_landscape_files + 'xenium_transform.csv'\npath_meta_cell_micron = base_path + 'cells.csv.gz'\npath_meta_cell_image = path_landscape_files + 'cell_metadata.parquet'\n</pre> path_transformation_matrix = path_landscape_files + 'xenium_transform.csv' path_meta_cell_micron = base_path + 'cells.csv.gz' path_meta_cell_image = path_landscape_files + 'cell_metadata.parquet' In\u00a0[35]: Copied! <pre>default_clustering = pd.read_csv(base_path + 'analysis/clustering/gene_expression_graphclust/clusters.csv', index_col=0)\ndefault_clustering\n</pre> default_clustering = pd.read_csv(base_path + 'analysis/clustering/gene_expression_graphclust/clusters.csv', index_col=0) default_clustering Out[35]: Cluster Barcode aaaadnje-1 15 aaacalai-1 9 aaacjgil-1 15 aaacpcil-1 13 aaadhocp-1 18 ... ... oiloppgp-1 10 oilpccne-1 6 oimacfoj-1 10 oimaiaae-1 11 oimajkkk-1 23 <p>140194 rows \u00d7 1 columns</p> In\u00a0[36]: Copied! <pre># do not including clustering information in default cell metadata\ndega.pre.make_meta_cell_image_coord(\n    'Xenium', \n    path_transformation_matrix, \n    path_meta_cell_micron, \n    path_meta_cell_image, \n    image_scale=image_scale\n)\n</pre> # do not including clustering information in default cell metadata dega.pre.make_meta_cell_image_coord(     'Xenium',      path_transformation_matrix,      path_meta_cell_micron,      path_meta_cell_image,      image_scale=image_scale ) In\u00a0[37]: Copied! <pre>if not os.path.exists(path_landscape_files + 'cell_clusters/'):\n    os.mkdir(path_landscape_files + 'cell_clusters/')\n</pre> if not os.path.exists(path_landscape_files + 'cell_clusters/'):     os.mkdir(path_landscape_files + 'cell_clusters/') In\u00a0[38]: Copied! <pre>default_clustering = pd.DataFrame(default_clustering.values, index=default_clustering.index.tolist(), columns=['cluster'])\ndefault_clustering.head()\n</pre> default_clustering = pd.DataFrame(default_clustering.values, index=default_clustering.index.tolist(), columns=['cluster']) default_clustering.head() Out[38]: cluster aaaadnje-1 15 aaacalai-1 9 aaacjgil-1 15 aaacpcil-1 13 aaadhocp-1 18 In\u00a0[39]: Copied! <pre>default_clustering_ini = pd.DataFrame(default_clustering.values, index=default_clustering.index.tolist(), columns=['cluster'])\ndefault_clustering_ini.head()\n</pre> default_clustering_ini = pd.DataFrame(default_clustering.values, index=default_clustering.index.tolist(), columns=['cluster']) default_clustering_ini.head() Out[39]: cluster aaaadnje-1 15 aaacalai-1 9 aaacjgil-1 15 aaacpcil-1 13 aaadhocp-1 18 In\u00a0[40]: Copied! <pre>meta_cell = pd.read_parquet(path_landscape_files + 'cell_metadata.parquet')\nmeta_cell.shape\n</pre> meta_cell = pd.read_parquet(path_landscape_files + 'cell_metadata.parquet') meta_cell.shape Out[40]: <pre>(140702, 2)</pre> In\u00a0[41]: Copied! <pre>default_clustering_ini['cluster'] = default_clustering_ini['cluster'].astype('string')\n</pre> default_clustering_ini['cluster'] = default_clustering_ini['cluster'].astype('string') In\u00a0[42]: Copied! <pre>default_clustering = pd.DataFrame(index=meta_cell.index.tolist())\n\ndefault_clustering.loc[default_clustering_ini.index.tolist(), 'cluster'] = default_clustering_ini['cluster']\n</pre> default_clustering = pd.DataFrame(index=meta_cell.index.tolist())  default_clustering.loc[default_clustering_ini.index.tolist(), 'cluster'] = default_clustering_ini['cluster'] In\u00a0[43]: Copied! <pre>default_clustering.to_parquet(path_landscape_files + 'cell_clusters/cluster.parquet')\n</pre> default_clustering.to_parquet(path_landscape_files + 'cell_clusters/cluster.parquet') In\u00a0[44]: Copied! <pre>df_meta = pd.read_csv(base_path + 'analysis/clustering/gene_expression_graphclust/clusters.csv', index_col=0)\ndf_meta['Cluster'] = df_meta['Cluster'].astype('string')\ndf_meta.columns = ['cluster']\n</pre> df_meta = pd.read_csv(base_path + 'analysis/clustering/gene_expression_graphclust/clusters.csv', index_col=0) df_meta['Cluster'] = df_meta['Cluster'].astype('string') df_meta.columns = ['cluster'] In\u00a0[45]: Copied! <pre># dega.pre.make_meta_cell_image_coord(\n#     'Xenium', \n#     path_transformation_matrix, \n#     path_meta_cell_micron, \n#     path_meta_cell_image, \n#     df_meta=df_meta\n# )\n</pre> # dega.pre.make_meta_cell_image_coord( #     'Xenium',  #     path_transformation_matrix,  #     path_meta_cell_micron,  #     path_meta_cell_image,  #     df_meta=df_meta # ) In\u00a0[46]: Copied! <pre>ser_counts = default_clustering['cluster'].value_counts()\nclusters = ser_counts.index.tolist()\n</pre> ser_counts = default_clustering['cluster'].value_counts() clusters = ser_counts.index.tolist() In\u00a0[47]: Copied! <pre># Get all categorical color palettes from Matplotlib and flatten them into a single list of colors\npalettes = [plt.get_cmap(name).colors for name in plt.colormaps() if \"tab\" in name]\nflat_colors = [color for palette in palettes for color in palette]\n\n# Convert RGB tuples to hex codes\nflat_colors_hex = [to_hex(color) for color in flat_colors]\n\n# Use modular arithmetic to assign a color to each gene, white for genes with \"Blank\"\ncolors = [\n    flat_colors_hex[i % len(flat_colors_hex)] if \"Blank\" not in cluster else \"#FFFFFF\"\n    for i, cluster in enumerate(clusters)\n]\n\n# Create a DataFrame with genes and their assigned colors\nser_color = pd.Series(colors, index=clusters, name='color')\n\nmeta_cluster = pd.DataFrame(ser_color)\n\nmeta_cluster['count'] = ser_counts\n\nmeta_cluster.to_parquet(path_landscape_files + 'cell_clusters/meta_cluster.parquet')\n</pre> # Get all categorical color palettes from Matplotlib and flatten them into a single list of colors palettes = [plt.get_cmap(name).colors for name in plt.colormaps() if \"tab\" in name] flat_colors = [color for palette in palettes for color in palette]  # Convert RGB tuples to hex codes flat_colors_hex = [to_hex(color) for color in flat_colors]  # Use modular arithmetic to assign a color to each gene, white for genes with \"Blank\" colors = [     flat_colors_hex[i % len(flat_colors_hex)] if \"Blank\" not in cluster else \"#FFFFFF\"     for i, cluster in enumerate(clusters) ]  # Create a DataFrame with genes and their assigned colors ser_color = pd.Series(colors, index=clusters, name='color')  meta_cluster = pd.DataFrame(ser_color)  meta_cluster['count'] = ser_counts  meta_cluster.to_parquet(path_landscape_files + 'cell_clusters/meta_cluster.parquet') In\u00a0[48]: Copied! <pre>tile_size = 200\n</pre> tile_size = 200 In\u00a0[49]: Copied! <pre>%%time \ntechnology = 'Xenium'\npath_trx = base_path + 'transcripts.parquet'\npath_trx_tiles = path_landscape_files + 'transcript_tiles'\ntile_bounds = dega.pre.make_trx_tiles(\n    'Xenium', \n    path_trx, \n    path_transformation_matrix, \n    path_trx_tiles,\n    # tile_size=tile_size,\n    # coarse_tile_size=tile_size * 10,\n    tile_size=tile_size,    \n    image_scale=image_scale\n    # verbose=True\n)\n</pre> %%time  technology = 'Xenium' path_trx = base_path + 'transcripts.parquet' path_trx_tiles = path_landscape_files + 'transcript_tiles' tile_bounds = dega.pre.make_trx_tiles(     'Xenium',      path_trx,      path_transformation_matrix,      path_trx_tiles,     # tile_size=tile_size,     # coarse_tile_size=tile_size * 10,     tile_size=tile_size,         image_scale=image_scale     # verbose=True ) <pre>Processing chunks: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00&lt;00:00, 14.69it/s]\nProcessing coarse tiles: 126tile [00:17,  7.15tile/s]</pre> <pre>CPU times: user 30.2 s, sys: 27 s, total: 57.1 s\nWall time: 18.8 s\n</pre> <pre>\n</pre> In\u00a0[50]: Copied! <pre>%%time\npath_cell_boundaries = base_path + 'cell_boundaries.parquet'\npath_output = path_landscape_files + 'cell_segmentation'\ndega.pre.make_cell_boundary_tiles(\n    'Xenium',\n    path_cell_boundaries, \n    path_meta_cell_micron, \n    path_transformation_matrix, \n    path_output,\n    #coarse_tile_size=tile_size * 10,\n    tile_size=tile_size,\n    tile_bounds=tile_bounds,\n    image_scale=image_scale\n)\n</pre> %%time path_cell_boundaries = base_path + 'cell_boundaries.parquet' path_output = path_landscape_files + 'cell_segmentation' dega.pre.make_cell_boundary_tiles(     'Xenium',     path_cell_boundaries,      path_meta_cell_micron,      path_transformation_matrix,      path_output,     #coarse_tile_size=tile_size * 10,     tile_size=tile_size,     tile_bounds=tile_bounds,     image_scale=image_scale ) <pre>Processing coarse tiles: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:13&lt;00:00,  1.52s/it]\n</pre> <pre>CPU times: user 23.1 s, sys: 7.1 s, total: 30.3 s\nWall time: 24.4 s\n</pre> In\u00a0[51]: Copied! <pre>path_cbg = base_path + 'cell_feature_matrix/'\npath_output = path_landscape_files + 'gene_metadata.parquet'\ndega.pre.make_meta_gene('Xenium', path_cbg, path_output)\n</pre> path_cbg = base_path + 'cell_feature_matrix/' path_output = path_landscape_files + 'gene_metadata.parquet' dega.pre.make_meta_gene('Xenium', path_cbg, path_output) <pre>Reading mtx file from  data/xenium_data/Xenium_V1_human_Pancreas_FFPE_outs/cell_feature_matrix/\ncalculating mean expression from sparse float data\ncalculating variance by looping over rows\n</pre> In\u00a0[52]: Copied! <pre># Example usage:\npath_image_pyramid = path_landscape_files + 'pyramid_images/dapi_files/'  # Change this to your actual directory path\nmax_pyramid_zoom = dega.pre.get_max_zoom_level(path_image_pyramid)\n\nprint(max_pyramid_zoom)\n</pre> # Example usage: path_image_pyramid = path_landscape_files + 'pyramid_images/dapi_files/'  # Change this to your actual directory path max_pyramid_zoom = dega.pre.get_max_zoom_level(path_image_pyramid)  print(max_pyramid_zoom) <pre>16\n</pre> In\u00a0[53]: Copied! <pre>usecols = ['cell_id', 'x_centroid', 'y_centroid']\nmeta_cell = pd.read_csv(base_path + 'cells.csv.gz', index_col=0, usecols=usecols)\nmeta_cell.columns = ['center_x', 'center_y']\nmeta_cell\n</pre> usecols = ['cell_id', 'x_centroid', 'y_centroid'] meta_cell = pd.read_csv(base_path + 'cells.csv.gz', index_col=0, usecols=usecols) meta_cell.columns = ['center_x', 'center_y'] meta_cell Out[53]: center_x center_y cell_id aaaadnje-1 446.326691 1701.357300 aaacalai-1 441.307831 1735.877930 aaacjgil-1 466.053192 1712.259766 aaacpcil-1 430.858093 1707.464600 aaadhocp-1 476.111145 1711.089355 ... ... ... oiloppgp-1 6082.675781 555.142883 oilpccne-1 6106.899414 494.951843 oimacfoj-1 6080.991211 626.742126 oimaiaae-1 6030.594727 536.503418 oimajkkk-1 6022.637207 573.784302 <p>140702 rows \u00d7 2 columns</p> In\u00a0[54]: Copied! <pre>df_meta = pd.read_csv(base_path + 'analysis/clustering/gene_expression_graphclust/clusters.csv', index_col=0)\ndf_meta['Cluster'] = df_meta['Cluster'].astype('string')\ndf_meta.columns = ['cluster']\n</pre> df_meta = pd.read_csv(base_path + 'analysis/clustering/gene_expression_graphclust/clusters.csv', index_col=0) df_meta['Cluster'] = df_meta['Cluster'].astype('string') df_meta.columns = ['cluster'] In\u00a0[55]: Copied! <pre>meta_cell['cluster'] = df_meta['cluster']\n</pre> meta_cell['cluster'] = df_meta['cluster'] In\u00a0[56]: Copied! <pre>list_ser = []\nfor inst_cat in meta_cell['cluster'].unique().tolist():\n    if inst_cat is not None:\n        inst_cells = meta_cell[meta_cell['cluster'] == inst_cat].index.tolist()\n        # print(inst_cat, len(inst_cells))\n\n        inst_ser = cbg.loc[inst_cells].sum()/len(inst_cells)\n        inst_ser.name = inst_cat\n\n        list_ser.append(inst_ser)\n\ndf_sig = pd.concat(list_ser, axis=1)\n</pre> list_ser = [] for inst_cat in meta_cell['cluster'].unique().tolist():     if inst_cat is not None:         inst_cells = meta_cell[meta_cell['cluster'] == inst_cat].index.tolist()         # print(inst_cat, len(inst_cells))          inst_ser = cbg.loc[inst_cells].sum()/len(inst_cells)         inst_ser.name = inst_cat          list_ser.append(inst_ser)  df_sig = pd.concat(list_ser, axis=1)      In\u00a0[57]: Copied! <pre>df_sig = pd.concat(list_ser, axis=1)\n# handling weird behavior where there is a multiindex it appears\ndf_sig.columns = df_sig.columns.tolist()\ndf_sig.index = df_sig.index.tolist()\n</pre> df_sig = pd.concat(list_ser, axis=1) # handling weird behavior where there is a multiindex it appears df_sig.columns = df_sig.columns.tolist() df_sig.index = df_sig.index.tolist() In\u00a0[58]: Copied! <pre>keep_genes = df_sig.index.tolist()\nkeep_genes = [x for x in keep_genes if 'Unassigned' not in x]\nkeep_genes = [x for x in keep_genes if 'NegControl' not in x]\nkeep_genes = [x for x in keep_genes if 'DeprecatedCodeword' not in x]\nlen(keep_genes)\n\ndf_sig = df_sig.loc[keep_genes, clusters]\ndf_sig.shape\n</pre> keep_genes = df_sig.index.tolist() keep_genes = [x for x in keep_genes if 'Unassigned' not in x] keep_genes = [x for x in keep_genes if 'NegControl' not in x] keep_genes = [x for x in keep_genes if 'DeprecatedCodeword' not in x] len(keep_genes)  df_sig = df_sig.loc[keep_genes, clusters] df_sig.shape Out[58]: <pre>(377, 28)</pre> In\u00a0[59]: Copied! <pre>df_sig.sparse.to_dense().to_parquet(path_landscape_files + 'df_sig.parquet')\n</pre> df_sig.sparse.to_dense().to_parquet(path_landscape_files + 'df_sig.parquet') In\u00a0[60]: Copied! <pre>image_info =  [\n        {\n            \"name\": \"dapi\",\n            \"button_name\": \"DAPI\",\n            \"color\": [\n                0,\n                0,\n                255\n            ]\n        },\n        {\n            \"name\": \"bound\",\n            \"button_name\": \"BOUND\",\n            \"color\": [\n                0,\n                255,\n                0\n            ]\n        },\n        {\n            \"name\": \"rna\",\n            \"button_name\": \"RNA\",\n            \"color\": [\n                255,\n                0,\n                0\n            ]\n        },\n        {\n            \"name\": \"prot\",\n            \"button_name\": \"PROT\",\n            \"color\": [\n                255,\n                255,\n                255\n            ]\n        }\n    ]\n</pre> image_info =  [         {             \"name\": \"dapi\",             \"button_name\": \"DAPI\",             \"color\": [                 0,                 0,                 255             ]         },         {             \"name\": \"bound\",             \"button_name\": \"BOUND\",             \"color\": [                 0,                 255,                 0             ]         },         {             \"name\": \"rna\",             \"button_name\": \"RNA\",             \"color\": [                 255,                 0,                 0             ]         },         {             \"name\": \"prot\",             \"button_name\": \"PROT\",             \"color\": [                 255,                 255,                 255             ]         }     ] In\u00a0[61]: Copied! <pre>dega.pre.save_landscape_parameters(\n    'Xenium', \n    path_landscape_files,\n    'dapi_files',\n    tile_size=tile_size,\n    image_info=image_info,\n    image_format='.webp'\n)\n</pre> dega.pre.save_landscape_parameters(     'Xenium',      path_landscape_files,     'dapi_files',     tile_size=tile_size,     image_info=image_info,     image_format='.webp' ) <pre>data/xenium_landscapes/Xenium_V1_human_Pancreas_FFPE_outs_sparse//pyramid_images/dapi_files\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/brief_notebooks/Pre-process_Xenium_V1_human_Pancreas_FFPE_outs/#pre-process_xenium_v1_human_pancreas_ffpe_outs","title":"Pre-process_Xenium_V1_human_Pancreas_FFPE_outs\u00b6","text":""},{"location":"examples/brief_notebooks/Pre-process_Xenium_V1_human_Pancreas_FFPE_outs/#unzip-xenium-data","title":"Unzip Xenium Data\u00b6","text":""},{"location":"examples/brief_notebooks/Pre-process_Xenium_V1_human_Pancreas_FFPE_outs/#decompress-cell-feature-matrix-mtx-files","title":"Decompress Cell Feature Matrix MTX Files\u00b6","text":""},{"location":"examples/brief_notebooks/Pre-process_Xenium_V1_human_Pancreas_FFPE_outs/#decompress-xenium-analysis-files","title":"Decompress Xenium Analysis Files\u00b6","text":""},{"location":"examples/brief_notebooks/Pre-process_Xenium_V1_human_Pancreas_FFPE_outs/#cbg","title":"CBG\u00b6","text":""},{"location":"examples/brief_notebooks/Pre-process_Xenium_V1_human_Pancreas_FFPE_outs/#gene-metadata","title":"Gene Metadata\u00b6","text":""},{"location":"examples/brief_notebooks/Pre-process_Xenium_V1_human_Pancreas_FFPE_outs/#cell-by-gene-files","title":"Cell-by-gene Files\u00b6","text":""},{"location":"examples/brief_notebooks/Pre-process_Xenium_V1_human_Pancreas_FFPE_outs/#image-tiles","title":"Image Tiles\u00b6","text":""},{"location":"examples/brief_notebooks/Pre-process_Xenium_V1_human_Pancreas_FFPE_outs/#dapi","title":"DAPI\u00b6","text":""},{"location":"examples/brief_notebooks/Pre-process_Xenium_V1_human_Pancreas_FFPE_outs/#cell-metadata","title":"Cell Metadata\u00b6","text":""},{"location":"examples/brief_notebooks/Pre-process_Xenium_V1_human_Pancreas_FFPE_outs/#save-cell-metadata","title":"Save cell metadata\u00b6","text":""},{"location":"examples/brief_notebooks/Pre-process_Xenium_V1_human_Pancreas_FFPE_outs/#save-default-clustering-results","title":"Save default clustering results\u00b6","text":""},{"location":"examples/brief_notebooks/Pre-process_Xenium_V1_human_Pancreas_FFPE_outs/#cluster-colors","title":"Cluster Colors\u00b6","text":""},{"location":"examples/brief_notebooks/Pre-process_Xenium_V1_human_Pancreas_FFPE_outs/#transcripts","title":"Transcripts\u00b6","text":""},{"location":"examples/brief_notebooks/Pre-process_Xenium_V1_human_Pancreas_FFPE_outs/#cell-boundaries","title":"Cell Boundaries\u00b6","text":""},{"location":"examples/brief_notebooks/Pre-process_Xenium_V1_human_Pancreas_FFPE_outs/#gene-metadata","title":"Gene Metadata\u00b6","text":""},{"location":"examples/brief_notebooks/Pre-process_Xenium_V1_human_Pancreas_FFPE_outs/#max-zoom","title":"Max Zoom\u00b6","text":""},{"location":"examples/brief_notebooks/Pre-process_Xenium_V1_human_Pancreas_FFPE_outs/#cluster-gene-expression","title":"Cluster Gene Expression\u00b6","text":""},{"location":"examples/brief_notebooks/Pre-process_Xenium_V1_human_Pancreas_FFPE_outs/#save-landscape-parameters-json","title":"Save Landscape Parameters JSON\u00b6","text":""},{"location":"examples/brief_notebooks/UMAP-Cluster_Pancreas_Xenium/","title":"UMAP-Cluster Pancreas Xenium","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n%env ANYWIDGET_HMR=1\n</pre> %load_ext autoreload %autoreload 2 %env ANYWIDGET_HMR=1 <pre>env: ANYWIDGET_HMR=1\n</pre> In\u00a0[2]: Copied! <pre>import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport scanpy as sc\nimport squidpy as sq\nimport spatialdata as sd\n\nimport celldega as dega\n\nfrom spatialdata_io import xenium\n</pre> import pandas as pd import matplotlib.pyplot as plt import seaborn as sns  import scanpy as sc import squidpy as sq import spatialdata as sd  import celldega as dega  from spatialdata_io import xenium <pre>/Users/feni/anaconda3/envs/celldega_3.9/lib/python3.9/site-packages/numba/core/decorators.py:250: RuntimeWarning: nopython is set for njit and is ignored\n  warnings.warn('nopython is set for njit and is ignored', RuntimeWarning)\n</pre> In\u00a0[3]: Copied! <pre>from ipywidgets import Widget\n</pre> from ipywidgets import Widget In\u00a0[4]: Copied! <pre>ls data\n</pre> ls data <pre>merscope_data/        visium-hd_data/       xenium_landscapes/\nmerscope_landscapes/  visium-hd_landscapes/\ntmp.json              xenium_data/\n</pre> In\u00a0[5]: Copied! <pre>xenium_path = 'data/xenium_data/Xenium_V1_human_Pancreas_FFPE_outs/'\nzarr_path = 'data/xenium_data/Xenium_V1_human_Pancreas_FFPE_outs.zarr'\n</pre> xenium_path = 'data/xenium_data/Xenium_V1_human_Pancreas_FFPE_outs/' zarr_path = 'data/xenium_data/Xenium_V1_human_Pancreas_FFPE_outs.zarr' In\u00a0[6]: Copied! <pre>sdata = xenium(xenium_path)\n</pre> sdata = xenium(xenium_path) <pre>INFO     reading data/xenium_data/Xenium_V1_human_Pancreas_FFPE_outs/cell_feature_matrix.h5                        \n</pre> <pre>/var/folders/8d/jxpy9rd10j7fp2rcj_s5sz3c0000gq/T/ipykernel_70631/1221898808.py:1: DeprecationWarning: The default value of `cells_as_circles` will change to `False` in the next release. Please pass `True` explicitly to maintain the current behavior.\n  sdata = xenium(xenium_path)\n</pre> In\u00a0[8]: Copied! <pre># xenium.write(zarr_path) - original code from documentation\nsdata.write(zarr_path)\n</pre> # xenium.write(zarr_path) - original code from documentation sdata.write(zarr_path) In\u00a0[9]: Copied! <pre>sdata = sd.read_zarr(zarr_path)\nsdata\n</pre> sdata = sd.read_zarr(zarr_path) sdata <pre>/Users/feni/anaconda3/envs/celldega_3.9/lib/python3.9/site-packages/anndata/_core/aligned_df.py:67: ImplicitModificationWarning: Transforming to str index.\n  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n</pre> Out[9]: <pre>SpatialData object, with associated Zarr store: /Users/feni/Documents/celldega/notebooks/data/xenium_data/Xenium_V1_human_Pancreas_FFPE_outs.zarr\n\u251c\u2500\u2500 Images\n\u2502     \u2514\u2500\u2500 'morphology_focus': DataTree[cyx] (5, 13770, 34155), (5, 6885, 17077), (5, 3442, 8538), (5, 1721, 4269), (5, 860, 2134)\n\u251c\u2500\u2500 Labels\n\u2502     \u251c\u2500\u2500 'cell_labels': DataTree[yx] (13770, 34155), (6885, 17077), (3442, 8538), (1721, 4269), (860, 2134)\n\u2502     \u2514\u2500\u2500 'nucleus_labels': DataTree[yx] (13770, 34155), (6885, 17077), (3442, 8538), (1721, 4269), (860, 2134)\n\u251c\u2500\u2500 Points\n\u2502     \u2514\u2500\u2500 'transcripts': DataFrame with shape: (&lt;Delayed&gt;, 11) (3D points)\n\u251c\u2500\u2500 Shapes\n\u2502     \u251c\u2500\u2500 'cell_boundaries': GeoDataFrame shape: (140702, 1) (2D shapes)\n\u2502     \u251c\u2500\u2500 'cell_circles': GeoDataFrame shape: (140702, 2) (2D shapes)\n\u2502     \u2514\u2500\u2500 'nucleus_boundaries': GeoDataFrame shape: (136531, 1) (2D shapes)\n\u2514\u2500\u2500 Tables\n      \u2514\u2500\u2500 'table': AnnData (140702, 377)\nwith coordinate systems:\n    \u25b8 'global', with elements:\n        morphology_focus (Images), cell_labels (Labels), nucleus_labels (Labels), transcripts (Points), cell_boundaries (Shapes), cell_circles (Shapes), nucleus_boundaries (Shapes)</pre> In\u00a0[10]: Copied! <pre>adata = sdata.tables[\"table\"]\nadata\n</pre> adata = sdata.tables[\"table\"] adata Out[10]: <pre>AnnData object with n_obs \u00d7 n_vars = 140702 \u00d7 377\n    obs: 'cell_id', 'transcript_counts', 'control_probe_counts', 'control_codeword_counts', 'unassigned_codeword_counts', 'deprecated_codeword_counts', 'total_counts', 'cell_area', 'nucleus_area', 'region', 'z_level', 'nucleus_count', 'cell_labels'\n    var: 'gene_ids', 'feature_types', 'genome'\n    uns: 'spatialdata_attrs'\n    obsm: 'spatial'</pre> In\u00a0[11]: Copied! <pre>adata.obs\n</pre> adata.obs Out[11]: cell_id transcript_counts control_probe_counts control_codeword_counts unassigned_codeword_counts deprecated_codeword_counts total_counts cell_area nucleus_area region z_level nucleus_count cell_labels 0 aaaadnje-1 37 0 0 0 0 37 44.117658 38.021564 cell_circles 0.0 1.0 1 1 aaacalai-1 60 0 0 0 0 60 66.244221 33.912345 cell_circles 0.0 1.0 2 2 aaacjgil-1 63 0 0 0 0 63 104.491566 52.697346 cell_circles 0.0 1.0 3 3 aaacpcil-1 12 0 0 0 0 12 34.183282 17.520626 cell_circles 0.0 1.0 4 4 aaadhocp-1 143 0 0 0 0 143 149.060787 51.116877 cell_circles 0.0 1.0 5 ... ... ... ... ... ... ... ... ... ... ... ... ... ... 140697 oiloppgp-1 14 0 0 0 0 14 15.082188 15.082188 cell_circles 6.0 1.0 140698 140698 oilpccne-1 2 0 0 0 0 2 5.734844 5.734844 cell_circles 6.0 1.0 140699 140699 oimacfoj-1 11 0 0 0 0 11 13.682344 13.682344 cell_circles 6.0 1.0 140700 140700 oimaiaae-1 18 0 0 0 0 18 17.701251 17.701251 cell_circles 6.0 1.0 140701 140701 oimajkkk-1 12 0 0 0 0 12 17.204532 17.204532 cell_circles 6.0 1.0 140702 <p>140702 rows \u00d7 13 columns</p> In\u00a0[12]: Copied! <pre>adata.obsm[\"spatial\"]\n</pre> adata.obsm[\"spatial\"] Out[12]: <pre>array([[ 446.32669067, 1701.3572998 ],\n       [ 441.30783081, 1735.87792969],\n       [ 466.05319214, 1712.25976562],\n       ...,\n       [6080.99121094,  626.74212646],\n       [6030.59472656,  536.50341797],\n       [6022.63720703,  573.78430176]])</pre> In\u00a0[13]: Copied! <pre>sc.pp.calculate_qc_metrics(adata, percent_top=(10, 20, 50, 150), inplace=True)\n</pre> sc.pp.calculate_qc_metrics(adata, percent_top=(10, 20, 50, 150), inplace=True) In\u00a0[14]: Copied! <pre>cprobes = (\n    adata.obs[\"control_probe_counts\"].sum() / adata.obs[\"total_counts\"].sum() * 100\n)\ncwords = (\n    adata.obs[\"control_codeword_counts\"].sum() / adata.obs[\"total_counts\"].sum() * 100\n)\nprint(f\"Negative DNA probe count % : {cprobes}\")\nprint(f\"Negative decoding count % : {cwords}\")\n</pre> cprobes = (     adata.obs[\"control_probe_counts\"].sum() / adata.obs[\"total_counts\"].sum() * 100 ) cwords = (     adata.obs[\"control_codeword_counts\"].sum() / adata.obs[\"total_counts\"].sum() * 100 ) print(f\"Negative DNA probe count % : {cprobes}\") print(f\"Negative decoding count % : {cwords}\") <pre>Negative DNA probe count % : 0.006005935170375317\nNegative decoding count % : 0.0014334407204219034\n</pre> In\u00a0[15]: Copied! <pre>fig, axs = plt.subplots(1, 4, figsize=(15, 4))\n\naxs[0].set_title(\"Total transcripts per cell\")\nsns.histplot(\n    adata.obs[\"total_counts\"],\n    kde=False,\n    ax=axs[0],\n)\n\naxs[1].set_title(\"Unique transcripts per cell\")\nsns.histplot(\n    adata.obs[\"n_genes_by_counts\"],\n    kde=False,\n    ax=axs[1],\n)\n\n\naxs[2].set_title(\"Area of segmented cells\")\nsns.histplot(\n    adata.obs[\"cell_area\"],\n    kde=False,\n    ax=axs[2],\n)\n\naxs[3].set_title(\"Nucleus ratio\")\nsns.histplot(\n    adata.obs[\"nucleus_area\"] / adata.obs[\"cell_area\"],\n    kde=False,\n    ax=axs[3],\n)\n</pre> fig, axs = plt.subplots(1, 4, figsize=(15, 4))  axs[0].set_title(\"Total transcripts per cell\") sns.histplot(     adata.obs[\"total_counts\"],     kde=False,     ax=axs[0], )  axs[1].set_title(\"Unique transcripts per cell\") sns.histplot(     adata.obs[\"n_genes_by_counts\"],     kde=False,     ax=axs[1], )   axs[2].set_title(\"Area of segmented cells\") sns.histplot(     adata.obs[\"cell_area\"],     kde=False,     ax=axs[2], )  axs[3].set_title(\"Nucleus ratio\") sns.histplot(     adata.obs[\"nucleus_area\"] / adata.obs[\"cell_area\"],     kde=False,     ax=axs[3], ) Out[15]: <pre>&lt;Axes: title={'center': 'Nucleus ratio'}, ylabel='Count'&gt;</pre> In\u00a0[16]: Copied! <pre>sc.pp.filter_cells(adata, min_counts=10)\nsc.pp.filter_genes(adata, min_cells=5)\n</pre> sc.pp.filter_cells(adata, min_counts=10) sc.pp.filter_genes(adata, min_cells=5) In\u00a0[17]: Copied! <pre>adata.layers[\"counts\"] = adata.X.copy()\nsc.pp.normalize_total(adata, inplace=True)\nsc.pp.log1p(adata)\nsc.pp.pca(adata)\nsc.pp.neighbors(adata)\nsc.tl.umap(adata)\nsc.tl.leiden(adata)\n</pre> adata.layers[\"counts\"] = adata.X.copy() sc.pp.normalize_total(adata, inplace=True) sc.pp.log1p(adata) sc.pp.pca(adata) sc.pp.neighbors(adata) sc.tl.umap(adata) sc.tl.leiden(adata) In\u00a0[18]: Copied! <pre>sc.pl.umap(\n    adata,\n    color=[\n        \"total_counts\",\n        \"n_genes_by_counts\",\n        \"leiden\",\n    ],\n    wspace=0.4,\n)\n</pre> sc.pl.umap(     adata,     color=[         \"total_counts\",         \"n_genes_by_counts\",         \"leiden\",     ],     wspace=0.4, ) In\u00a0[19]: Copied! <pre>sq.pl.spatial_scatter(\n    adata,\n    library_id=\"spatial\",\n    shape=None,\n    color=[\n        \"leiden\",\n    ],\n    wspace=0.4,\n)\n</pre> sq.pl.spatial_scatter(     adata,     library_id=\"spatial\",     shape=None,     color=[         \"leiden\",     ],     wspace=0.4, ) <pre>/Users/feni/anaconda3/envs/celldega_3.9/lib/python3.9/site-packages/squidpy/pl/_spatial_utils.py:946: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap', 'norm' will be ignored\n  _cax = scatter(\n</pre> In\u00a0[20]: Copied! <pre>adata\n</pre> adata Out[20]: <pre>AnnData object with n_obs \u00d7 n_vars = 122678 \u00d7 377\n    obs: 'cell_id', 'transcript_counts', 'control_probe_counts', 'control_codeword_counts', 'unassigned_codeword_counts', 'deprecated_codeword_counts', 'total_counts', 'cell_area', 'nucleus_area', 'region', 'z_level', 'nucleus_count', 'cell_labels', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'log1p_total_counts', 'pct_counts_in_top_10_genes', 'pct_counts_in_top_20_genes', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_150_genes', 'n_counts', 'leiden'\n    var: 'gene_ids', 'feature_types', 'genome', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'n_cells'\n    uns: 'spatialdata_attrs', 'log1p', 'pca', 'neighbors', 'umap', 'leiden', 'leiden_colors'\n    obsm: 'spatial', 'X_pca', 'X_umap'\n    varm: 'PCs'\n    layers: 'counts'\n    obsp: 'distances', 'connectivities'</pre> In\u00a0[21]: Copied! <pre>adata.obsm['X_umap']\n</pre> adata.obsm['X_umap'] Out[21]: <pre>array([[10.506712  ,  1.2212458 ],\n       [10.697917  ,  0.6223265 ],\n       [11.325302  ,  2.8573225 ],\n       ...,\n       [ 0.02741709,  5.6208534 ],\n       [-0.29021668,  6.7356443 ],\n       [-0.5836044 ,  4.175001  ]], dtype=float32)</pre> In\u00a0[22]: Copied! <pre>adata.write_h5ad('data/xenium_data/Xenium_V1_human_Pancreas_FFPE_outs.h5ad')\n</pre> adata.write_h5ad('data/xenium_data/Xenium_V1_human_Pancreas_FFPE_outs.h5ad') In\u00a0[23]: Copied! <pre>adata = sc.read_h5ad('data/xenium_data/Xenium_V1_human_Pancreas_FFPE_outs.h5ad')\nadata.obs.set_index('cell_id', inplace=True)\nadata\n</pre> adata = sc.read_h5ad('data/xenium_data/Xenium_V1_human_Pancreas_FFPE_outs.h5ad') adata.obs.set_index('cell_id', inplace=True) adata Out[23]: <pre>AnnData object with n_obs \u00d7 n_vars = 122678 \u00d7 377\n    obs: 'transcript_counts', 'control_probe_counts', 'control_codeword_counts', 'unassigned_codeword_counts', 'deprecated_codeword_counts', 'total_counts', 'cell_area', 'nucleus_area', 'region', 'z_level', 'nucleus_count', 'cell_labels', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'log1p_total_counts', 'pct_counts_in_top_10_genes', 'pct_counts_in_top_20_genes', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_150_genes', 'n_counts', 'leiden'\n    var: 'gene_ids', 'feature_types', 'genome', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'n_cells'\n    uns: 'leiden', 'leiden_colors', 'log1p', 'neighbors', 'pca', 'spatialdata_attrs', 'umap'\n    obsm: 'X_pca', 'X_umap', 'spatial'\n    varm: 'PCs'\n    layers: 'counts'\n    obsp: 'connectivities', 'distances'</pre> In\u00a0[24]: Copied! <pre>meta_cell = adata.obs['leiden'].to_dict()\n</pre> meta_cell = adata.obs['leiden'].to_dict() In\u00a0[25]: Copied! <pre>clusters = adata.obs['leiden'].cat.categories.tolist()\ncolors = adata.uns['leiden_colors']\nser_counts = adata.obs['leiden'].value_counts()\nser_color = pd.Series(colors, index=clusters, name='color')\nmeta_cluster_df = pd.DataFrame(ser_color)\nmeta_cluster_df['count'] = ser_counts\n\n# meta_cluster.index = ['leiden-' + str(x) for x in meta_cluster.index]\nmeta_cluster_df.index = [str(x) for x in meta_cluster_df.index]\nmeta_cluster = meta_cluster_df.to_dict(orient='index')\n</pre> clusters = adata.obs['leiden'].cat.categories.tolist() colors = adata.uns['leiden_colors'] ser_counts = adata.obs['leiden'].value_counts() ser_color = pd.Series(colors, index=clusters, name='color') meta_cluster_df = pd.DataFrame(ser_color) meta_cluster_df['count'] = ser_counts  # meta_cluster.index = ['leiden-' + str(x) for x in meta_cluster.index] meta_cluster_df.index = [str(x) for x in meta_cluster_df.index] meta_cluster = meta_cluster_df.to_dict(orient='index') In\u00a0[27]: Copied! <pre># umap_df.isna().any().any()\n</pre> # umap_df.isna().any().any() In\u00a0[28]: Copied! <pre>adata.obs.shape\n</pre> adata.obs.shape Out[28]: <pre>(122678, 21)</pre> In\u00a0[29]: Copied! <pre># umap_df = pd.DataFrame(adata.obsm['X_umap'] * 500, index=adata.obs.index)\numap_df = pd.DataFrame(adata.obsm['X_umap'], index=adata.obs.index)\n\n# Convert the DataFrame to a dictionary with index as keys and rows as arrays\numap_dict = umap_df.to_dict(orient='index')\n\n# Convert each row dictionary into a list of rounded values\numap = {key: [val for val in value.values()] for key, value in umap_dict.items()}\n</pre> # umap_df = pd.DataFrame(adata.obsm['X_umap'] * 500, index=adata.obs.index) umap_df = pd.DataFrame(adata.obsm['X_umap'], index=adata.obs.index)  # Convert the DataFrame to a dictionary with index as keys and rows as arrays umap_dict = umap_df.to_dict(orient='index')  # Convert each row dictionary into a list of rounded values umap = {key: [val for val in value.values()] for key, value in umap_dict.items()}  In\u00a0[30]: Copied! <pre>base_url = 'https://raw.githubusercontent.com/broadinstitute/celldega_Xenium_human_Pancreas_FFPE/main/Landscape_Xenium_V1_human_Pancreas_FFPE_outs_webp'\n</pre> base_url = 'https://raw.githubusercontent.com/broadinstitute/celldega_Xenium_human_Pancreas_FFPE/main/Landscape_Xenium_V1_human_Pancreas_FFPE_outs_webp' In\u00a0[31]: Copied! <pre># landscape_ist\n</pre>  # landscape_ist In\u00a0[32]: Copied! <pre># import pandas as pd\n# import numpy as np\n\n# Assuming `adata` is your AnnData object\n# Extract cluster assignments from the `leiden` column\nadata.obs['leiden'] = adata.obs['leiden'].astype('string')  # Ensure string dtype for clusters\n\nlist_ser = []\nfor inst_cat in adata.obs['leiden'].unique():\n    if inst_cat is not None:\n        # Get the indices of cells belonging to the current cluster\n        inst_cells = adata.obs[adata.obs['leiden'] == inst_cat].index.tolist()\n\n        # Compute the mean expression for the cluster\n        inst_ser = pd.Series(adata[inst_cells].X.mean(axis=0).A1, index=adata.var_names)\n        inst_ser.name = inst_cat\n\n        list_ser.append(inst_ser)\n\n# Combine results into a single DataFrame\ndf_sig = pd.concat(list_ser, axis=1)\n\n# Rename columns to cluster names\ndf_sig.columns = df_sig.columns.tolist()\n\n# Filter genes based on conditions\nkeep_genes = df_sig.index.tolist()\nkeep_genes = [x for x in keep_genes if 'Unassigned' not in x]\nkeep_genes = [x for x in keep_genes if 'NegControl' not in x]\nkeep_genes = [x for x in keep_genes if 'DeprecatedCodeword' not in x]\n\ndf_sig = df_sig.loc[keep_genes]\n\n# # Save the result as a Parquet file\n# df_sig.to_parquet('df_sig.parquet')\n</pre> # import pandas as pd # import numpy as np  # Assuming `adata` is your AnnData object # Extract cluster assignments from the `leiden` column adata.obs['leiden'] = adata.obs['leiden'].astype('string')  # Ensure string dtype for clusters  list_ser = [] for inst_cat in adata.obs['leiden'].unique():     if inst_cat is not None:         # Get the indices of cells belonging to the current cluster         inst_cells = adata.obs[adata.obs['leiden'] == inst_cat].index.tolist()          # Compute the mean expression for the cluster         inst_ser = pd.Series(adata[inst_cells].X.mean(axis=0).A1, index=adata.var_names)         inst_ser.name = inst_cat          list_ser.append(inst_ser)  # Combine results into a single DataFrame df_sig = pd.concat(list_ser, axis=1)  # Rename columns to cluster names df_sig.columns = df_sig.columns.tolist()  # Filter genes based on conditions keep_genes = df_sig.index.tolist() keep_genes = [x for x in keep_genes if 'Unassigned' not in x] keep_genes = [x for x in keep_genes if 'NegControl' not in x] keep_genes = [x for x in keep_genes if 'DeprecatedCodeword' not in x]  df_sig = df_sig.loc[keep_genes]  # # Save the result as a Parquet file # df_sig.to_parquet('df_sig.parquet')  In\u00a0[33]: Copied! <pre>df_sig.shape\n</pre> df_sig.shape Out[33]: <pre>(377, 11)</pre> In\u00a0[34]: Copied! <pre>network = dega.clust.hc(df_sig)\n</pre> network = dega.clust.hc(df_sig) In\u00a0[37]: Copied! <pre>Widget.close_all()\nmat = dega.viz.Matrix(network=network, width=500, height=500)\nlandscape_ist = dega.viz.Landscape(\n    technology='Xenium', \n    height=600,\n    base_url = base_url,\n    meta_cell = meta_cell,\n    meta_cluster = meta_cluster,\n    umap=umap,\n    landscape_state='umap'\n)\n</pre> Widget.close_all() mat = dega.viz.Matrix(network=network, width=500, height=500) landscape_ist = dega.viz.Landscape(     technology='Xenium',      height=600,     base_url = base_url,     meta_cell = meta_cell,     meta_cluster = meta_cluster,     umap=umap,     landscape_state='umap' ) In\u00a0[39]: Copied! <pre>dega.viz.landscape_matrix(landscape_ist, mat)\n</pre> dega.viz.landscape_matrix(landscape_ist, mat) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/brief_notebooks/UMAP-Cluster_Pancreas_Xenium/#umap-cluster-pancreas-xenium","title":"UMAP-Cluster Pancreas Xenium\u00b6","text":"<p>https://squidpy.readthedocs.io/en/stable/notebooks/tutorials/tutorial_xenium.html#analyze-xenium-data</p>"},{"location":"examples/brief_notebooks/UMAP-Cluster_Pancreas_Xenium/#pre-process-cluster-and-umap","title":"Pre-Process, Cluster, and UMAP\u00b6","text":""},{"location":"examples/brief_notebooks/UMAP-Cluster_Pancreas_Xenium/#calculate-qc-metrics","title":"Calculate QC Metrics\u00b6","text":""},{"location":"examples/brief_notebooks/UMAP-Cluster_Pancreas_Xenium/#load-pre-calc-clustering-and-umap-results","title":"Load Pre-calc Clustering and UMAP Results\u00b6","text":""},{"location":"gallery/","title":"Celldega Gallery","text":"<p>This page includes links to visualizations that are made with the stand-alone Celldega JavaScript library.</p>"},{"location":"gallery/#imaging-spatial-transcriptomics","title":"Imaging Spatial Transcriptomics","text":""},{"location":"gallery/#xenium","title":"Xenium","text":"<ul> <li>Xenium Mouse Brain </li> <li>Xenium Human Skin Cancer </li> </ul>"},{"location":"gallery/#sequencing-spatial-transcriptomics","title":"Sequencing Spatial Transcriptomics","text":""},{"location":"gallery/#visium-hd","title":"Visium HD","text":""},{"location":"gallery/gallery_xenium/","title":"Celldega Xenium Gallery","text":""},{"location":"gallery/gallery_xenium/#xenium-prime-mouse-brain-coronal-ff","title":"Xenium Prime Mouse Brain Coronal FF","text":""},{"location":"gallery/gallery_xenium/#xenium-prime-human-skin-ffpe-outs","title":"Xenium Prime Human Skin FFPE outs","text":""},{"location":"gallery/gallery_xenium/#xenium-human-pancreas-ffpe","title":"Xenium Human Pancreas FFPE","text":""},{"location":"gallery/gallery_xenium/#bone-marrow","title":"Bone Marrow","text":""},{"location":"gallery/gallery_xenium_mouse_brain/","title":"Xenium Prime Mouse Brain Coronal FF","text":""},{"location":"gallery/gallery_xenium_multi/","title":"Xenium Multi Dataset","text":""},{"location":"gallery/gallery_xenium_multi/#xenium-prime-mouse-brain-coronal-ff","title":"Xenium Prime Mouse Brain Coronal FF","text":""},{"location":"gallery/gallery_xenium_multi/#xenium-prime-human-skin-ffpe-outs","title":"Xenium Prime Human Skin FFPE outs","text":""},{"location":"gallery/gallery_xenium_multi/#xenium-human-pancreas-ffpe","title":"Xenium Human Pancreas FFPE","text":""},{"location":"gallery/gallery_xenium_multi/#bone-marrow","title":"Bone Marrow","text":""},{"location":"gallery/gallery_xenium_skin_cancer/","title":"Xenium Prime Human Skin FFPE outs","text":""},{"location":"javascript/","title":"JavaScript API Overview","text":"<p>Celldega's visualization methods can be used as a stand-alone JavaScript library outside the context of a Jupyter notebook. This can be used to create showcase visualizations with publicly hosted data.</p>"},{"location":"javascript/api/","title":"Celldega JavaScript API Documentation","text":"<p>The JavaScript component of Celldega is used within the Jupyter Widgets framework to provide interactive visualization in the context of a Jupyter notebook but can also be used as a standalone JavaScript library.</p>"},{"location":"javascript/api/#landscape_ist-api-documentation","title":"<code>landscape_ist</code> API Documentation","text":"<p>The <code>landscape_ist</code> function initializes and renders an interactive spatial transcriptomics (IST) landscape visualization. This API is designed to work with Deck.gl and includes customizable visualization options, dynamic data updates, and UI interactions.</p>"},{"location":"javascript/api/#parameters","title":"Parameters","text":"<ul> <li><code>el</code> (<code>HTMLElement</code>): The root DOM element where the visualization is rendered.</li> <li><code>ini_model</code> (<code>Object</code>): The initial data model containing configuration and state.</li> <li><code>token</code> (<code>string</code>): Authentication token for accessing data.</li> <li><code>ini_x</code>, <code>ini_y</code>, <code>ini_z</code> (<code>number</code>): Initial spatial coordinates for the view.</li> <li><code>ini_zoom</code> (<code>number</code>): Initial zoom level for the visualization.</li> <li><code>base_url</code> (<code>string</code>): Base URL for accessing data files.</li> <li><code>dataset_name</code> (<code>string</code>, optional): Name of the dataset being visualized.</li> <li><code>trx_radius</code> (<code>number</code>, optional): Initial radius for transcript points. Default: <code>0.25</code>.</li> <li><code>width</code> (<code>number|string</code>, optional): Width of the visualization. Default: <code>100%</code>.</li> <li><code>height</code> (<code>number</code>, optional): Height of the visualization. Default: <code>800</code>.</li> <li><code>view_change_custom_callback</code> (<code>Function</code>, optional): Custom callback triggered on view changes.</li> </ul>"},{"location":"javascript/api/#public-api","title":"Public API","text":"<p>The <code>landscape_ist</code> function returns an object (<code>landscape</code>) with several methods for interacting with the visualization.</p>"},{"location":"javascript/api/#update_matrix_gene","title":"<code>update_matrix_gene</code>","text":"<p>Updates the visualization to highlight data for a specific gene.</p>"},{"location":"javascript/api/#parameters_1","title":"Parameters","text":"<ul> <li><code>inst_gene</code> (<code>string</code>): The gene to highlight.</li> </ul>"},{"location":"javascript/api/#behavior","title":"Behavior","text":"<ul> <li>Updates the transcript layer to show data for the specified gene.</li> <li>Scrolls the bar graph to bring the selected gene into view.</li> <li>Toggles visibility of image layers and controls based on the selected gene.</li> </ul>"},{"location":"javascript/api/#update_matrix_col","title":"<code>update_matrix_col</code>","text":"<p>Updates the visualization to highlight data for a specific column (e.g., cluster).</p>"},{"location":"javascript/api/#parameters_2","title":"Parameters","text":"<ul> <li><code>inst_col</code> (<code>string</code>): The column to highlight.</li> </ul>"},{"location":"javascript/api/#behavior_1","title":"Behavior","text":"<ul> <li>Highlights the bar graph corresponding to the selected column.</li> <li>Updates cell and path layers to reflect the selected column.</li> <li>Toggles visibility of layers based on the column selection.</li> </ul>"},{"location":"javascript/api/#update_matrix_dendro_col","title":"<code>update_matrix_dendro_col</code>","text":"<p>Updates the visualization based on a dendrogram selection of columns.</p>"},{"location":"javascript/api/#parameters_3","title":"Parameters","text":"<ul> <li><code>selected_cols</code> (<code>Array&lt;string&gt;</code>): The list of selected column names.</li> </ul>"},{"location":"javascript/api/#behavior_2","title":"Behavior","text":"<ul> <li>Highlights the selected columns in the bar graph.</li> <li>Updates layers to reflect the selection.</li> </ul>"},{"location":"javascript/api/#update_view_state","title":"<code>update_view_state</code>","text":"<p>Updates the view state of the Deck.gl visualization.</p>"},{"location":"javascript/api/#parameters_4","title":"Parameters","text":"<ul> <li><code>new_view_state</code> (<code>Object</code>): The new view state configuration.</li> <li><code>close_up</code> (<code>boolean</code>): Whether the view should zoom in closely.</li> <li><code>trx_layer</code> (<code>Object</code>): The transcript layer to update.</li> </ul>"},{"location":"javascript/api/#behavior_3","title":"Behavior","text":"<ul> <li>Adjusts the viewport and reconfigures layers based on the new view state.</li> </ul>"},{"location":"javascript/api/#update_layers","title":"<code>update_layers</code>","text":"<p>Updates all visualization layers.</p>"},{"location":"javascript/api/#behavior_4","title":"Behavior","text":"<ul> <li>Refreshes the Deck.gl layers with the current visualization state.</li> </ul>"},{"location":"javascript/api/#finalize","title":"<code>finalize</code>","text":"<p>Finalizes the Deck.gl instance and cleans up resources.</p>"},{"location":"javascript/api/#behavior_5","title":"Behavior","text":"<ul> <li>Disposes of all Deck.gl resources and event listeners to prevent memory leaks.</li> </ul>"},{"location":"javascript/api/#usage-example","title":"Usage Example","text":"<pre><code>\njavascript\nimport { landscape_ist } from 'path/to/landscape_ist';\n\nconst rootElement = document.getElementById('visualization-container');\nconst model = { /* Model containing visualization data */ };\n\nconst visualization = await landscape_ist(\n    rootElement,\n    model,\n    'example-token',\n    100,\n    200,\n    0,\n    -5,\n    'https://example.com/data',\n    'Example Dataset'\n);\n\n// Update the visualization with a specific gene.\nvisualization.update_matrix_gene('TP53');\n\n// Update the visualization with a specific column.\nvisualization.update_matrix_col('Cluster 1');\n\n// Finalize the visualization when done.\nvisualization.finalize();\n\n</code></pre>"},{"location":"javascript/api/#matrix_viz-api-documentation","title":"<code>matrix_viz</code> API Documentation","text":"<p>The <code>matrix_viz</code> function initializes and renders a matrix visualization. This API is built using approaches and code adaptations from the Clustergrammer-GL library, and it integrates tightly with Deck.gl to provide interactive and dynamic visualizations.</p>"},{"location":"javascript/api/#parameters_5","title":"Parameters","text":"<ul> <li><code>model</code> (<code>Object</code>): The model object containing configuration data for the visualization.</li> <li><code>el</code> (<code>HTMLElement</code>): The root DOM element where the visualization is rendered.</li> <li><code>network</code> (<code>Object</code>): The network object containing the matrix data to visualize.</li> <li><code>width</code> (<code>string|number</code>, optional): The width of the visualization. Default: <code>'800'</code>.</li> <li><code>height</code> (<code>string|number</code>, optional): The height of the visualization. Default: <code>'800'</code>.</li> <li><code>row_label_callback</code> (<code>Function</code>, optional): A callback function triggered on row label interactions.</li> <li><code>col_label_callback</code> (<code>Function</code>, optional): A callback function triggered on column label interactions.</li> <li><code>col_dendro_callback</code> (<code>Function</code>, optional): A callback function triggered on dendrogram column interactions.</li> </ul>"},{"location":"javascript/api/#internal-behavior","title":"Internal Behavior","text":"<p>The function performs the following setup: 1. Deck.gl Integration:    - Initializes a Deck.gl instance for the matrix visualization.    - Sets properties for interactivity, including tooltips, view state changes, and layer filtering.</p> <ol> <li>Matrix Data Setup:</li> <li>Parses and structures the matrix data from the <code>network</code> object.</li> <li> <p>Configures labels, categories, and dendrograms for both rows and columns.</p> </li> <li> <p>Layer Initialization:</p> </li> <li>Creates layers for:<ul> <li>Matrix cells.</li> <li>Row and column labels.</li> <li>Row and column categories.</li> <li>Row and column dendrograms.</li> </ul> </li> <li> <p>Attaches interactions (e.g., click events) to these layers.</p> </li> <li> <p>UI Setup:</p> </li> <li>Creates a container for the visualization and appends it to the root DOM element.</li> </ol>"},{"location":"javascript/api/#example-usage","title":"Example Usage","text":"<pre><code>import { matrix_viz } from 'path/to/matrix_viz';\n\nconst rootElement = document.getElementById('matrix-container');\nconst model = { /* Model containing visualization data */ };\nconst network = { /* Network object representing the matrix data */ };\n\n// Callback functions\nconst rowLabelCallback = (row) =&gt; {\n    console.log('Row label clicked:', row);\n};\n\nconst colLabelCallback = (col) =&gt; {\n    console.log('Column label clicked:', col);\n};\n\nconst colDendroCallback = (dendro) =&gt; {\n    console.log('Column dendrogram clicked:', dendro);\n};\n\n// Initialize the matrix visualization\nawait matrix_viz(\n    model,\n    rootElement,\n    network,\n    800,\n    800,\n    rowLabelCallback,\n    colLabelCallback,\n    colDendroCallback\n);\n</code></pre>"},{"location":"overview/","title":"Overview","text":"<p>The Celldega library is being developed to help researchers easily visualize and analyze high-dimensional spatial-omics data in the context of a notebook workflow. Initial development has been focused on spatial transcriptomics visualization.</p> <p>Celldega can be used as a Python library in a Jupyter notebook environment or as a stand-alone JavaScript library for creating visualizations.</p> <ul> <li>Getting Started</li> <li>Installation</li> <li>Usage</li> </ul>"},{"location":"overview/file_formats/","title":"Celldega File Formats","text":"<p>While there has been tremendous progress in developing standardized data formats and architectures for spatial-omics data, namely SpatialData and the related AnnData, these approaches currently lack support for interactive cloud-based visualization of large (&gt;100M transcripts) Spatial Transcriptomics (ST) data. Furthermore, all-in-one data format approaches preclude the development of compact visualization-specific data formats.</p> <p>The Celldega project addresses these challenges with the development of a new ST data format called LandscapeFiles, specifically built for cloud-based visualization. LandscapeFiles support Celldega's Landscape visualization method by leveraging compact image formats and cloud-native data formats to enable efficient storage and visualization of image (e.g., microscopy images) and vectorized data (e.g., transcript coordinates). This approach is highly scalable, enabling the visualization of very large ST datasets (&gt;400M transcripts), while remaining compact enough that the  LandscapeFiles for an entire Xenium dataset can be hosted in a public GitHub repository.</p>"},{"location":"overview/file_formats/#landscapefiles","title":"LandscapeFiles","text":"<p>LandscapeFiles are generated using the Celldega pre module (see example Google Colab notebook Celldega-Landscape-Pre-Process_Xenium-Pancreas-Dataset) and are used by Celldega's JavaScript front-end to interactively visualize ST data. Users have several options for hosting LandscapeFiles both locally on the cloud (e.g., Terra.bio buckets) or locally (e.g., running a local server to locally host LandscapeFiles).</p>"},{"location":"overview/file_formats/#ist-landscapefiles","title":"iST LandscapeFiles","text":"<p>The file structure for a Xenium Prime dataset's LandscapeFiles is shown below.</p> <pre><code>.\n\u251c\u2500\u2500 cbg\n\u251c\u2500\u2500 cell_clusters\n\u251c\u2500\u2500 cell_metadata.parquet\n\u251c\u2500\u2500 cell_segmentation\n\u251c\u2500\u2500 df_sig.parquet\n\u251c\u2500\u2500 landscape_parameters.json\n\u251c\u2500\u2500 meta_gene.parquet\n\u251c\u2500\u2500 pyramid_images\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 bound_files\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dapi_files\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 prot_files\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 rna_files\n\u2502\u2500\u2500 transcript_tiles\n\u2514\u2500\u2500 xenium_transform.csv\n\n</code></pre> <p>The LandscapeFiles for an an example public 10X Genomics Xenium dataset can be found here.</p>"},{"location":"overview/file_formats/#cell-by-gene","title":"Cell-by-Gene","text":"<p>The <code>cbg</code> directory contains parquet files for each gene. Each file has a table of all the non-zero single cell expression counts. See example below:</p> <pre><code>    A2ML1\naaaaljij-1  18\naaabgfcl-1  24\naaacghkb-1  28\naaachnfg-1  14\naaacknep-1  1\n\n</code></pre>"},{"location":"overview/file_formats/#cell-clusters","title":"Cell Clusters","text":"<p>The <code>cell_clusters</code> directory contains single-cell clustering data. For Xenium data, these will include the default clustering results stored in two parquet files.</p>"},{"location":"overview/file_formats/#clusterparquet","title":"cluster.parquet","text":"<p>This file contains the cluster identity of each cell. See example below:</p> <pre><code>    cluster\naaaaljij-1  28\naaabgfcl-1  27\naaacghkb-1  27\naaachnfg-1  28\naaacknep-1  28\n\n</code></pre>"},{"location":"overview/file_formats/#meta_clusterparquet","title":"meta_cluster.parquet","text":"<p>This file contains metadata on the cell clusters, which includes the color and cell count. See example below:</p> <pre><code>    color   count\n1   #1f77b4 12742\n2   #ff7f0e 10058\n3   #2ca02c 9171\n4   #d62728 8781\n5   #9467bd 7760\n\n</code></pre>"},{"location":"overview/file_formats/#cell-metadata","title":"Cell Metadata","text":"<p>The <code>cell_metadata.parquet</code> file contains the centroid positions of all cells. See example below:</p> <pre><code>cell_id name    geometry\n\naaaaljij-1  aaaaljij-1  [819.7626194690856, 10819.416697734863]\naaabgfcl-1  aaabgfcl-1  [861.7377139772034, 10683.254024123535]\naaacghkb-1  aaacghkb-1  [876.8403955191346, 10627.146491566895]\naaachnfg-1  aaachnfg-1  [799.6315031020813, 10692.094786328125]\naaacknep-1  aaacknep-1  [760.0623424668274, 10729.360408533203]\n\n</code></pre>"},{"location":"overview/file_formats/#cell-segmentation","title":"Cell Segmentation","text":"<p>The <code>cell_segmentation</code> directory contains tiled parquet files that contain cell segmentation polygons for the cells within a given tile. See example below:</p> <pre><code>cell_id GEOMETRY    name\n\nmnnojdjm-1  [[[35052.998290142576, 2648.999973659546], [35...   mnnojdjm-1\nmnoafgkh-1  [[[35229.99735775, 2654.999800875], [35227.998...   mnoafgkh-1\nmnodjmcf-1  [[[35090.99920641015, 2657.9998580948486], [35...   mnodjmcf-1\nmoelbbjj-1  [[[35233.997817008785, 2602.9998622198486], [3...   moelbbjj-1\nmoemfhce-1  [[[35242.998275892576, 2539.9998095], [35239.9...   moemfhce-1\n\n</code></pre>"},{"location":"overview/file_formats/#cell-cluster-gene-expression-signatures","title":"Cell Cluster Gene Expression Signatures","text":"<p>The <code>df_sig.parquet</code> file contains the gene expression signatures of the cell clusters - defined as the average gene expression level of a cluster's cells. See example below:</p> <pre><code>    1   2   3   4   5   6   7   8   9   10  ... 20  21  22  23  24  25  26  27  28  29\nA2ML1   0.000235    0.000597    0.000109    0.000114    0.002320    0.000823    0.000996    0.000372    0.000760    0.000473    ... 0.018356    0.0000  0.000000    0.000000    0.000000    0.000000    2.593168    8.309091    5.602632    0.000000\nAAMP    0.296029    0.298668    0.032494    0.052727    0.003222    0.515027    0.014938    0.070061    0.395857    0.470894    ... 0.122905    0.0960  0.429596    0.058206    0.128743    0.511224    0.580745    0.456566    0.136842    0.052632\nAAR2    0.075655    0.069994    0.015375    0.023118    0.002964    0.118705    0.006971    0.038840    0.091410    0.117132    ... 0.054270    0.0424  0.129148    0.022901    0.030938    0.130612    0.154244    0.117172    0.057895    0.021053\nAARSD1  0.074557    0.156194    0.013412    0.017880    0.001546    0.200357    0.005477    0.028805    0.121057    0.120208    ... 0.047087    0.0272  0.093274    0.019084    0.028942    0.223469    0.120083    0.024242    0.005263    0.010526\nABAT    0.004787    0.008053    0.009814    0.015830    0.000902    0.009743    0.004481    0.004832    0.003801    0.006626    ... 0.008779    0.0072  0.004484    0.017176    0.008982    0.002041    0.006211    0.002020    0.000000    0.005263\n</code></pre>"},{"location":"overview/file_formats/#landscape-parameters","title":"Landscape Parameters","text":"<p>This file contains the configuration information about the dataset. See example below:</p> <pre><code>{\n    \"technology\": \"Xenium\",\n    \"max_pyramid_zoom\": 16,\n    \"tile_size\": 250,\n    \"image_info\": [\n        {\n            \"name\": \"dapi\",\n            \"button_name\": \"DAPI\",\n            \"color\": [\n                0,\n                0,\n                255\n            ]\n        },\n        {\n            \"name\": \"bound\",\n            \"button_name\": \"BOUND\",\n            \"color\": [\n                0,\n                255,\n                0\n            ]\n        },\n        {\n            \"name\": \"rna\",\n            \"button_name\": \"RNA\",\n            \"color\": [\n                255,\n                0,\n                0\n            ]\n        },\n        {\n            \"name\": \"prot\",\n            \"button_name\": \"PROT\",\n            \"color\": [\n                255,\n                255,\n                255\n            ]\n        }\n    ],\n    \"image_format\": \".webp\"\n}\n</code></pre>"},{"location":"overview/file_formats/#gene-metadata","title":"Gene Metadata","text":"<p>The <code>gene_metadata.parquet</code> file contains gene level metadata including: average expression across all cells, standard deviation, max expression, proportion of cells with non-zero expression, and the color assigned to each gene. See example below:</p> <pre><code>    mean    std max non-zero    color\nA2ML1   0.078391    3.128721    46.0    0.000009    #1f77b4\nAAMP    0.175449    1.621841    7.0 0.000009    #ff7f0e\nAAR2    0.048494    0.780702    4.0 0.000009    #2ca02c\nAARSD1  0.060533    0.897824    4.0 0.000009    #d62728\nABAT    0.006575    0.285613    3.0 0.000009    #9467bd\n\n</code></pre>"},{"location":"overview/file_formats/#pyramid-images","title":"Pyramid Images","text":"<p>The <code>pyramid_images</code> directory contains iST images from all available channels saved  Deep Zoom pyramids using the image file format WebP. An example directory structure for a Xenium multi-modal dataset looks like:</p> <pre><code>.\n\u251c\u2500\u2500 bound.dzi\n\u251c\u2500\u2500 bound_files\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 0\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 10\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 11\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 12\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 13\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 14\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 15\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 16\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 2\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 3\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 4\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 5\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 6\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 7\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 8\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 9\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 vips-properties.xml\n\u251c\u2500\u2500 dapi.dzi\n\u251c\u2500\u2500 dapi_files\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 0\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 10\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 11\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 12\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 13\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 14\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 15\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 16\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 2\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 3\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 4\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 5\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 6\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 7\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 8\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 9\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 vips-properties.xml\n\u251c\u2500\u2500 prot.dzi\n\u251c\u2500\u2500 prot_files\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 0\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 10\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 11\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 12\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 13\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 14\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 15\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 16\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 2\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 3\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 4\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 5\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 6\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 7\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 8\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 9\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 vips-properties.xml\n\u251c\u2500\u2500 rna.dzi\n\u2514\u2500\u2500 rna_files\n    \u251c\u2500\u2500 0\n    \u251c\u2500\u2500 1\n    \u251c\u2500\u2500 10\n    \u251c\u2500\u2500 11\n    \u251c\u2500\u2500 12\n    \u251c\u2500\u2500 13\n    \u251c\u2500\u2500 14\n    \u251c\u2500\u2500 15\n    \u251c\u2500\u2500 16\n    \u251c\u2500\u2500 2\n    \u251c\u2500\u2500 3\n    \u251c\u2500\u2500 4\n    \u251c\u2500\u2500 5\n    \u251c\u2500\u2500 6\n    \u251c\u2500\u2500 7\n    \u251c\u2500\u2500 8\n    \u251c\u2500\u2500 9\n    \u2514\u2500\u2500 vips-properties.xml\n\n</code></pre>"},{"location":"overview/file_formats/#transcript-tiles","title":"Transcript Tiles","text":"<p>The <code>transcript_tiles</code> directory contains tiled parquet files that contain transcript data for transcripts within a given tile. See example below:</p> <pre><code>    name    geometry\n20862147    AARSD1  [25663.38, 11758.09]\n20862230    ABCA1   [25650.44, 11757.28]\n20862780    ABCD1   [25634.19, 11754.12]\n20862819    ABCD1   [25635.51, 11755.29]\n20863051    ABHD6   [25506.54, 11753.75]\n\n</code></pre>"},{"location":"overview/file_formats/#image-transformation","title":"Image Transformation","text":"<p>The <code>xenium_transform.csv</code> file contains the 3x3 image transformation matrix to transition from physical coordinates into image coordinates.</p>"},{"location":"overview/file_formats/#sst-landscapefiles","title":"sST LandscapeFiles","text":""},{"location":"overview/getting_started/","title":"Getting Started","text":"<p>Celldega is a spatial analysis and visualization library that is being developed by the Spatial Technology Platform at the Broad Institute of MIT and Harvard. Celldega can be used as a Jupyter Widget in Python as well as a stand-alone JavaScript library.</p> <p>Please see examples notebooks below to try out Celldega in a Jupyter notebook or ObservableHQ JavaScript notebook:</p> <ul> <li>Celldega_Xenium_Landscape_Visualizations_Colab.ipynb</li> <li>Celldega Landscape Xenium ObservableHQ</li> </ul>"},{"location":"overview/installation/","title":"Installation","text":""},{"location":"overview/installation/#python","title":"Python","text":"<p>The Celldega library can be installed using pip</p> <p>Celldega can be installed using pip:</p> <pre><code>pip install celldega\n</code></pre> <p>Celldega can also be installed with the optional pre-processing requirements (e.g., vips for image pre-processing) using:</p> <pre><code>pip install celldega[pre]\n</code></pre>"},{"location":"overview/installation/#javascript","title":"JavaScript","text":"<p>Celldega can be used in a JavaScript environment such as ObservableHQ by importing it as a module from content delivery networks like esm.sh:</p> <pre><code>celldega = await import('https://esm.sh/celldega@latest')\n</code></pre> <p>Or by importing it from a local file</p> <pre><code>import celldega from 'js/widget.js'\n</code></pre>"},{"location":"overview/usage/","title":"Celldega Usage","text":""},{"location":"overview/usage/#terrabio","title":"Terra.bio","text":"<p>** Coming soon **</p>"},{"location":"python/","title":"Python API Overview","text":""},{"location":"python/#pre-module-overview","title":"Pre Module Overview","text":"<p>The <code>pre</code> module contains methods for pre-processing LandscapeFiles.</p>"},{"location":"python/#clust-module-overview","title":"Clust Module Overview","text":"<p>The <code>clust</code> module contains methods for clustering high-dimensional data.</p>"},{"location":"python/#neighborhood-overview","title":"Neighborhood Overview","text":"<p>The <code>nbhd</code> module contains methods for calculating tissue neighborhoods.</p>"},{"location":"python/#viz-module-overview","title":"Viz Module Overview","text":"<p>The <code>viz</code> module contains functions and classes for data visualization.</p>"},{"location":"python/api/","title":"Python API Reference","text":"<p>Module for performing neighborhood analysis.</p> <p>Module for pre-processing to generate LandscapeFiles from ST data.</p> <p>Module for visualization</p>"},{"location":"python/api/#celldega.nbhd.alpha_shape_cell_clusters","title":"<code>alpha_shape_cell_clusters(meta_cell, cat='cluster', alphas=[100, 150, 200, 250, 300, 350])</code>","text":"<p>Compute alpha shapes for each cluster in the cell metadata.</p> <p>Parameters: - meta_cell: GeoDataFrame of cell metadata. - cat: Column name in meta_cell containing the cluster labels. - alphas: List of alpha values to compute shapes for.</p> <p>Returns: - GeoDataFrame of alpha shapes.</p> Source code in <code>src/celldega/nbhd/__init__.py</code> <pre><code>def alpha_shape_cell_clusters(meta_cell, cat='cluster', alphas=[100, 150, 200, 250, 300, 350]):\n\n    \"\"\"\n    Compute alpha shapes for each cluster in the cell metadata.\n\n    Parameters:\n    - meta_cell: GeoDataFrame of cell metadata.\n    - cat: Column name in meta_cell containing the cluster labels.\n    - alphas: List of alpha values to compute shapes for.\n\n    Returns:\n    - GeoDataFrame of alpha shapes.\n\n    \"\"\"\n\n    gdf_alpha = gpd.GeoDataFrame()\n\n    for inv_alpha in alphas:\n\n        for inst_cluster in meta_cell[cat].unique():\n\n            inst_clust = meta_cell[meta_cell[cat] == inst_cluster]\n\n            if inst_clust.shape[0]&gt; 3:\n\n                nested_array = inst_clust['geometry'].values\n\n                # Convert to a 2D NumPy array\n                flat_array = np.vstack(nested_array)\n\n                inst_shape = alpha_shape(flat_array, inv_alpha)\n\n                inst_name = inst_cluster + '_' + str(inv_alpha)\n\n                gdf_alpha.loc[inst_name, 'name'] = inst_name\n\n                gdf_alpha.loc[inst_name, 'cat'] = inst_cluster\n\n                gdf_alpha.loc[inst_name, 'geometry'] = inst_shape\n\n                gdf_alpha.loc[inst_name, 'inv_alpha'] = int(inv_alpha)\n\n    gdf_alpha[\"geometry\"] = gdf_alpha[\"geometry\"].apply(lambda geom: _round_coordinates(geom, precision=2))\n\n    gdf_alpha['area'] = gdf_alpha.area\n\n    gdf_alpha = gdf_alpha.loc[gdf_alpha.area.sort_values(ascending=False).index.tolist()]\n\n    return gdf_alpha\n</code></pre>"},{"location":"python/api/#celldega.pre.calc_meta_gene_data","title":"<code>calc_meta_gene_data(cbg)</code>","text":"<p>Calculate gene metadata from the cell-by-gene matrix</p> <p>Parameters:</p> Name Type Description Default <code>cbg</code> <code>DataFrame</code> <p>A sparse DataFrame with genes as columns and barcodes as rows.</p> required <p>Returns:</p> Type Description <p>pandas.DataFrame: A DataFrame with gene metadata including mean, standard deviation, maximum expression, and proportion of non-zero expression.</p> Source code in <code>src/celldega/pre/landscape.py</code> <pre><code>def calc_meta_gene_data(cbg):\n    \"\"\"\n    Calculate gene metadata from the cell-by-gene matrix\n\n    Args:\n        cbg (pandas.DataFrame): A sparse DataFrame with genes as columns and barcodes as rows.\n\n    Returns:\n        pandas.DataFrame: A DataFrame with gene metadata including mean, standard deviation,\n            maximum expression, and proportion of non-zero expression.\n    \"\"\"\n\n    # Helper function to convert to dense if sparse\n    def convert_to_dense(series):\n        \"\"\"\n        Convert a pandas Series to dense format if it's sparse.\n\n        Parameters\n        ----------\n        series : pandas.Series\n\n        Returns\n        -------\n        pandas.Series\n            Dense Series if input was sparse; original Series otherwise.\n        \"\"\"\n        if pd.api.types.is_sparse(series):\n            return series.sparse.to_dense()\n        return series\n\n    # Ensure cbg is a DataFrame\n    if not isinstance(cbg, pd.DataFrame):\n        raise TypeError(\"cbg must be a pandas DataFrame\")\n\n    # Determine if cbg is sparse\n    is_sparse = pd.api.types.is_sparse(cbg)\n\n    if is_sparse:\n        # Ensure cbg has SparseDtype with float and fill_value=0\n        cbg = cbg.astype(pd.SparseDtype(\"float\", fill_value=0))\n        print(\"cbg is a sparse DataFrame. Proceeding with sparse operations.\")\n    else:\n        print(\"cbg is a dense DataFrame. Proceeding with dense operations.\")\n\n    # Calculate mean expression across tiles\n    print(\"Calculating mean expression\")\n    mean_expression = cbg.mean(axis=0)\n\n    # Calculate variance as the average of the squared deviations\n    print(\"Calculating variance\")\n    num_tiles = cbg.shape[1]\n    variance = cbg.apply(\n        lambda x: ((x - mean_expression[x.name]) ** 2).sum() / num_tiles, axis=0\n    )\n    std_deviation = np.sqrt(variance)\n\n    # Calculate maximum expression\n    max_expression = cbg.max(axis=0)\n\n    # Calculate proportion of tiles with non-zero expression\n    proportion_nonzero = (cbg != 0).sum(axis=0) / len(cbg)\n\n    # Create a DataFrame to hold all these metrics\n    meta_gene = pd.DataFrame(\n        {\n            \"mean\": mean_expression.sparse.to_dense(),\n            \"std\": std_deviation,\n            \"max\": max_expression.sparse.to_dense(),\n            \"non-zero\": proportion_nonzero.sparse.to_dense(),\n        }\n\n    )\n\n    meta_gene_clean = pd.DataFrame(meta_gene.values, index=meta_gene.index.tolist(), columns=meta_gene.columns)\n\n    return meta_gene_clean\n</code></pre>"},{"location":"python/api/#celldega.pre.convert_long_id_to_short","title":"<code>convert_long_id_to_short(df)</code>","text":"<p>Converts a column of long integer cell IDs in a DataFrame to a shorter, hash-based representation.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The DataFrame containing the EntityID.</p> required <p>Returns:     pd.DataFrame: The original DataFrame with an additional column named <code>cell_id</code>                   containing the shortened cell IDs.</p> <p>The function applies a SHA-256 hash to each cell ID, encodes the hash using base64, and truncates it to create a shorter identifier that is added as a new column to the DataFrame.</p> Source code in <code>src/celldega/pre/__init__.py</code> <pre><code>def convert_long_id_to_short(df):\n    \"\"\"\n    Converts a column of long integer cell IDs in a DataFrame to a shorter, hash-based representation.\n\n    Args:\n        df (pd.DataFrame): The DataFrame containing the EntityID.\n    Returns:\n        pd.DataFrame: The original DataFrame with an additional column named `cell_id`\n                      containing the shortened cell IDs.\n\n    The function applies a SHA-256 hash to each cell ID, encodes the hash using base64, and truncates\n    it to create a shorter identifier that is added as a new column to the DataFrame.\n    \"\"\"\n    # Function to hash and encode the cell ID\n    def hash_and_shorten_id(cell_id):\n        # Create a hash of the cell ID\n        cell_id_bytes = str(cell_id).encode('utf-8')\n        hash_object = hashlib.sha256(cell_id_bytes)\n        hash_digest = hash_object.digest()\n\n        # Encode the hash to a base64 string to mix letters and numbers, truncate to 9 characters\n        short_id = base64.urlsafe_b64encode(hash_digest).decode('utf-8')[:9]\n        return short_id\n\n    # Apply the hash_and_shorten_id function to each cell ID in the specified column\n    df['cell_id'] = df['EntityID'].apply(hash_and_shorten_id)\n\n    return df\n</code></pre>"},{"location":"python/api/#celldega.pre.convert_to_jpeg","title":"<code>convert_to_jpeg(image_path, quality=80)</code>","text":"<p>Convert a TIFF image to a JPEG image with a quality of score</p>"},{"location":"python/api/#celldega.pre.convert_to_jpeg--parameters","title":"Parameters","text":"<p>image_path : str     Path to the image file quality : int (default=80)     Quality score for the JPEG image</p>"},{"location":"python/api/#celldega.pre.convert_to_jpeg--returns","title":"Returns","text":"<p>new_image_path : str     Path to the JPEG image file</p> Source code in <code>src/celldega/pre/__init__.py</code> <pre><code>def convert_to_jpeg(image_path, quality=80):\n    \"\"\"\n    Convert a TIFF image to a JPEG image with a quality of score\n\n    Parameters\n    ----------\n    image_path : str\n        Path to the image file\n    quality : int (default=80)\n        Quality score for the JPEG image\n\n    Returns\n    -------\n    new_image_path : str\n        Path to the JPEG image file\n\n    \"\"\"\n\n    # Load the TIFF image\n    image = pyvips.Image.new_from_file(image_path, access=\"sequential\")\n\n    # Save the image as a JPEG with a quality of 80\n    new_image_path = image_path.replace(\".tif\", \".jpeg\")\n    image.jpegsave(new_image_path, Q=quality)\n\n    return new_image_path\n</code></pre>"},{"location":"python/api/#celldega.pre.convert_to_png","title":"<code>convert_to_png(image_path)</code>","text":"<p>Convert a TIFF image to a JPEG image with a quality of score</p>"},{"location":"python/api/#celldega.pre.convert_to_png--parameters","title":"Parameters","text":"<p>image_path : str     Path to the image file quality : int (default=80)     Quality score for the JPEG image</p>"},{"location":"python/api/#celldega.pre.convert_to_png--returns","title":"Returns","text":"<p>new_image_path : str     Path to the JPEG image file</p> Source code in <code>src/celldega/pre/__init__.py</code> <pre><code>def convert_to_png(image_path):\n    \"\"\"\n    Convert a TIFF image to a JPEG image with a quality of score\n\n    Parameters\n    ----------\n    image_path : str\n        Path to the image file\n    quality : int (default=80)\n        Quality score for the JPEG image\n\n    Returns\n    -------\n    new_image_path : str\n        Path to the JPEG image file\n\n    \"\"\"\n\n    # Load the TIFF image\n    image = pyvips.Image.new_from_file(image_path, access=\"sequential\")\n\n    # Save the image as a JPEG with a quality of 80\n    new_image_path = image_path.replace(\".tif\", \".png\")\n    image.pngsave(new_image_path)\n\n    return new_image_path\n</code></pre>"},{"location":"python/api/#celldega.pre.convert_to_webp","title":"<code>convert_to_webp(image_path, quality=100)</code>","text":"<p>Convert a TIFF image to a WEBP image with a specified quality score.</p>"},{"location":"python/api/#celldega.pre.convert_to_webp--parameters","title":"Parameters","text":"<p>image_path : str     Path to the image file quality : int (default=100)     Quality score for the WEBP image (higher is better quality)</p>"},{"location":"python/api/#celldega.pre.convert_to_webp--returns","title":"Returns","text":"<p>new_image_path : str     Path to the WEBP image file</p> Source code in <code>src/celldega/pre/__init__.py</code> <pre><code>def convert_to_webp(image_path, quality=100):\n    \"\"\"\n    Convert a TIFF image to a WEBP image with a specified quality score.\n\n    Parameters\n    ----------\n    image_path : str\n        Path to the image file\n    quality : int (default=100)\n        Quality score for the WEBP image (higher is better quality)\n\n    Returns\n    -------\n    new_image_path : str\n        Path to the WEBP image file\n    \"\"\"\n    # Load the TIFF image\n    image = pyvips.Image.new_from_file(image_path, access=\"sequential\")\n\n    # Save the image as a WEBP with specified quality\n    new_image_path = image_path.replace(\".tif\", \".webp\")\n    image.webpsave(new_image_path, Q=quality)\n\n    return new_image_path\n</code></pre>"},{"location":"python/api/#celldega.pre.get_max_zoom_level","title":"<code>get_max_zoom_level(path_image_pyramid)</code>","text":"<p>Returns the maximum zoom level based on the highest-numbered directory in the specified path_image_pyramid.</p> <p>Parameters:</p> Name Type Description Default <code>path_image_pyramid</code> <code>str</code> <p>The path to the directory containing zoom level directories.</p> required <p>Returns:</p> Name Type Description <code>max_pyramid_zoom</code> <code>int</code> <p>The maximum zoom level.</p> Source code in <code>src/celldega/pre/__init__.py</code> <pre><code>def get_max_zoom_level(path_image_pyramid):\n    \"\"\"\n    Returns the maximum zoom level based on the highest-numbered directory\n    in the specified path_image_pyramid.\n\n    Parameters:\n        path_image_pyramid (str): The path to the directory containing zoom level directories.\n\n    Returns:\n        max_pyramid_zoom (int): The maximum zoom level.\n    \"\"\"\n    # List all entries in the path_image_pyramid that are directories and can be converted to integers\n    zoom_levels = [\n        entry\n        for entry in os.listdir(path_image_pyramid)\n        if os.path.isdir(os.path.join(path_image_pyramid, entry)) and entry.isdigit()\n    ]\n\n    # Convert to integer and find the maximum value\n    max_pyramid_zoom = max(map(int, zoom_levels)) if zoom_levels else None\n\n    return max_pyramid_zoom\n</code></pre>"},{"location":"python/api/#celldega.pre.make_cell_boundary_tiles","title":"<code>make_cell_boundary_tiles(technology, path_cell_boundaries, path_meta_cell_micron, path_transformation_matrix, path_output, coarse_tile_factor=20, tile_size=250, tile_bounds=None, image_scale=1, max_workers=8)</code>","text":"<p>Processes cell boundary data and divides it into spatial tiles based on the provided technology. Reads cell boundary data, applies affine transformations, and divides the data into coarse and fine tiles. The resulting tiles are saved as Parquet files, each containing the geometries of cells in that tile.</p>"},{"location":"python/api/#celldega.pre.make_cell_boundary_tiles--parameters","title":"Parameters","text":"<p>technology : str     The technology used to generate the cell boundary data, e.g., \"MERSCOPE\", \"Xenium\", or \"custom\". path_cell_boundaries : str     Path to the file containing the cell boundaries (Parquet format). path_meta_cell_micron : str     Path to the file containing cell metadata (CSV format). path_transformation_matrix : str     Path to the file containing the transformation matrix (CSV format). path_output : str     Directory path where the output files (Parquet files) for each tile will be saved. coarse_tile_factor  : int, optional, default=20.     scaling factor of each coarse-grain tile comparing to the fine tile size. tile_size : int, optional, default=500     Size of each fine-grain tile in microns. tile_bounds : dict, optional     Dictionary containing the minimum and maximum bounds for x and y coordinates. image_scale : float, optional, default=1     Scale factor to apply to the geometry data. max_workers : int, optional, default=8     Maximum number of parallel workers for processing tiles.</p>"},{"location":"python/api/#celldega.pre.make_cell_boundary_tiles--returns","title":"Returns","text":"<p>None</p> Source code in <code>src/celldega/pre/boundary_tile.py</code> <pre><code>def make_cell_boundary_tiles(\n    technology,\n    path_cell_boundaries,\n    path_meta_cell_micron,\n    path_transformation_matrix,\n    path_output,\n    coarse_tile_factor=20,\n    tile_size=250,\n    tile_bounds=None,\n    image_scale=1,\n    max_workers=8\n):\n\n\n    \"\"\"\n    Processes cell boundary data and divides it into spatial tiles based on the provided technology.\n    Reads cell boundary data, applies affine transformations, and divides the data into coarse and fine tiles.\n    The resulting tiles are saved as Parquet files, each containing the geometries of cells in that tile.\n\n    Parameters\n    ----------\n    technology : str\n        The technology used to generate the cell boundary data, e.g., \"MERSCOPE\", \"Xenium\", or \"custom\".\n    path_cell_boundaries : str\n        Path to the file containing the cell boundaries (Parquet format).\n    path_meta_cell_micron : str\n        Path to the file containing cell metadata (CSV format).\n    path_transformation_matrix : str\n        Path to the file containing the transformation matrix (CSV format).\n    path_output : str\n        Directory path where the output files (Parquet files) for each tile will be saved.\n    coarse_tile_factor  : int, optional, default=20.\n        scaling factor of each coarse-grain tile comparing to the fine tile size.\n    tile_size : int, optional, default=500\n        Size of each fine-grain tile in microns.\n    tile_bounds : dict, optional\n        Dictionary containing the minimum and maximum bounds for x and y coordinates.\n    image_scale : float, optional, default=1\n        Scale factor to apply to the geometry data.\n    max_workers : int, optional, default=8\n        Maximum number of parallel workers for processing tiles.\n\n    Returns\n    -------\n    None\n    \"\"\"\n\n    def numpy_affine_transform(coords, matrix):\n        \"\"\"Apply affine transformation to numpy coordinates.\"\"\"\n        # Homogeneous coordinates for affine transformation\n        coords = np.hstack([coords, np.ones((coords.shape[0], 1))])\n        transformed_coords = coords @ matrix.T\n        return transformed_coords[:, :2]  # Drop the homogeneous coordinate\n\n    def batch_transform_geometries(geometries, transformation_matrix, scale):\n        \"\"\"\n        Batch transform geometries using numpy for optimized performance.\n        \"\"\"\n        # Extract affine transformation parameters into a 3x3 matrix for numpy\n        affine_matrix = np.array([\n            [transformation_matrix[0, 0], transformation_matrix[0, 1], transformation_matrix[0, 2]],\n            [transformation_matrix[1, 0], transformation_matrix[1, 1], transformation_matrix[1, 2]],\n            [0, 0, 1]\n        ])\n\n        transformed_geometries = []\n\n        for polygon in geometries:\n            # Extract coordinates and transform them\n            if isinstance(polygon, MultiPolygon):\n                polygon = next(polygon.geoms)  # Use the first geometry\n\n            # Transform the exterior of the polygon\n            exterior_coords = np.array(polygon.exterior.coords)\n\n            # Apply the affine transformation and scale\n            transformed_coords = numpy_affine_transform(exterior_coords, affine_matrix) / scale\n\n            # Append the result to the transformed_geometries list\n            transformed_geometries.append([transformed_coords.tolist()])\n\n        return transformed_geometries\n\n\n    def filter_and_save_fine_boundary(coarse_tile, fine_i, fine_j, fine_tile_x_min, fine_tile_x_max, fine_tile_y_min, fine_tile_y_max, path_output):\n        cell_ids = coarse_tile.index.values\n\n        tile_filter = (\n            (coarse_tile[\"center_x\"] &gt;= fine_tile_x_min) &amp; (coarse_tile[\"center_x\"] &lt; fine_tile_x_max) &amp;\n            (coarse_tile[\"center_y\"] &gt;= fine_tile_y_min) &amp; (coarse_tile[\"center_y\"] &lt; fine_tile_y_max)\n        )\n        filtered_indices = np.where(tile_filter)[0]\n\n        keep_cells = cell_ids[filtered_indices]\n        fine_tile_cells = coarse_tile.loc[keep_cells, [\"GEOMETRY\"]]\n        fine_tile_cells = fine_tile_cells.assign(name=fine_tile_cells.index)\n\n        if not fine_tile_cells.empty:\n            filename = f\"{path_output}/cell_tile_{fine_i}_{fine_j}.parquet\"\n            fine_tile_cells.to_parquet(filename)\n\n    def process_fine_boundaries(coarse_tile, i, j, coarse_tile_x_min, coarse_tile_x_max, coarse_tile_y_min, coarse_tile_y_max, tile_size, path_output, x_min, y_min, n_fine_tiles_x, n_fine_tiles_y):\n        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n            futures = []\n            for fine_i in range(n_fine_tiles_x):\n                fine_tile_x_min = x_min + fine_i * tile_size\n                fine_tile_x_max = fine_tile_x_min + tile_size\n\n                if not (fine_tile_x_min &gt;= coarse_tile_x_min and fine_tile_x_max &lt;= coarse_tile_x_max):\n                    continue\n\n                for fine_j in range(n_fine_tiles_y):\n                    fine_tile_y_min = y_min + fine_j * tile_size\n                    fine_tile_y_max = fine_tile_y_min + tile_size\n\n                    if not (fine_tile_y_min &gt;= coarse_tile_y_min and fine_tile_y_max &lt;= coarse_tile_y_max):\n                        continue\n\n                    futures.append(executor.submit(\n                        filter_and_save_fine_boundary, coarse_tile, fine_i, fine_j, fine_tile_x_min, fine_tile_x_max, fine_tile_y_min, fine_tile_y_max, path_output\n                    ))\n\n            for future in futures:\n                future.result()\n\n    tile_size_x = tile_size\n    tile_size_y = tile_size\n\n    transformation_matrix = pd.read_csv(path_transformation_matrix, header=None, sep=\" \").values\n\n    # Load cell boundary data based on the technology\n    if technology == \"MERSCOPE\":\n        df_meta = pd.read_parquet(f\"{path_output.replace('cell_segmentation','cell_metadata.parquet')}\")\n        entity_to_cell_id_dict = pd.Series(df_meta.index.values, index=df_meta.EntityID).to_dict()\n        cells_orig = gpd.read_parquet(path_cell_boundaries)\n        cells_orig['cell_id'] = cells_orig['EntityID'].map(entity_to_cell_id_dict)\n        cells_orig = cells_orig[cells_orig[\"ZIndex\"] == 1]\n\n        # Correct cell_id issues with meta_cell\n        meta_cell = pd.read_csv(path_meta_cell_micron)\n        meta_cell['cell_id'] = meta_cell['EntityID'].map(entity_to_cell_id_dict)\n        cells_orig.index = meta_cell[meta_cell[\"cell_id\"].isin(cells_orig['cell_id'])].index\n\n        # Correct 'MultiPolygon' to 'Polygon'\n        cells_orig[\"geometry\"] = cells_orig[\"Geometry\"].apply(\n            lambda x: list(x.geoms)[0] if isinstance(x, MultiPolygon) else x\n        )\n\n        cells_orig.set_index('cell_id', inplace=True)\n\n    elif technology == \"Xenium\":\n        xenium_cells = pd.read_parquet(path_cell_boundaries)\n        grouped = xenium_cells.groupby(\"cell_id\")[[\"vertex_x\", \"vertex_y\"]].agg(lambda x: x.tolist())\n        grouped[\"geometry\"] = grouped.apply(lambda row: Polygon(zip(row[\"vertex_x\"], row[\"vertex_y\"])), axis=1)\n        cells_orig = gpd.GeoDataFrame(grouped, geometry=\"geometry\")[[\"geometry\"]]\n\n    elif technology == \"custom\":\n        cells_orig = gpd.read_parquet(path_cell_boundaries)\n\n    # Transform geometries\n    cells_orig[\"GEOMETRY\"] = batch_transform_geometries(cells_orig[\"geometry\"], transformation_matrix, image_scale)\n\n    # Convert transformed geometries to polygons and calculate centroids\n    cells_orig[\"polygon\"] = cells_orig[\"GEOMETRY\"].apply(lambda x: Polygon(x[0]))\n    gdf_cells = gpd.GeoDataFrame(geometry=cells_orig[\"polygon\"])\n    gdf_cells[\"center_x\"] = gdf_cells.geometry.centroid.x\n    gdf_cells[\"center_y\"] = gdf_cells.geometry.centroid.y\n    gdf_cells[\"GEOMETRY\"] = cells_orig[\"GEOMETRY\"]\n\n    # Ensure the output directory exists\n    if not os.path.exists(path_output):\n        os.makedirs(path_output)\n\n    # Calculate tile bounds and fine/coarse tiles\n    x_min, x_max = tile_bounds[\"x_min\"], tile_bounds[\"x_max\"]\n    y_min, y_max = tile_bounds[\"y_min\"], tile_bounds[\"y_max\"]\n    n_fine_tiles_x = int(np.ceil((x_max - x_min) / tile_size))\n    n_fine_tiles_y = int(np.ceil((y_max - y_min) / tile_size))\n    n_coarse_tiles_x = int(np.ceil((x_max - x_min) / (coarse_tile_factor * tile_size)))\n    n_coarse_tiles_y = int(np.ceil((y_max - y_min) / (coarse_tile_factor * tile_size)))\n\n    # Process coarse tiles in parallel\n    for i in tqdm(range(n_coarse_tiles_x), desc=\"Processing coarse tiles\"):\n        coarse_tile_x_min = x_min + i * (coarse_tile_factor * tile_size)\n        coarse_tile_x_max = coarse_tile_x_min + (coarse_tile_factor * tile_size)\n\n        for j in range(n_coarse_tiles_y):\n            coarse_tile_y_min = y_min + j * (coarse_tile_factor * tile_size)\n            coarse_tile_y_max = coarse_tile_y_min + (coarse_tile_factor * tile_size)\n\n            coarse_tile = gdf_cells[\n                (gdf_cells[\"center_x\"] &gt;= coarse_tile_x_min) &amp; (gdf_cells[\"center_x\"] &lt; coarse_tile_x_max) &amp;\n                (gdf_cells[\"center_y\"] &gt;= coarse_tile_y_min) &amp; (gdf_cells[\"center_y\"] &lt; coarse_tile_y_max)\n            ]\n            if not coarse_tile.empty:\n                process_fine_boundaries(coarse_tile, i, j, coarse_tile_x_min, coarse_tile_x_max, coarse_tile_y_min, coarse_tile_y_max, tile_size, path_output, x_min, y_min, n_fine_tiles_x, n_fine_tiles_y)\n</code></pre>"},{"location":"python/api/#celldega.pre.make_deepzoom_pyramid","title":"<code>make_deepzoom_pyramid(image_path, output_path, pyramid_name, tile_size=512, overlap=0, suffix='.jpeg')</code>","text":"<p>Create a DeepZoom image pyramid from a JPEG image</p>"},{"location":"python/api/#celldega.pre.make_deepzoom_pyramid--parameters","title":"Parameters","text":"<p>image_path : str     Path to the JPEG image file tile_size : int (default=512)     Tile size for the DeepZoom pyramid overlap : int (default=0)     Overlap size for the DeepZoom pyramid suffix : str (default='jpeg')     Suffix for the DeepZoom pyramid tiles</p>"},{"location":"python/api/#celldega.pre.make_deepzoom_pyramid--returns","title":"Returns","text":"<p>None</p> Source code in <code>src/celldega/pre/__init__.py</code> <pre><code>def make_deepzoom_pyramid(\n    image_path, output_path, pyramid_name, tile_size=512, overlap=0, suffix=\".jpeg\"\n):\n    \"\"\"\n    Create a DeepZoom image pyramid from a JPEG image\n\n    Parameters\n    ----------\n    image_path : str\n        Path to the JPEG image file\n    tile_size : int (default=512)\n        Tile size for the DeepZoom pyramid\n    overlap : int (default=0)\n        Overlap size for the DeepZoom pyramid\n    suffix : str (default='jpeg')\n        Suffix for the DeepZoom pyramid tiles\n\n    Returns\n    -------\n    None\n\n    \"\"\"\n\n    # Define the output path\n    output_path = Path(output_path)\n\n    # Load the JPEG image\n    image = pyvips.Image.new_from_file(image_path, access=\"sequential\")\n\n    # check if the output path exists and create it if it does not\n    output_path.mkdir(parents=True, exist_ok=True)\n\n    # append the pyramid name to the output path\n    output_path = output_path / pyramid_name\n\n    # Save the image as a DeepZoom image pyramid\n    image.dzsave(output_path, tile_size=tile_size, overlap=overlap, suffix=suffix)\n</code></pre>"},{"location":"python/api/#celldega.pre.make_meta_cell_image_coord","title":"<code>make_meta_cell_image_coord(technology, path_transformation_matrix, path_meta_cell_micron, path_meta_cell_image, image_scale)</code>","text":"<p>Apply an affine transformation to the cell coordinates in microns and save the transformed coordinates in pixels</p>"},{"location":"python/api/#celldega.pre.make_meta_cell_image_coord--parameters","title":"Parameters","text":"<p>technology : str     The technology used to generate the data, Xenium and MERSCOPE are supported. path_transformation_matrix : str     Path to the transformation matrix file path_meta_cell_micron : str     Path to the meta cell file with coordinates in microns path_meta_cell_image : str     Path to save the meta cell file with coordinates in pixels</p>"},{"location":"python/api/#celldega.pre.make_meta_cell_image_coord--returns","title":"Returns","text":"<p>None</p>"},{"location":"python/api/#celldega.pre.make_meta_cell_image_coord--examples","title":"Examples","text":"<p>make_meta_cell_image_coord( ...     technology='Xenium', ...     path_transformation_matrix='data/transformation_matrix.txt', ...     path_meta_cell_micron='data/meta_cell_micron.csv', ...     path_meta_cell_image='data/meta_cell_image.parquet' ... )</p> Source code in <code>src/celldega/pre/__init__.py</code> <pre><code>def make_meta_cell_image_coord(\n    technology,\n    path_transformation_matrix,\n    path_meta_cell_micron,\n    path_meta_cell_image,\n    image_scale\n):\n    \"\"\"\n    Apply an affine transformation to the cell coordinates in microns and save\n    the transformed coordinates in pixels\n\n    Parameters\n    ----------\n    technology : str\n        The technology used to generate the data, Xenium and MERSCOPE are supported.\n    path_transformation_matrix : str\n        Path to the transformation matrix file\n    path_meta_cell_micron : str\n        Path to the meta cell file with coordinates in microns\n    path_meta_cell_image : str\n        Path to save the meta cell file with coordinates in pixels\n\n    Returns\n    -------\n    None\n\n    Examples\n    --------\n    &gt;&gt;&gt; make_meta_cell_image_coord(\n    ...     technology='Xenium',\n    ...     path_transformation_matrix='data/transformation_matrix.txt',\n    ...     path_meta_cell_micron='data/meta_cell_micron.csv',\n    ...     path_meta_cell_image='data/meta_cell_image.parquet'\n    ... )\n\n    \"\"\"\n\n    transformation_matrix = pd.read_csv(\n        path_transformation_matrix, header=None, sep=\" \"\n    ).values\n\n    if technology == \"MERSCOPE\":\n        meta_cell = pd.read_csv(path_meta_cell_micron, usecols=[\"EntityID\", \"center_x\", \"center_y\"])\n        meta_cell = convert_long_id_to_short(meta_cell)\n        meta_cell[\"name\"] =  meta_cell[\"cell_id\"]\n        meta_cell = meta_cell.set_index('cell_id')\n    elif technology == \"Xenium\":\n        usecols = [\"cell_id\", \"x_centroid\", \"y_centroid\"]\n        meta_cell = pd.read_csv(path_meta_cell_micron, index_col=0, usecols=usecols)\n        meta_cell.columns = [\"center_x\", \"center_y\"]\n        meta_cell[\"name\"] = pd.Series(meta_cell.index, index=meta_cell.index)\n\n    # Adding a ones column to accommodate for affine transformation\n    meta_cell[\"ones\"] = 1\n\n    # Preparing the data for matrix multiplication\n    points = meta_cell[[\"center_x\", \"center_y\", \"ones\"]].values\n\n    # Applying the transformation matrix\n    transformed_points = np.dot(transformation_matrix, points.T).T\n\n    # Updating the DataFrame with transformed coordinates\n    meta_cell[\"center_x\"] = transformed_points[:, 0]\n    meta_cell[\"center_y\"] = transformed_points[:, 1]\n\n    # Dropping the ones column as it's no longer needed\n    meta_cell.drop(columns=[\"ones\"], inplace=True)\n\n    meta_cell[\"center_x\"] = meta_cell[\"center_x\"] / image_scale\n    meta_cell[\"center_y\"] = meta_cell[\"center_y\"] / image_scale\n\n    meta_cell[\"geometry\"] = meta_cell.apply(\n        lambda row: [row[\"center_x\"], row[\"center_y\"]], axis=1\n    )\n\n    if technology == \"MERSCOPE\":\n        meta_cell = meta_cell[[\"name\", \"geometry\", \"EntityID\"]]\n    else:\n        meta_cell = meta_cell[[\"name\", \"geometry\"]]\n\n\n    meta_cell.to_parquet(path_meta_cell_image)\n</code></pre>"},{"location":"python/api/#celldega.pre.make_meta_gene","title":"<code>make_meta_gene(technology, path_cbg, path_output)</code>","text":"<p>Create a DataFrame with genes and their assigned colors</p>"},{"location":"python/api/#celldega.pre.make_meta_gene--parameters","title":"Parameters","text":"<p>technology : str     The technology used to generate the data, Xenium and MERSCOPE are supported. path_cbg : str     Path to the cell-by-gene matrix data (the data format can vary based on technology) path_output : str     Path to save the meta gene file</p>"},{"location":"python/api/#celldega.pre.make_meta_gene--returns","title":"Returns","text":"<p>None</p>"},{"location":"python/api/#celldega.pre.make_meta_gene--examples","title":"Examples","text":"<p>make_meta_gene( ...     technology='Xenium', ...     path_cbg='data/', ...     path_output='data/meta_gene.parquet' ... )</p> Source code in <code>src/celldega/pre/__init__.py</code> <pre><code>def make_meta_gene(technology, path_cbg, path_output):\n    \"\"\"\n    Create a DataFrame with genes and their assigned colors\n\n    Parameters\n    ----------\n    technology : str\n        The technology used to generate the data, Xenium and MERSCOPE are supported.\n    path_cbg : str\n        Path to the cell-by-gene matrix data (the data format can vary based on technology)\n    path_output : str\n        Path to save the meta gene file\n\n    Returns\n    -------\n    None\n\n    Examples\n    --------\n    &gt;&gt;&gt; make_meta_gene(\n    ...     technology='Xenium',\n    ...     path_cbg='data/',\n    ...     path_output='data/meta_gene.parquet'\n    ... )\n    \"\"\"\n\n    if technology == \"MERSCOPE\":\n        cbg = pd.read_csv(path_cbg, index_col=0)\n        genes = cbg.columns.tolist()\n    elif technology == \"Xenium\":\n        # genes = pd.read_csv(path_cbg + 'features.tsv.gz', sep='\\t', header=None)[1].values.tolist()\n        cbg = read_cbg_mtx(path_cbg)\n        genes = cbg.columns.tolist()\n\n    # Get all categorical color palettes from Matplotlib and flatten them into a single list of colors\n    palettes = [plt.get_cmap(name).colors for name in plt.colormaps() if \"tab\" in name]\n    flat_colors = [color for palette in palettes for color in palette]\n\n    # Convert RGB tuples to hex codes\n    flat_colors_hex = [to_hex(color) for color in flat_colors]\n\n    # Use modular arithmetic to assign a color to each gene, white for genes with \"Blank\"\n    colors = [\n        flat_colors_hex[i % len(flat_colors_hex)] if \"Blank\" not in gene else \"#FFFFFF\"\n        for i, gene in enumerate(genes)\n    ]\n\n    # Create a DataFrame with genes and their assigned colors\n    ser_color = pd.Series(colors, index=genes)\n\n    # calculate gene expression metadata\n    meta_gene = calc_meta_gene_data(cbg)\n    meta_gene['color'] = ser_color\n\n    # Identify sparse columns\n    sparse_cols = [col for col in meta_gene.columns if pd.api.types.is_sparse(meta_gene[col])]\n\n    # Convert sparse columns to dense\n    for col in sparse_cols:\n        meta_gene[col] = meta_gene[col].sparse.to_dense()\n\n    meta_gene.to_parquet(path_output)\n</code></pre>"},{"location":"python/api/#celldega.pre.make_trx_tiles","title":"<code>make_trx_tiles(technology, path_trx, path_transformation_matrix, path_trx_tiles, coarse_tile_factor=10, tile_size=250, chunk_size=1000000, verbose=False, image_scale=1, max_workers=8)</code>","text":"<p>Processes transcript data by dividing it into coarse-grain and fine-grain tiles, applying transformations, and saving the results in a parallelized manner.</p>"},{"location":"python/api/#celldega.pre.make_trx_tiles--parameters","title":"Parameters","text":"<p>technology : str     The technology used for generating the transcript data (e.g., \"MERSCOPE\" or \"Xenium\"). path_trx : str     Path to the file containing the transcript data. path_transformation_matrix : str     Path to the file containing the transformation matrix (CSV file). path_trx_tiles : str     Directory path where the output files (Parquet files) for each tile will be saved. coarse_tile_factor : int, optional     Scaling factor of each coarse-grain tile comparing to the fine tile size. tile_size : int, optional     Size of each fine-grain tile in microns (default is 250). chunk_size : int, optional     Number of rows to process per chunk for memory efficiency (default is 1000000). verbose : bool, optional     Flag to enable verbose output (default is False). image_scale : float, optional     Scale factor to apply to the transcript coordinates (default is 0.5). max_workers : int, optional     Maximum number of parallel workers for processing tiles (default is 8).</p>"},{"location":"python/api/#celldega.pre.make_trx_tiles--returns","title":"Returns","text":"<p>dict     A dictionary containing the bounds of the processed data in both x and y directions.</p> Source code in <code>src/celldega/pre/trx_tile.py</code> <pre><code>def make_trx_tiles(\n    technology,\n    path_trx,\n    path_transformation_matrix,\n    path_trx_tiles,\n    coarse_tile_factor=10,\n    tile_size=250,\n    chunk_size=1000000,\n    verbose=False,\n    image_scale=1,\n    max_workers=8\n):\n    \"\"\"\n    Processes transcript data by dividing it into coarse-grain and fine-grain tiles,\n    applying transformations, and saving the results in a parallelized manner.\n\n    Parameters\n    ----------\n    technology : str\n        The technology used for generating the transcript data (e.g., \"MERSCOPE\" or \"Xenium\").\n    path_trx : str\n        Path to the file containing the transcript data.\n    path_transformation_matrix : str\n        Path to the file containing the transformation matrix (CSV file).\n    path_trx_tiles : str\n        Directory path where the output files (Parquet files) for each tile will be saved.\n    coarse_tile_factor : int, optional\n        Scaling factor of each coarse-grain tile comparing to the fine tile size.\n    tile_size : int, optional\n        Size of each fine-grain tile in microns (default is 250).\n    chunk_size : int, optional\n        Number of rows to process per chunk for memory efficiency (default is 1000000).\n    verbose : bool, optional\n        Flag to enable verbose output (default is False).\n    image_scale : float, optional\n        Scale factor to apply to the transcript coordinates (default is 0.5).\n    max_workers : int, optional\n        Maximum number of parallel workers for processing tiles (default is 8).\n\n    Returns\n    -------\n    dict\n        A dictionary containing the bounds of the processed data in both x and y directions.\n    \"\"\"\n\n    def process_coarse_tile(trx, i, j, coarse_tile_x_min, coarse_tile_x_max, coarse_tile_y_min, coarse_tile_y_max, tile_size, path_trx_tiles, x_min, y_min, n_fine_tiles_x, n_fine_tiles_y, max_workers):\n        # Filter the entire dataset for the current coarse tile\n        coarse_tile = trx.filter(\n            (pl.col(\"transformed_x\") &gt;= coarse_tile_x_min) &amp; (pl.col(\"transformed_x\") &lt; coarse_tile_x_max) &amp;\n            (pl.col(\"transformed_y\") &gt;= coarse_tile_y_min) &amp; (pl.col(\"transformed_y\") &lt; coarse_tile_y_max)\n        )\n\n        if not coarse_tile.is_empty():\n            # Now process fine tiles using global fine tile indices\n            process_fine_tiles(coarse_tile, i, j, coarse_tile_x_min, coarse_tile_x_max, coarse_tile_y_min, coarse_tile_y_max, tile_size, path_trx_tiles, x_min, y_min, n_fine_tiles_x, n_fine_tiles_y, max_workers)   \n\n\n    def process_fine_tiles(coarse_tile, coarse_i, coarse_j, coarse_tile_x_min, coarse_tile_x_max, coarse_tile_y_min, coarse_tile_y_max, tile_size, path_trx_tiles, x_min, y_min, n_fine_tiles_x, n_fine_tiles_y, max_workers=8):\n\n        # Use ThreadPoolExecutor for parallel processing of fine-grain tiles within the coarse tile\n        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n            futures = []\n\n            # Iterate over fine-grain tiles within the global bounds\n            for fine_i in range(n_fine_tiles_x):\n                fine_tile_x_min = x_min + fine_i * tile_size\n                fine_tile_x_max = fine_tile_x_min + tile_size\n\n                # Process only if the fine tile falls within the current coarse tile's bounds\n                if not (fine_tile_x_min &gt;= coarse_tile_x_min and fine_tile_x_max &lt;= coarse_tile_x_max):\n                    continue\n\n                for fine_j in range(n_fine_tiles_y):\n                    fine_tile_y_min = y_min + fine_j * tile_size\n                    fine_tile_y_max = fine_tile_y_min + tile_size\n\n                    # Process only if the fine tile falls within the current coarse tile's bounds\n                    if not (fine_tile_y_min &gt;= coarse_tile_y_min and fine_tile_y_max &lt;= coarse_tile_y_max):\n                        continue\n\n                    # Submit the task for each fine tile to process in parallel\n                    futures.append(executor.submit(\n                        filter_and_save_fine_tile, coarse_tile, coarse_i, coarse_j, fine_i, fine_j, \n                        fine_tile_x_min, fine_tile_x_max, fine_tile_y_min, fine_tile_y_max, path_trx_tiles\n                    ))\n\n            # Wait for all futures to complete\n            for future in concurrent.futures.as_completed(futures):\n                future.result()  # Raise exceptions if any occurred during execution\n\n\n    def filter_and_save_fine_tile(coarse_tile, coarse_i, coarse_j, fine_i, fine_j, fine_tile_x_min, fine_tile_x_max, fine_tile_y_min, fine_tile_y_max, path_trx_tiles):\n\n        # Filter the coarse tile for the current fine tile's boundaries\n        fine_tile_trx = coarse_tile.filter(\n            (pl.col(\"transformed_x\") &gt;= fine_tile_x_min) &amp; (pl.col(\"transformed_x\") &lt; fine_tile_x_max) &amp;\n            (pl.col(\"transformed_y\") &gt;= fine_tile_y_min) &amp; (pl.col(\"transformed_y\") &lt; fine_tile_y_max)\n        )\n\n        if not fine_tile_trx.is_empty():\n            # Add geometry column as a list of [x, y] pairs\n            fine_tile_trx = fine_tile_trx.with_columns(\n                pl.concat_list([pl.col(\"transformed_x\"), pl.col(\"transformed_y\")]).alias(\"geometry\")\n            ).drop(['transformed_x', 'transformed_y'])\n\n            # Define the filename based on fine tile coordinates\n            filename = f\"{path_trx_tiles}/transcripts_tile_{fine_i}_{fine_j}.parquet\"\n\n            # Save the filtered DataFrame to a Parquet file\n            fine_tile_trx.to_pandas().to_parquet(filename)\n\n\n    # Load transformation matrix\n    transformation_matrix = np.loadtxt(path_transformation_matrix)\n\n    # Load the transcript data based on the technology using Polars\n    if technology == \"MERSCOPE\":\n        trx_ini = pl.read_csv(path_trx, columns=[\"gene\", \"global_x\", \"global_y\"])\n        trx_ini = trx_ini.with_columns([\n            pl.col(\"global_x\").alias(\"x\"),\n            pl.col(\"global_y\").alias(\"y\"),\n            pl.col(\"gene\").alias(\"name\")\n        ]).select([\"name\", \"x\", \"y\"])\n\n    elif technology == \"Xenium\":\n        trx_ini = pl.read_parquet(path_trx).select([\n            pl.col(\"feature_name\").alias(\"name\"),\n            pl.col(\"x_location\").alias(\"x\"),\n            pl.col(\"y_location\").alias(\"y\")\n        ])\n\n    # Process the data in chunks and apply transformations\n    all_chunks = []\n\n    for start_row in tqdm(range(0, trx_ini.height, chunk_size), desc=\"Processing chunks\"):\n        chunk = trx_ini.slice(start_row, chunk_size)\n\n        # Apply transformation matrix to the coordinates\n        points = np.hstack([chunk.select([\"x\", \"y\"]).to_numpy(), np.ones((chunk.height, 1))])\n        transformed_points = np.dot(points, transformation_matrix.T)[:, :2]\n\n        # Create new transformed columns and drop original x, y columns\n        transformed_chunk = chunk.with_columns([\n            (pl.Series(transformed_points[:, 0]) * image_scale).round(2).alias(\"transformed_x\"),\n            (pl.Series(transformed_points[:, 1]) * image_scale).round(2).alias(\"transformed_y\")\n        ]).drop([\"x\", \"y\"])\n        all_chunks.append(transformed_chunk)\n\n    # Concatenate all chunks after processing\n    trx = pl.concat(all_chunks)\n\n    # Ensure the output directory exists\n    if not os.path.exists(path_trx_tiles):\n        os.makedirs(path_trx_tiles)\n\n    # Get min and max x, y values\n    x_min, x_max = trx.select([\n        pl.col(\"transformed_x\").min().alias(\"x_min\"),\n        pl.col(\"transformed_x\").max().alias(\"x_max\")\n    ]).row(0)\n\n    y_min, y_max = trx.select([\n        pl.col(\"transformed_y\").min().alias(\"y_min\"),\n        pl.col(\"transformed_y\").max().alias(\"y_max\")\n    ]).row(0)\n\n    # Calculate the number of fine-grain tiles globally\n    n_fine_tiles_x = int(np.ceil((x_max - x_min) / tile_size))\n    n_fine_tiles_y = int(np.ceil((y_max - y_min) / tile_size))\n\n    # Calculate the number of coarse-grain tiles\n    n_coarse_tiles_x = int(np.ceil((x_max - x_min) / (coarse_tile_factor * tile_size)))\n    n_coarse_tiles_y = int(np.ceil((y_max - y_min) / (coarse_tile_factor * tile_size)))\n\n    # Use ThreadPoolExecutor for parallel processing of coarse-grain tiles\n    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n        futures = []\n        for i in range(n_coarse_tiles_x):\n            coarse_tile_x_min = x_min + i * (coarse_tile_factor * tile_size)\n            coarse_tile_x_max = coarse_tile_x_min + (coarse_tile_factor * tile_size)\n\n            for j in range(n_coarse_tiles_y):\n                coarse_tile_y_min = y_min + j * (coarse_tile_factor * tile_size)\n                coarse_tile_y_max = coarse_tile_y_min + (coarse_tile_factor * tile_size)\n\n                # Submit each coarse tile for parallel processing\n                futures.append(executor.submit(\n                    process_coarse_tile, trx, i, j, coarse_tile_x_min, coarse_tile_x_max, coarse_tile_y_min, coarse_tile_y_max, tile_size, path_trx_tiles, x_min, y_min, n_fine_tiles_x, n_fine_tiles_y, max_workers\n                ))\n\n        # Wait for all coarse tiles to complete\n        for future in tqdm(concurrent.futures.as_completed(futures), desc=\"Processing coarse tiles\", unit=\"tile\"):\n            future.result()  # Raise exceptions if any occurred during execution\n\n    # Return the tile bounds\n    tile_bounds = {\n        \"x_min\": x_min,\n        \"x_max\": x_max,\n        \"y_min\": y_min,\n        \"y_max\": y_max,\n    }\n\n    return tile_bounds\n</code></pre>"},{"location":"python/api/#celldega.pre.read_cbg_mtx","title":"<code>read_cbg_mtx(base_path)</code>","text":"<p>Read the cell-by-gene matrix from the mtx files.</p>"},{"location":"python/api/#celldega.pre.read_cbg_mtx--parameters","title":"Parameters","text":"<p>base_path : str     The base path to the directory containing the mtx files.</p>"},{"location":"python/api/#celldega.pre.read_cbg_mtx--returns","title":"Returns","text":"<p>cbg : pandas.DataFrame     A sparse DataFrame with genes as columns and barcodes as rows.</p> Source code in <code>src/celldega/pre/landscape.py</code> <pre><code>def read_cbg_mtx(base_path):\n    \"\"\"\n    Read the cell-by-gene matrix from the mtx files.\n\n    Parameters\n    ----------\n    base_path : str\n        The base path to the directory containing the mtx files.\n\n    Returns\n    -------\n    cbg : pandas.DataFrame\n        A sparse DataFrame with genes as columns and barcodes as rows.\n    \"\"\"\n    print(\"Reading mtx file from \", base_path)\n\n    # File paths\n    barcodes_path = os.path.join(base_path, \"barcodes.tsv.gz\")\n    features_path = os.path.join(base_path, \"features.tsv.gz\")\n    matrix_path = os.path.join(base_path, \"matrix.mtx.gz\")\n\n    # Read barcodes and features\n    barcodes = pd.read_csv(barcodes_path, header=None, compression=\"gzip\")\n    features = pd.read_csv(features_path, header=None, compression=\"gzip\", sep=\"\\t\")\n\n    # Read the gene expression matrix and transpose it\n    # Transpose and convert to CSC format for fast column slicing\n    matrix = mmread(matrix_path).transpose().tocsc()\n\n    # Create a sparse DataFrame with genes as columns and barcodes as rows\n    cbg = pd.DataFrame.sparse.from_spmatrix(\n        matrix, index=barcodes[0], columns=features[1]\n    )\n    cbg = cbg.rename_axis('__index_level_0__', axis='columns')\n\n    return cbg\n</code></pre>"},{"location":"python/api/#celldega.pre.reduce_image_size","title":"<code>reduce_image_size(image_path, scale_image=0.5, path_landscape_files='')</code>","text":""},{"location":"python/api/#celldega.pre.reduce_image_size--parameters","title":"Parameters","text":"<p>image_path : str     Path to the image file scale_image : float (default=0.5)     Scale factor for the image resize</p>"},{"location":"python/api/#celldega.pre.reduce_image_size--returns","title":"Returns","text":"<p>new_image_path : str     Path to the resized image file</p> Source code in <code>src/celldega/pre/__init__.py</code> <pre><code>def reduce_image_size(image_path, scale_image=0.5, path_landscape_files=\"\"):\n    \"\"\"\n\n    Parameters\n    ----------\n    image_path : str\n        Path to the image file\n    scale_image : float (default=0.5)\n        Scale factor for the image resize\n\n    Returns\n    -------\n    new_image_path : str\n        Path to the resized image file\n    \"\"\"\n\n    image = pyvips.Image.new_from_file(image_path, access=\"sequential\")\n\n    resized_image = image.resize(scale_image)\n\n    new_image_name = image_path.split(\"/\")[-1].replace(\".tif\", \"_downsize.tif\")\n    new_image_path = f\"{path_landscape_files}/{new_image_name}\"\n    resized_image.write_to_file(new_image_path)\n\n    return new_image_path\n</code></pre>"},{"location":"python/api/#celldega.pre.save_cbg_gene_parquets","title":"<code>save_cbg_gene_parquets(base_path, cbg, verbose=False)</code>","text":"<p>Save the cell-by-gene matrix as gene-specific Parquet files.</p>"},{"location":"python/api/#celldega.pre.save_cbg_gene_parquets--parameters","title":"Parameters","text":"<p>base_path : str     The base path to the parent directory containing the landscape_files directory. cbg : pandas.DataFrame     A sparse DataFrame with genes as columns and barcodes as rows. verbose : bool, optional     Whether to print progress information, by default False.</p>"},{"location":"python/api/#celldega.pre.save_cbg_gene_parquets--returns","title":"Returns","text":"<p>None</p> Source code in <code>src/celldega/pre/landscape.py</code> <pre><code>def save_cbg_gene_parquets(base_path, cbg, verbose=False):\n    \"\"\"\n    Save the cell-by-gene matrix as gene-specific Parquet files.\n\n    Parameters\n    ----------\n    base_path : str\n        The base path to the parent directory containing the landscape_files directory.\n    cbg : pandas.DataFrame\n        A sparse DataFrame with genes as columns and barcodes as rows.\n    verbose : bool, optional\n        Whether to print progress information, by default False.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    output_dir = os.path.join(base_path, \"cbg\")\n    os.makedirs(output_dir, exist_ok=True)\n\n    for index, gene in enumerate(cbg.columns):\n        if verbose and index % 100 == 0:\n            print(f\"Processing gene {index}: {gene}\")\n\n        # Extract the column as a DataFrame as a copy\n        col_df = cbg[[gene]].copy()\n\n        # Convert to dense and integer type\n        col_df = col_df.sparse.to_dense().astype(int)\n\n        # Create a DataFrame necessary to prevent error in to_parquet\n        inst_df = pd.DataFrame(\n            col_df.values, columns=[gene], index=col_df.index.tolist()\n        )\n\n        # Replace 0 with NA and drop rows where all values are NA\n        inst_df.replace(0, pd.NA, inplace=True)\n        inst_df.dropna(how=\"all\", inplace=True)\n\n        # Save to Parquet if DataFrame is not empty\n        if not inst_df.empty:\n            output_path = os.path.join(output_dir, f\"{gene}.parquet\")\n            inst_df.to_parquet(output_path)\n</code></pre>"},{"location":"python/api/#celldega.pre.save_landscape_parameters","title":"<code>save_landscape_parameters(technology, path_landscape_files, image_name='dapi_files', tile_size=1000, image_info={}, image_format='.webp')</code>","text":"<p>Save the landscape parameters to a JSON file.</p> Source code in <code>src/celldega/pre/__init__.py</code> <pre><code>def save_landscape_parameters(\n    technology, path_landscape_files, image_name=\"dapi_files\", tile_size=1000, image_info={}, image_format='.webp'\n):\n    \"\"\"\n    Save the landscape parameters to a JSON file.\n    \"\"\"\n\n    path_image_pyramid = f\"{path_landscape_files}/pyramid_images/{image_name}\"\n\n    print(path_image_pyramid)\n\n    max_pyramid_zoom = get_max_zoom_level(path_image_pyramid)\n\n    landscape_parameters = {\n        \"technology\": technology,\n        \"max_pyramid_zoom\": max_pyramid_zoom,\n        \"tile_size\": tile_size,\n        \"image_info\": image_info,\n        \"image_format\": image_format\n    }\n\n    path_landscape_parameters = f\"{path_landscape_files}/landscape_parameters.json\"\n\n    with open(path_landscape_parameters, \"w\") as file:\n        json.dump(landscape_parameters, file, indent=4)\n</code></pre>"},{"location":"python/api/#celldega.viz.Landscape","title":"<code>Landscape</code>","text":"<p>               Bases: <code>AnyWidget</code></p> <p>A widget for interactive visualization of spatial omics data. This widget currently supports iST (Xenium and MERSCOPE) and sST (Visium HD data)</p> <p>Parameters:</p> Name Type Description Default <code>ini_x</code> <code>float</code> <p>The initial x-coordinate of the view.</p> required <code>ini_y</code> <code>float</code> <p>The initial y-coordinate of the view.</p> required <code>ini_zoom</code> <code>float</code> <p>The initial zoom level of the view.</p> required <code>token</code> <code>str</code> <p>The token traitlet.</p> required <code>base_url</code> <code>str</code> <p>The base URL for the widget.</p> required <code>dataset_name</code> <code>str</code> <p>The name of the dataset to visualize. This will show up in the user interface bar.</p> required <p>Attributes:</p> Name Type Description <code>component</code> <code>str</code> <p>The name of the component.</p> <code>technology</code> <code>str</code> <p>The technology used.</p> <code>base_url</code> <code>str</code> <p>The base URL for the widget.</p> <code>token</code> <code>str</code> <p>The token traitlet.</p> <code>ini_x</code> <code>float</code> <p>The initial x-coordinate of the view.</p> <code>ini_y</code> <code>float</code> <p>The initial y-coordinate of the view.</p> <code>ini_z</code> <code>float</code> <p>The initial z-coordinate of the view.</p> <code>ini_zoom</code> <code>float</code> <p>The initial zoom level of the view.</p> <code>dataset_name</code> <code>str</code> <p>The name of the dataset to visualize.</p> <code>update_trigger</code> <code>dict</code> <p>The dictionary to trigger updates.</p> <code>cell_clusters</code> <code>dict</code> <p>The dictionary containing cell cluster information.</p> <p>Returns:</p> Name Type Description <code>Landscape</code> <p>A widget for visualizing a 'landscape' view of spatial omics data.</p> Source code in <code>src/celldega/viz/widget.py</code> <pre><code>class Landscape(anywidget.AnyWidget):\n    \"\"\"\n    A widget for interactive visualization of spatial omics data. This widget\n    currently supports iST (Xenium and MERSCOPE) and sST (Visium HD data)\n\n    Args:\n        ini_x (float): The initial x-coordinate of the view.\n        ini_y (float): The initial y-coordinate of the view.\n        ini_zoom (float): The initial zoom level of the view.\n        token (str): The token traitlet.\n        base_url (str): The base URL for the widget.\n        dataset_name (str, optional): The name of the dataset to visualize. This will show up in the user interface bar.\n\n    Attributes:\n        component (str): The name of the component.\n        technology (str): The technology used.\n        base_url (str): The base URL for the widget.\n        token (str): The token traitlet.\n        ini_x (float): The initial x-coordinate of the view.\n        ini_y (float): The initial y-coordinate of the view.\n        ini_z (float): The initial z-coordinate of the view.\n        ini_zoom (float): The initial zoom level of the view.\n        dataset_name (str): The name of the dataset to visualize.\n        update_trigger (dict): The dictionary to trigger updates.\n        cell_clusters (dict): The dictionary containing cell cluster information.\n\n    Returns:\n        Landscape: A widget for visualizing a 'landscape' view of spatial omics data.\n    \"\"\"\n    _esm = pathlib.Path(__file__).parent / \"../static\" / \"widget.js\"\n    _css = pathlib.Path(__file__).parent / \"../static\" / \"widget.css\"\n    component = traitlets.Unicode(\"Landscape\").tag(sync=True)\n\n    technology = traitlets.Unicode(\"sst\").tag(sync=True)\n    base_url = traitlets.Unicode(\"\").tag(sync=True)\n    token = traitlets.Unicode(\"\").tag(sync=True)\n    ini_x = traitlets.Float().tag(sync=True)\n    ini_y = traitlets.Float().tag(sync=True)\n    ini_z = traitlets.Float().tag(sync=True)\n    ini_zoom = traitlets.Float(0).tag(sync=True)\n    square_tile_size = traitlets.Float(1.4).tag(sync=True)\n    dataset_name = traitlets.Unicode(\"\").tag(sync=True)\n    region = traitlets.Dict({}).tag(sync=True)\n    nbhd = traitlets.Dict({}).tag(sync=True)\n\n    meta_cell = traitlets.Dict({}).tag(sync=True)\n    meta_cluster = traitlets.Dict({}).tag(sync=True)\n    umap = traitlets.Dict({}).tag(sync=True)\n    landscape_state = traitlets.Unicode(\"spatial\").tag(sync=True)\n\n    update_trigger = traitlets.Dict().tag(sync=True)\n    cell_clusters = traitlets.Dict().tag(sync=True)\n\n    width = traitlets.Int(0).tag(sync=True)\n    height = traitlets.Int(800).tag(sync=True)\n\n    def trigger_update(self, new_value):\n        # This method updates the update_trigger traitlet with a new value\n        # You can pass any information necessary for the update, or just a timestamp\n        self.update_trigger = new_value\n\n    def update_cell_clusters(self, new_clusters):\n        # Convert the new_clusters to a JSON serializable format if necessary\n        self.cell_clusters = new_clusters\n</code></pre>"},{"location":"python/api/#celldega.viz.Matrix","title":"<code>Matrix</code>","text":"<p>               Bases: <code>AnyWidget</code></p> <p>A widget for interactive visualization of a hierarchically clustered matrix.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int</code> <p>The value traitlet.</p> required <code>component</code> <code>str</code> <p>The component traitlet.</p> required <code>network</code> <code>dict</code> <p>The network traitlet.</p> required <code>click_info</code> <code>dict</code> <p>The click_info traitlet.</p> required <p>Attributes:</p> Name Type Description <code>component</code> <code>str</code> <p>The name of the component.</p> <code>network</code> <code>dict</code> <p>The network dictionary.</p> <code>click_info</code> <code>dict</code> <p>The click_info dictionary.</p> <p>Returns:</p> Name Type Description <code>Matrix</code> <p>A widget for visualizing a hierarchically clustered matrix.</p> Source code in <code>src/celldega/viz/widget.py</code> <pre><code>class Matrix(anywidget.AnyWidget):\n    \"\"\"\n    A widget for interactive visualization of a hierarchically clustered matrix.\n\n    Args:\n        value (int): The value traitlet.\n        component (str): The component traitlet.\n        network (dict): The network traitlet.\n        click_info (dict): The click_info traitlet.\n\n    Attributes:\n        component (str): The name of the component.\n        network (dict): The network dictionary.\n        click_info (dict): The click_info dictionary.\n\n    Returns:\n        Matrix: A widget for visualizing a hierarchically clustered matrix.\n    \"\"\"\n\n    _esm = pathlib.Path(__file__).parent / \"../static\" / \"widget.js\"\n    _css = pathlib.Path(__file__).parent / \"../static\" / \"widget.css\"\n    value = traitlets.Int(0).tag(sync=True)\n    component = traitlets.Unicode(\"Matrix\").tag(sync=True)\n\n    network = traitlets.Dict({}).tag(sync=True)\n\n    width = traitlets.Int(600).tag(sync=True)\n    height = traitlets.Int(600).tag(sync=True)\n    click_info = traitlets.Dict({}).tag(sync=True)\n</code></pre>"},{"location":"python/api/#celldega.viz.landscape_matrix","title":"<code>landscape_matrix(landscape, mat, width='600px', height='700px')</code>","text":"<p>Display a <code>Landscape</code> widget and a <code>Matrix</code> widget side by side.</p> <p>Parameters:</p> Name Type Description Default <code>landscape</code> <code>Landscape</code> <p>A <code>Landscape</code> widget.</p> required <code>mat</code> <code>Matrix</code> <p>A <code>Matrix</code> widget.</p> required <code>width</code> <code>str</code> <p>The width of the widgets.</p> <code>'600px'</code> <code>height</code> <code>str</code> <p>The height of the widgets.</p> <code>'700px'</code> <p>Returns:</p> Type Description <p>Visualization display</p> <p>Example: See example Landscape-Matrix_Xenium notebook</p> Source code in <code>src/celldega/viz/__init__.py</code> <pre><code>def landscape_matrix(landscape, mat, width='600px', height='700px'):\n    \"\"\"\n    Display a `Landscape` widget and a `Matrix` widget side by side.\n\n    Args:\n        landscape (Landscape): A `Landscape` widget.\n        mat (Matrix): A `Matrix` widget.\n        width (str): The width of the widgets.\n        height (str): The height of the widgets.\n\n    Returns:\n        Visualization display\n\n    Example:\n    See example [Landscape-Matrix_Xenium](../../../examples/brief_notebooks/Landscape-Matrix_Xenium) notebook\n    \"\"\"\n\n    # Use `jslink` to directly link `click_info` from `mat` to `trigger_value` in `landscape_ist`\n    jslink((mat, 'click_info'), (landscape, 'update_trigger'))\n\n    # Set layouts for the widgets\n    mat.layout = Layout(width=width)  # Adjust as needed\n    landscape.layout = Layout(width=width, height=height)  # Adjust as needed\n\n    # Display widgets side by side\n    widgets_side_by_side = HBox([landscape, mat])\n\n    display(widgets_side_by_side)\n</code></pre>"},{"location":"python/clust/api/","title":"Clust Module API Reference","text":"<p>Module for clustering high-dimensional data.</p>"},{"location":"python/clust/api/#celldega.clust.Network","title":"<code>Network</code>","text":"<p>               Bases: <code>object</code></p> <p>Clustergrammer.py takes a matrix as input (either from a file of a Pandas DataFrame), normalizes/filters, hierarchically clusters, and produces the :ref:<code>visualization_json</code> for :ref:<code>clustergrammer_js</code>.</p> <p>Networks have two states:</p> <ol> <li>the data state, where they are stored as a matrix and nodes</li> <li>the viz state where they are stored as viz.links, viz.row_nodes, and viz.col_nodes.</li> </ol> <p>The goal is to start in a data-state and produce a viz-state of the network that will be used as input to clustergram.js.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>class Network(object):\n  '''\n  Clustergrammer.py takes a matrix as input (either from a file of a Pandas DataFrame), normalizes/filters, hierarchically clusters, and produces the :ref:`visualization_json` for :ref:`clustergrammer_js`.\n\n  Networks have two states:\n\n    1. the data state, where they are stored as a matrix and nodes\n    2. the viz state where they are stored as viz.links, viz.row_nodes, and viz.col_nodes.\n\n  The goal is to start in a data-state and produce a viz-state of\n  the network that will be used as input to clustergram.js.\n  '''\n\n  def __init__(self, widget=None):\n    initialize_net.main(self, widget)\n\n  def reset(self):\n    '''\n    This re-initializes the Network object.\n    '''\n    initialize_net.main(self)\n\n  def load_file(self, filename):\n    '''\n    Load TSV file.\n    '''\n    load_data.load_file(self, filename)\n\n  def load_file_as_string(self, file_string, filename=''):\n    '''\n    Load file as a string.\n    '''\n    load_data.load_file_as_string(self, file_string, filename=filename)\n\n\n  def load_stdin(self):\n    '''\n    Load stdin TSV-formatted string.\n    '''\n    load_data.load_stdin(self)\n\n  def load_tsv_to_net(self, file_buffer, filename=None):\n    '''\n    This will load a TSV matrix file buffer; this is exposed so that it will\n    be possible to load data without having to read from a file.\n    '''\n    load_data.load_tsv_to_net(self, file_buffer, filename)\n\n  def load_vect_post_to_net(self, vect_post):\n    '''\n    Load data in the vector format JSON.\n    '''\n    load_vect_post.main(self, vect_post)\n\n  def load_data_file_to_net(self, filename):\n    '''\n    Load Clustergrammer's dat format (saved as JSON).\n    '''\n    inst_dat = self.load_json_to_dict(filename)\n    load_data.load_data_to_net(self, inst_dat)\n\n  def cluster(self, dist_type='cosine', run_clustering=True,\n                 dendro=True, views=[],\n                 linkage_type='average', sim_mat=False, filter_sim=0.0,\n                 calc_cat_pval=False, run_enrichr=None, enrichrgram=None,\n                 clust_library='scipy', min_samples=1, min_cluster_size=2):\n    '''\n    The main function performs hierarchical clustering, optionally generates\n    filtered views (e.g. row-filtered views), and generates the :\n    ``visualization_json``.\n\n    Used to set views equal to ['N_row_sum', 'N_row_var']\n    '''\n    initialize_net.viz(self)\n\n    make_clust_fun.make_clust(self, dist_type=dist_type,\n                                    run_clustering=run_clustering,\n                                    dendro=dendro,\n                                    requested_views=views,\n                                    linkage_type=linkage_type,\n                                    sim_mat=sim_mat,\n                                    filter_sim=filter_sim,\n                                    calc_cat_pval=calc_cat_pval,\n                                    run_enrichr=run_enrichr,\n                                    enrichrgram=enrichrgram,\n                                    clust_library=clust_library,\n                                    min_samples=min_samples,\n                                    min_cluster_size=min_cluster_size)\n\n  def swap_nan_for_zero(self):\n    '''\n    Swaps all NaN (numpy NaN) instances for zero.\n    '''\n    self.dat['mat'][np.isnan(self.dat['mat'])] = 0\n\n  def load_df(self, df_ini, meta_col=None, meta_row=None, col_cats=None,\n              row_cats=None, is_downsampled=False, meta_ds_row=None,\n              meta_ds_col=None):\n    '''\n    Load Pandas DataFrame.\n    '''\n    self.reset()\n\n    # load dataframe\n    df = deepcopy(df_ini)\n\n\n    if is_downsampled:\n      if meta_ds_col is not None:\n        self.meta_ds_col = meta_ds_col\n      if meta_ds_row is not None:\n        self.meta_ds_row = meta_ds_row\n\n    # define downsampled status\n    self.is_downsampled = is_downsampled\n    # print('load_df: is_downsampled', is_downsampled)\n\n    if hasattr(self, 'meta_col') == False and hasattr(self, 'meta_row') == False:\n      self.meta_cat = False\n\n    # load metadata\n    if isinstance(meta_col, pd.DataFrame):\n      self.meta_col = meta_col\n\n      if col_cats is None:\n        self.col_cats = meta_col.columns.tolist()\n      else:\n        self.col_cats = col_cats\n\n      self.meta_cat = True\n\n    if isinstance(meta_row, pd.DataFrame):\n      self.meta_row = meta_row\n\n      if row_cats is None:\n        self.row_cats = meta_row.columns.tolist()\n      else:\n        self.row_cats = row_cats\n\n      self.meta_cat = True\n\n    data_formats.df_to_dat(self, df, define_cat_colors=True)\n\n  def export_df(self):\n    '''\n    Export Pandas DataFrame/\n    '''\n    df = data_formats.dat_to_df(self)\n\n    # drop tuple categories if downsampling\n    if self.is_downsampled:\n      df.columns = self.dat['nodes']['col']\n      df.index = self.dat['nodes']['row']\n\n    return df\n\n  def df_to_dat(self, df, define_cat_colors=False):\n    '''\n    Load Pandas DataFrame (will be deprecated).\n    '''\n    data_formats.df_to_dat(self, df, define_cat_colors)\n\n  def set_matrix_colors(self, pos='red', neg='blue'):\n\n    self.viz['matrix_colors'] = {}\n    self.viz['matrix_colors']['pos'] = pos\n    self.viz['matrix_colors']['neg'] = neg\n\n  def set_global_cat_colors(self, df_meta):\n\n    for inst_name in df_meta.index.tolist():\n      inst_color = df_meta.loc[inst_name, 'color']\n\n      self.viz['global_cat_colors'][inst_name] = inst_color\n\n  def set_cat_color(self, axis, cat_index, cat_name, inst_color):\n\n    if axis == 0:\n      axis = 'row'\n    if axis == 1:\n      axis = 'col'\n\n    try:\n      # process cat_index\n      cat_index = cat_index - 1\n      cat_index = 'cat-' + str(cat_index)\n\n      self.viz['cat_colors'][axis][cat_index][cat_name] = inst_color\n\n    except:\n      print('there was an error setting the category color')\n\n  def dat_to_df(self):\n    '''\n    Export Pandas DataFrams (will be deprecated).\n    '''\n    return data_formats.dat_to_df(self)\n\n  def export_net_json(self, net_type='viz', indent='no-indent'):\n    '''\n    Export dat or viz JSON.\n    '''\n    return export_data.export_net_json(self, net_type, indent)\n\n  def export_viz_to_widget(self, which_viz='viz'):\n    '''\n    Export viz JSON, for use with clustergrammer_widget. Formerly method was\n    named widget.\n    '''\n\n    return export_data.export_net_json(self, which_viz, 'no-indent')\n\n  def widget(self, which_viz='viz', link_net=None, link_net_js=None, clust_library='scipy',\n    min_samples=1, min_cluster_size=2):\n    '''\n    Generate a widget visualization using the widget. The export_viz_to_widget\n    method passes the visualization JSON to the instantiated widget, which is\n    returned and visualized on the front-end.\n    '''\n    # run clustering if necessary\n    if len(self.viz['row_nodes']) == 0:\n      self.cluster(clust_library=clust_library, min_samples=min_samples,\n                   min_cluster_size=min_cluster_size)\n\n      # add manual_category to viz json\n      if 'manual_category' in self.dat:\n        self.viz['manual_category'] = self.dat['manual_category']\n\n      # add pre-z-score data to viz\n      if 'pre_zscore' in self.dat:\n        self.viz['pre_zscore'] = self.dat['pre_zscore']\n\n    self.widget_instance = self.widget_class(network = self.export_viz_to_widget(which_viz))\n\n    # initialize manual category\n    if 'manual_category' in self.dat:\n      manual_cat = {}\n      axis = 'col'\n      manual_cat[axis] = {}\n      manual_cat[axis]['col_cat_colors'] = self.viz['cat_colors'][axis]['cat-0']\n\n      man_cat_name = self.dat['manual_category'][axis]\n      if axis == 'col':\n        manual_cat[axis][man_cat_name] = self.meta_col[man_cat_name].to_dict()\n\n      self.widget_instance.manual_cat = json.dumps(manual_cat)\n\n      self.widget_instance.observe(self.get_manual_category, names='manual_cat')\n\n    # add link (python)\n    if link_net is not None:\n      inst_link = widgets.link(\n                                (self.widget_instance, 'manual_cat'),\n                                (link_net.widget_instance, 'manual_cat')\n                               )\n      self.widget_instance.link = inst_link\n\n    # add jslink (JavaScript)\n    if link_net_js is not None:\n\n      inst_link = widgets.jslink(\n                                (self.widget_instance, 'manual_cat'),\n                                (link_net_js.widget_instance, 'manual_cat')\n                               )\n      self.widget_instance.link = inst_link\n\n    return self.widget_instance\n\n\n  def widget_df(self):\n    '''\n    Export a DataFrame from the front-end visualization. For instance, a user\n    can filter to show only a single cluster using the dendrogram and then\n    get a dataframe of this cluster using the widget_df method.\n    '''\n\n    if hasattr(self, 'widget_instance') == True:\n\n      if self.widget_instance.mat_string != '':\n\n        tmp_net = deepcopy(Network())\n\n        df_string = self.widget_instance.mat_string\n\n        tmp_net.load_file_as_string(df_string)\n\n        df = tmp_net.export_df()\n\n        return df\n\n      else:\n        return self.export_df()\n\n    else:\n      if hasattr(self, 'widget_class') == True:\n        print('Please make the widget before exporting the widget DataFrame.')\n        print('Do this using the widget method: net.widget()')\n\n      else:\n        print('Can not make widget because Network has no attribute widget_class')\n        print('Please instantiate Network with clustergrammer_widget using: Network(clustergrammer_widget)')\n\n  def write_json_to_file(self, net_type, filename, indent='no-indent'):\n    '''\n    Save dat or viz as a JSON to file.\n    '''\n    export_data.write_json_to_file(self, net_type, filename, indent)\n\n  def write_matrix_to_tsv(self, filename=None, df=None):\n    '''\n    Export data-matrix to file.\n    '''\n    return export_data.write_matrix_to_tsv(self, filename, df)\n\n  def filter_sum(self, threshold, take_abs=True, axis=None, inst_rc=None):\n    '''\n    Filter a network's rows or columns based on the sum across rows or columns.\n    '''\n\n    if axis is None:\n      axis = inst_rc\n      print('warning inst_rc argument will be deprecated, please use axis')\n\n      if inst_rc is None:\n        print('please provide axis argument')\n\n    inst_df = self.dat_to_df()\n    if axis == 'row':\n      inst_df = run_filter.df_filter_row_sum(inst_df, threshold, take_abs)\n    elif axis == 'col':\n      inst_df = run_filter.df_filter_col_sum(inst_df, threshold, take_abs)\n    self.df_to_dat(inst_df)\n\n  def filter_N_top(self, N_top, rank_type='sum', inst_rc=None, axis=None):\n    '''\n    Filter the matrix rows or columns based on sum/variance, and only keep the top\n    N.\n    '''\n\n    if axis is None:\n      axis = inst_rc\n      print('warning inst_rc argument will be deprecated, please use axis')\n\n      if inst_rc is None:\n        print('please provide axis argument')\n\n    inst_df = self.dat_to_df()\n\n    inst_df = run_filter.filter_N_top(inst_rc, inst_df, N_top, rank_type)\n\n    self.df_to_dat(inst_df)\n\n  def filter_threshold(self, threshold, num_occur=1, inst_rc=None, axis=None):\n    '''\n    Filter the matrix rows or columns based on num_occur values being above a\n    threshold (in absolute value).\n    '''\n\n    if axis is None:\n      axis = inst_rc\n      print('warning inst_rc argument will be deprecated, please use axis')\n\n      if inst_rc is None:\n        print('please provide axis argument')\n\n    inst_df = self.dat_to_df()\n\n    inst_df = run_filter.filter_threshold(inst_df, axis, threshold,\n      num_occur)\n\n    self.df_to_dat(inst_df)\n\n  def filter_cat(self, axis, cat_index, cat_name):\n    '''\n    Filter the matrix based on their category. cat_index is the index of the category, the first category has index=1.\n    '''\n    run_filter.filter_cat(self, axis, cat_index, cat_name)\n\n  def filter_names(self, axis, names):\n    '''\n    Filter the visualization using row/column names. The function takes, axis ('row'/'col') and names, a list of strings.\n    '''\n    run_filter.filter_names(self, axis, names)\n\n  def clip(self, lower=None, upper=None):\n    '''\n    Trim values at input thresholds using pandas function\n    '''\n    df = self.export_df()\n    df = df.clip(lower=lower, upper=upper)\n    self.load_df(df)\n\n  def normalize(self, df=None, norm_type='zscore', axis='row', z_clip=None):\n    '''\n    Normalize the matrix rows or columns using Z-score (zscore) or Quantile Normalization (qn). Users can optionally pass in a DataFrame to be normalized (and this will be incorporated into the Network object).\n    '''\n    normalize_fun.run_norm(self, df, norm_type, axis, z_clip)\n\n  def downsample(self, df=None, ds_type='kmeans', axis='row', num_samples=100,\n                 random_state=1000, ds_name='Downsample',\n                 ds_cluster_name='cluster'):\n    '''\n    Downsample the matrix rows or columns (currently supporting kmeans only). Users can optionally pass in a DataFrame to be downsampled (and this will be incorporated into the network object).\n    '''\n    return downsample_fun.main(self, df, ds_type, axis, num_samples, random_state, ds_name, ds_cluster_name)\n\n  def random_sample(self, num_samples, df=None, replace=False, weights=None, random_state=100, axis='row'):\n    '''\n    Return random sample of matrix.\n    '''\n\n    if df is None:\n      df = self.dat_to_df()\n\n    if axis == 'row':\n      axis = 0\n    if axis == 'col':\n      axis = 1\n\n    df = self.export_df()\n    df = df.sample(n=num_samples, replace=replace, weights=weights, random_state=random_state,  axis=axis)\n\n    self.load_df(df)\n\n  def add_cats(self, axis, cat_data):\n    '''\n    Add categories to rows or columns using cat_data array of objects. Each object in cat_data is a dictionary with one key (category title) and value (rows/column names) that have this category. Categories will be added onto the existing categories and will be added in the order of the objects in the array.\n\n    Example ``cat_data``::\n\n\n        [\n          {\n            \"title\": \"First Category\",\n            \"cats\": {\n              \"true\": [\n                \"ROS1\",\n                \"AAK1\"\n              ]\n            }\n          },\n          {\n            \"title\": \"Second Category\",\n            \"cats\": {\n              \"something\": [\n                \"PDK4\"\n              ]\n            }\n          }\n        ]\n\n\n    '''\n    for inst_data in cat_data:\n      categories.add_cats(self, axis, inst_data)\n\n  def Iframe_web_app(self, filename=None, width=1000, height=800):\n\n    link = iframe_web_app.main(self, filename, width, height)\n\n    return link\n\n  def enrichrgram(self, lib, axis='row'):\n    '''\n    Add Enrichr gene enrichment results to your visualization (where your rows\n    are genes). Run enrichrgram before clustering to incldue enrichment results\n    as row categories. Enrichrgram can also be run on the front-end using the\n    Enrichr logo at the top left.\n\n    Set lib to the Enrichr library that you want to use for enrichment analysis.\n    Libraries included:\n\n      * ChEA_2016\n      * KEA_2015\n      * ENCODE_TF_ChIP-seq_2015\n      * ENCODE_Histone_Modifications_2015\n      * Disease_Perturbations_from_GEO_up\n      * Disease_Perturbations_from_GEO_down\n      * GO_Molecular_Function_2015\n      * GO_Biological_Process_2015\n      * GO_Cellular_Component_2015\n      * Reactome_2016\n      * KEGG_2016\n      * MGI_Mammalian_Phenotype_Level_4\n      * LINCS_L1000_Chem_Pert_up\n      * LINCS_L1000_Chem_Pert_down\n\n    '''\n\n    df = self.export_df()\n    df, bar_info = enr_fun.add_enrichr_cats(df, axis, lib)\n    self.load_df(df)\n\n    self.dat['enrichrgram_lib'] = lib\n    self.dat['row_cat_bars'] = bar_info\n\n  @staticmethod\n  def load_gmt(filename):\n    return load_data.load_gmt(filename)\n\n  @staticmethod\n  def load_json_to_dict(filename):\n    return load_data.load_json_to_dict(filename)\n\n  @staticmethod\n  def save_dict_to_json(inst_dict, filename, indent='no-indent'):\n    export_data.save_dict_to_json(inst_dict, filename, indent)\n\n  @staticmethod\n  def load_gene_exp_to_df(inst_path):\n    '''\n    Loads gene expression data from 10x in sparse matrix format and returns a\n    Pandas dataframe\n    '''\n\n    import pandas as pd\n    from scipy import io\n    from scipy import sparse\n    from ast import literal_eval as make_tuple\n\n    # matrix\n    Matrix = io.mmread( inst_path + 'matrix.mtx')\n    mat = Matrix.todense()\n\n    # genes\n    filename = inst_path + 'genes.tsv'\n    f = open(filename, 'r')\n    lines = f.readlines()\n    f.close()\n\n    # # add unique id to all genes\n    # genes = []\n    # unique_id = 0\n    # for inst_line in lines:\n    #     inst_line = inst_line.strip().split()\n\n    #     if len(inst_line) &gt; 1:\n    #       inst_gene = inst_line[1]\n    #     else:\n    #       inst_gene = inst_line[0]\n\n    #     genes.append(inst_gene + '_' + str(unique_id))\n    #     unique_id = unique_id + 1\n\n    # add unique id only to duplicate genes\n    ini_genes = []\n    for inst_line in lines:\n        inst_line = inst_line.strip().split()\n        if len(inst_line) &gt; 1:\n          inst_gene = inst_line[1]\n        else:\n          inst_gene = inst_line[0]\n        ini_genes.append(inst_gene)\n\n    gene_name_count = pd.Series(ini_genes).value_counts()\n    duplicate_genes = gene_name_count[gene_name_count &gt; 1].index.tolist()\n\n    dup_index = {}\n    genes = []\n    for inst_row in ini_genes:\n\n      # add index to non-unique genes\n      if inst_row in duplicate_genes:\n\n        # calc_non-unque index\n        if inst_row not in dup_index:\n          dup_index[inst_row] = 1\n        else:\n          dup_index[inst_row] = dup_index[inst_row] + 1\n\n        new_row = inst_row + '_' + str(dup_index[inst_row])\n\n      else:\n        new_row = inst_row\n\n      genes.append(new_row)\n\n    # barcodes\n    filename = inst_path + 'barcodes.tsv'\n    f = open(filename, 'r')\n    lines = f.readlines()\n    f.close()\n\n    cell_barcodes = []\n    for inst_bc in lines:\n        inst_bc = inst_bc.strip().split('\\t')\n\n        # remove dash from barcodes if necessary\n        if '-' in inst_bc[0]:\n          inst_bc[0] = inst_bc[0].split('-')[0]\n\n        cell_barcodes.append(inst_bc[0])\n\n    # parse tuples if necessary\n    try:\n        cell_barcodes = [make_tuple(x) for x in cell_barcodes]\n    except:\n        pass\n\n    try:\n        genes = [make_tuple(x) for x in genes]\n    except:\n        pass\n\n    # make dataframe\n    df = pd.DataFrame(mat, index=genes, columns=cell_barcodes)\n\n    return df\n\n  @staticmethod\n  def save_gene_exp_to_mtx_dir(inst_path, df):\n\n    import os\n    from scipy import io\n    from scipy import sparse\n\n    if not os.path.exists(inst_path):\n        os.makedirs(inst_path)\n\n    genes = df.index.tolist()\n    barcodes = df.columns.tolist()\n\n    save_list_to_tsv(genes, inst_path + 'genes.tsv')\n    save_list_to_tsv(barcodes, inst_path + 'barcodes.tsv')\n\n    mat_ge = df.values\n    mat_ge_sparse = sparse.coo_matrix(mat_ge)\n\n    io.mmwrite( inst_path + 'matrix.mtx', mat_ge_sparse)\n\n  @staticmethod\n  def save_list_to_tsv(inst_list, filename):\n\n      f = open(filename, 'w')\n      for inst_line in inst_list:\n          f.write(str(inst_line) + '\\n')\n\n      f.close()\n\n  def sim_same_and_diff_category_samples(self, df, cat_index=1, dist_type='cosine',\n                                         equal_var=False, plot_roc=True,\n                                         precalc_dist=False, calc_roc=True):\n      '''\n      Calculate the similarity of samples from the same and different categories. The\n      cat_index gives the index of the category, where 1 in the first category\n      '''\n\n      cols = df.columns.tolist()\n\n      if type(precalc_dist) == bool:\n          # compute distnace between rows (transpose to get cols as rows)\n          dist_arr = 1 - pdist(df.transpose(), metric=dist_type)\n      else:\n          dist_arr = precalc_dist\n\n      # generate sample names with categories\n      sample_combos = list(combinations(range(df.shape[1]),2))\n\n      sample_names = [str(ind) + '_same' if cols[x[0]][cat_index] == cols[x[1]][cat_index] else str(ind) + '_different' for ind, x in enumerate(sample_combos)]\n\n      ser_dist = pd.Series(data=dist_arr, index=sample_names)\n\n      # find same-cat sample comparisons\n      same_cat = [x for x in sample_names if x.split('_')[1] == 'same']\n\n      # find diff-cat sample comparisons\n      diff_cat = [x for x in sample_names if x.split('_')[1] == 'different']\n\n      # make series of same and diff category sample comparisons\n      ser_same = ser_dist[same_cat]\n      ser_same.name = 'Same Category'\n      ser_diff = ser_dist[diff_cat]\n      ser_diff.name = 'Different Category'\n\n      sim_dict = {}\n      roc_data = {}\n      sim_data = {}\n\n      sim_dict['same'] = ser_same\n      sim_dict['diff'] = ser_diff\n\n      pval_dict = {}\n      ttest_stat, pval_dict['ttest'] = ttest_ind(ser_diff, ser_same, equal_var=equal_var)\n\n      ttest_stat, pval_dict['mannwhitney'] = mannwhitneyu(ser_diff, ser_same)\n\n      if calc_roc:\n          # calc AUC\n          true_index = list(np.ones(sim_dict['same'].shape[0]))\n          false_index = list(np.zeros(sim_dict['diff'].shape[0]))\n          y_true = true_index + false_index\n\n          true_val = list(sim_dict['same'].values)\n          false_val = list(sim_dict['diff'].values)\n          y_score = true_val + false_val\n\n          fpr, tpr, thresholds = roc_curve(y_true, y_score)\n\n          inst_auc = auc(fpr, tpr)\n\n          if plot_roc:\n              plt.figure()\n              plt.plot(fpr, tpr)\n              plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n              plt.figure(figsize=(10,10))\n\n              print('AUC', inst_auc)\n\n          roc_data['true'] = y_true\n          roc_data['score'] = y_score\n          roc_data['fpr'] = fpr\n          roc_data['tpr'] = tpr\n          roc_data['thresholds'] = thresholds\n          roc_data['auc'] = inst_auc\n\n      sim_data['sim_dict'] = sim_dict\n      sim_data['pval_dict'] = pval_dict\n      sim_data['roc_data'] = roc_data\n\n      return sim_data\n\n  def generate_signatures(self, df_data, df_meta, category_name, pval_cutoff=0.05,\n                          num_top_dims=False, verbose=True, equal_var=False):\n\n      '''\n      Generate signatures for column categories\n      T-test is run for each category in a one-vs-all manner. The num_top_dims overrides\n      the P-value cutoff.\n      '''\n\n      df_t = df_data.transpose()\n\n      # remove columns (dimensions) with constant values\n      orig_num_cols = df_t.shape[1]\n      df_t = df_t.loc[:, (df_t != df_t.iloc[0]).any()]\n      if df_t.shape[1] &lt; orig_num_cols:\n        print('dropped columns with constant values')\n\n      # make tuple rows\n      df_t.index = [(x, df_meta.loc[x, category_name]) for x in df_t.index.tolist()]\n      category_level = 1\n\n      df = self.row_tuple_to_multiindex(df_t)\n\n      cell_types = sorted(list(set(df.index.get_level_values(category_level).tolist())))\n\n      keep_genes = []\n      keep_genes_dict = {}\n      gene_pval_dict = {}\n      all_fold_info = {}\n\n      for inst_ct in cell_types:\n\n          inst_ct_mat = df.xs(key=inst_ct, level=category_level)\n          inst_other_mat = df.drop(inst_ct, level=category_level)\n\n          # save mean values and fold change\n          fold_info = {}\n          fold_info['cluster_mean'] = inst_ct_mat.mean()\n          fold_info['other_mean'] = inst_other_mat.mean()\n          fold_info['log2_fold'] = fold_info['cluster_mean']/fold_info['other_mean']\n          fold_info['log2_fold'] = fold_info['log2_fold'].apply(np.log2)\n          all_fold_info[inst_ct] = fold_info\n\n          inst_stats, inst_pvals = ttest_ind(inst_ct_mat, inst_other_mat, axis=0, equal_var=equal_var)\n\n          ser_pval = pd.Series(data=inst_pvals, index=df.columns.tolist()).sort_values()\n\n          if num_top_dims == False:\n              ser_pval_keep = ser_pval[ser_pval &lt; pval_cutoff]\n          else:\n              ser_pval_keep = ser_pval[:num_top_dims]\n\n          gene_pval_dict[inst_ct] = ser_pval_keep\n\n          inst_keep = ser_pval_keep.index.tolist()\n          keep_genes.extend(inst_keep)\n          keep_genes_dict[inst_ct] = inst_keep\n\n      keep_genes = sorted(list(set(keep_genes)))\n\n      df_gbm = df.groupby(level=category_level).mean().transpose()\n      cols = df_gbm.columns.tolist()\n\n      df_sig = df_gbm.loc[keep_genes]\n\n      if len(keep_genes) == 0 and verbose:\n          print('found no informative dimensions')\n\n      df_gene_pval = pd.concat(gene_pval_dict, axis=1, sort=False)\n\n      df_diff = {}\n      for inst_col in df_gene_pval:\n\n          inst_pvals = df_gene_pval[inst_col]\n\n          # nans represent dimensions that did not meet pval or top threshold\n          inst_pvals = inst_pvals.dropna().sort_values()\n\n          inst_genes = inst_pvals.index.tolist()\n\n          # prevent failure if no cells have this category\n          if inst_pvals.shape[0] &gt; 0:\n              rej, pval_corr = smm.multipletests(inst_pvals, 0.05, method='fdr_bh')[:2]\n\n              ser_pval = pd.Series(data=inst_pvals, index=inst_genes, name='P-values')\n              ser_bh_pval = pd.Series(data=pval_corr, index=inst_genes, name='BH P-values')\n              ser_log2_fold = all_fold_info[inst_col]['log2_fold'].loc[inst_genes]\n              ser_log2_fold.name = 'Log2 Fold Change'\n              ser_cluster_mean = all_fold_info[inst_col]['cluster_mean'].loc[inst_genes]\n              ser_cluster_mean.name = 'Cluster Mean'\n              ser_other_mean = all_fold_info[inst_col]['other_mean'].loc[inst_genes]\n              ser_other_mean.name = 'All Other Mean'\n              inst_df = pd.concat([ser_pval, ser_bh_pval, ser_log2_fold, ser_cluster_mean, ser_other_mean], axis=1)\n\n              df_diff[inst_col] = inst_df\n\n      return df_sig, df_diff\n\n  def old_generate_signatures(self, df_ini, category_level, pval_cutoff=0.05,\n                          num_top_dims=False, verbose=True, equal_var=False):\n\n      ''' Generate signatures for column categories '''\n\n      # change this to use category name and set caetgory level to 1 always\n      ###################################\n\n      df_t = df_ini.transpose()\n\n      # remove columns with constant values\n      df_t = df_t.loc[:, (df_t != df_t.iloc[0]).any()]\n\n      df = self.row_tuple_to_multiindex(df_t)\n\n      cell_types = sorted(list(set(df.index.get_level_values(category_level).tolist())))\n\n      keep_genes = []\n      keep_genes_dict = {}\n      gene_pval_dict = {}\n      all_fold_info = {}\n\n      for inst_ct in cell_types:\n\n          inst_ct_mat = df.xs(key=inst_ct, level=category_level)\n          inst_other_mat = df.drop(inst_ct, level=category_level)\n\n          # save mean values and fold change\n          fold_info = {}\n          fold_info['cluster_mean'] = inst_ct_mat.mean()\n          fold_info['other_mean'] = inst_other_mat.mean()\n          fold_info['log2_fold'] = fold_info['cluster_mean']/fold_info['other_mean']\n          fold_info['log2_fold'] = fold_info['log2_fold'].apply(np.log2)\n          all_fold_info[inst_ct] = fold_info\n\n          inst_stats, inst_pvals = ttest_ind(inst_ct_mat, inst_other_mat, axis=0, equal_var=equal_var)\n\n          ser_pval = pd.Series(data=inst_pvals, index=df.columns.tolist()).sort_values()\n\n          if num_top_dims == False:\n              ser_pval_keep = ser_pval[ser_pval &lt; pval_cutoff]\n          else:\n              ser_pval_keep = ser_pval[:num_top_dims]\n\n          gene_pval_dict[inst_ct] = ser_pval_keep\n\n          inst_keep = ser_pval_keep.index.tolist()\n          keep_genes.extend(inst_keep)\n          keep_genes_dict[inst_ct] = inst_keep\n\n      keep_genes = sorted(list(set(keep_genes)))\n\n      df_gbm = df.groupby(level=category_level).mean().transpose()\n      cols = df_gbm.columns.tolist()\n      new_cols = []\n      for inst_col in cols:\n          new_col = (inst_col, category_level + ': ' + inst_col)\n          new_cols.append(new_col)\n      df_gbm.columns = new_cols\n\n      df_sig = df_gbm.loc[keep_genes]\n\n      if len(keep_genes) == 0 and verbose:\n          print('found no informative dimensions')\n\n      df_gene_pval = pd.concat(gene_pval_dict, axis=1, sort=False)\n\n      return df_sig, df_gene_pval, all_fold_info\n\n  def predict_cats_from_sigs(self, df_data_ini, df_meta, df_sig_ini,\n                             predict='Predicted Category', dist_type='cosine',\n                             unknown_thresh=-1):\n      ''' Predict category using signature '''\n\n      keep_rows = df_sig_ini.index.tolist()\n      data_rows = df_data_ini.index.tolist()\n\n      common_rows = list(set(data_rows).intersection(keep_rows))\n\n      df_data = deepcopy(df_data_ini.loc[common_rows])\n      df_sig = deepcopy(df_sig_ini.loc[common_rows])\n\n      # calculate sim_mat of df_data and df_sig\n      cell_types = df_sig.columns.tolist()\n      barcodes = df_data.columns.tolist()\n      sim_mat = 1 - pairwise_distances(df_sig.transpose(), df_data.transpose(), metric=dist_type)\n      df_sim = pd.DataFrame(data=sim_mat, index=cell_types, columns=barcodes).transpose()\n\n      # get the top column value (most similar signature)\n      df_sim_top = df_sim.idxmax(axis=1)\n\n      # get the maximum similarity of a cell to a cell type definition\n      max_sim = df_sim.max(axis=1)\n\n      unknown_cells = max_sim[max_sim &lt; unknown_thresh].index.tolist()\n\n      # assign unknown cells (need category of same name)\n      df_sim_top[unknown_cells] = 'Unknown'\n\n      # add predicted category name to top list\n      # top_list = df_sim_top.values\n      df_sim = df_sim.transpose()\n\n      df_meta[predict] = df_sim_top\n\n      return df_sim, df_meta\n\n\n  def old_predict_cats_from_sigs(self, df_data_ini, df_sig_ini, dist_type='cosine', predict_level='Predict Category',\n                             truth_level=1, unknown_thresh=-1):\n      ''' Predict category using signature '''\n\n      keep_rows = df_sig_ini.index.tolist()\n      data_rows = df_data_ini.index.tolist()\n\n      common_rows = list(set(data_rows).intersection(keep_rows))\n\n      df_data = deepcopy(df_data_ini.loc[common_rows])\n      df_sig = deepcopy(df_sig_ini.loc[common_rows])\n\n      # calculate sim_mat of df_data and df_sig\n      cell_types = df_sig.columns.tolist()\n      barcodes = df_data.columns.tolist()\n      sim_mat = 1 - pairwise_distances(df_sig.transpose(), df_data.transpose(), metric=dist_type)\n      df_sim = pd.DataFrame(data=sim_mat, index=cell_types, columns=barcodes).transpose()\n\n      # get the top column value (most similar signature)\n      df_sim_top = df_sim.idxmax(axis=1)\n\n      # get the maximum similarity of a cell to a cell type definition\n      max_sim = df_sim.max(axis=1)\n\n      unknown_cells = max_sim[max_sim &lt; unknown_thresh].index.tolist()\n\n      # assign unknown cells (need category of same name)\n      df_sim_top[unknown_cells] = 'Unknown'\n\n      # add predicted category name to top list\n      top_list = df_sim_top.values\n      top_list = [ predict_level + ': ' + x[0] if type(x) is tuple else predict_level + ': ' + x  for x in top_list]\n\n      # add cell type category to input data\n      df_cat = deepcopy(df_data)\n      cols = df_cat.columns.tolist()\n      new_cols = []\n\n      # check whether the columns have the true category available\n      has_truth = False\n      if type(cols[0]) is tuple:\n          has_truth = True\n\n      if has_truth:\n          new_cols = [tuple(list(a) + [b]) for a,b in zip(cols, top_list)]\n      else:\n          new_cols = [tuple([a] + [b]) for a,b in zip(cols, top_list)]\n\n      # transfer new categories\n      df_cat.columns = new_cols\n\n      # keep track of true and predicted labels\n      y_info = {}\n      y_info['true'] = []\n      y_info['pred'] = []\n\n      if has_truth:\n          y_info['true'] = [x[truth_level].split(': ')[1] for x in cols]\n          y_info['pred'] = [x.split(': ')[1] for x in top_list]\n\n      return df_cat, df_sim.transpose(), y_info\n\n  def assess_prediction(self, df_meta, truth, pred):\n      ''' Generate confusion matrix from y_info '''\n\n      y_info = {}\n      y_info['true'] = df_meta[truth].values.tolist()\n      y_info['pred'] = df_meta[pred].values.tolist()\n\n      sorted_cats = sorted(list(set(y_info['true'] + y_info['pred'])))\n      conf_mat = confusion_matrix(y_info['true'], y_info['pred'], labels=sorted_cats)\n\n      # true columns and pred rows\n      df_conf = pd.DataFrame(conf_mat, index=sorted_cats, columns=sorted_cats).transpose()\n\n      total_correct = np.trace(df_conf)\n      total_pred = df_conf.sum().sum()\n      fraction_correct = total_correct/float(total_pred)\n\n      # calculate ser_correct\n      correct_list = []\n      cat_counts = df_conf.sum(axis=0)\n      all_cols = df_conf.columns.tolist()\n      for inst_cat in all_cols:\n          inst_correct = df_conf.loc[inst_cat, inst_cat] / cat_counts[inst_cat]\n          correct_list.append(inst_correct)\n\n      ser_correct = pd.Series(data=correct_list, index=all_cols)\n\n      return df_conf, ser_correct, fraction_correct\n\n  def old_confusion_matrix_and_correct_series(self, y_info):\n      ''' Generate confusion matrix from y_info '''\n\n\n      a = deepcopy(y_info['true'])\n      true_count = dict((i, a.count(i)) for i in set(a))\n\n      a = deepcopy(y_info['pred'])\n      pred_count = dict((i, a.count(i)) for i in set(a))\n\n      sorted_cats = sorted(list(set(y_info['true'] + y_info['pred'])))\n      conf_mat = confusion_matrix(y_info['true'], y_info['pred'], sorted_cats)\n      df_conf = pd.DataFrame(conf_mat, index=sorted_cats, columns=sorted_cats)\n\n      total_correct = np.trace(df_conf)\n      total_pred = df_conf.sum().sum()\n      fraction_correct = total_correct/float(total_pred)\n\n      # calculate ser_correct\n      correct_list = []\n      cat_counts = df_conf.sum(axis=1)\n      all_cols = df_conf.columns.tolist()\n      for inst_cat in all_cols:\n          inst_correct = df_conf[inst_cat].loc[inst_cat] / cat_counts[inst_cat]\n          correct_list.append(inst_correct)\n\n      ser_correct = pd.Series(data=correct_list, index=all_cols)\n\n      populations = {}\n      populations['true'] = true_count\n      populations['pred'] = pred_count\n\n      return df_conf, populations, ser_correct, fraction_correct\n\n  def compare_performance_to_shuffled_labels(self, df_data, category_level, num_shuffles=100,\n                                             random_seed=99, pval_cutoff=0.05, dist_type='cosine',\n                                             num_top_dims=False, predict_level='Predict Category',\n                                             truth_level=1, unknown_thresh=-1, equal_var=False,\n                                             performance_type='prediction'):\n      random.seed(random_seed)\n\n      perform_list = []\n      num_shuffles = num_shuffles\n\n      # pre-calculate the distance matrix (similarity matrix) if necessary\n      if performance_type == 'cat_sim_auc':\n          dist_arr = 1 - pdist(df_data.transpose(), metric=dist_type)\n\n      for inst_run in range(num_shuffles + 1):\n\n          cols = df_data.columns.tolist()\n          rows = df_data.index.tolist()\n          mat = df_data.values\n\n          shuffled_cols = deepcopy(cols)\n          random.shuffle(shuffled_cols)\n\n          # do not perform shuffling the first time to confirm that we get the same\n          # results as the unshuffled dataaset\n          if inst_run == 0:\n              df_shuffle = deepcopy(df_data)\n          else:\n              df_shuffle = pd.DataFrame(data=mat, columns=shuffled_cols, index=rows)\n\n          # generate signature on shuffled data\n          df_sig, keep_genes, keep_genes_dict, fold_info = generate_signatures(df_shuffle,\n                                                             category_level,\n                                                             pval_cutoff=pval_cutoff,\n                                                             num_top_dims=num_top_dims,\n                                                             equal_var=equal_var)\n\n          # predictive performance\n          if performance_type == 'prediction':\n\n              # predict categories from signature\n              df_pred_cat, df_sig_sim, y_info = self.predict_cats_from_sigs(df_shuffle, df_sig,\n                  dist_type=dist_type, predict_level=predict_level, truth_level=truth_level,\n                  unknown_thresh=unknown_thresh)\n\n              # calc confusion matrix and performance\n              df_conf, populations, ser_correct, fraction_correct = self.confusion_matrix_and_correct_series(y_info)\n\n              # store performances of shuffles\n              if inst_run &gt; 0:\n                  perform_list.append(fraction_correct)\n              else:\n                  real_performance = fraction_correct\n                  print('performance (fraction correct) of unshuffled: ' + str(fraction_correct))\n\n          elif performance_type == 'cat_sim_auc':\n\n              # predict categories from signature\n              sim_dict, pval_dict, roc_data = self.sim_same_and_diff_category_samples(df_shuffle,\n                  cat_index=1, plot_roc=False, equal_var=equal_var, precalc_dist=dist_arr)\n\n              # store performances of shuffles\n              if inst_run &gt; 0:\n                  perform_list.append(roc_data['auc'])\n              else:\n                  real_performance = roc_data['auc']\n                  print('performance (category similarity auc) of unshuffled: ' + str(roc_data['auc']))\n\n      perform_ser = pd.Series(perform_list)\n\n      in_top_fraction = perform_ser[perform_ser &gt; real_performance].shape[0]/num_shuffles\n      print('real data performs in the top ' + str(in_top_fraction*100) + '% of shuffled labels\\n')\n\n      return perform_ser\n\n  @staticmethod\n  def box_scatter_plot(df, group, columns=False, rand_seed=100, alpha=0.5,\n      dot_color='red', num_row=None, num_col=1, figsize=(10,10),\n      start_title='Variable Measurements Across', end_title='Groups',\n      group_list=False):\n\n      from scipy import stats\n      import pandas as pd\n\n      import matplotlib.pyplot as plt\n      # %matplotlib inline\n\n      if columns == False:\n          columns = df.columns.tolist()\n\n      plt.figure(figsize=figsize)\n      figure_title = start_title + ' ' + group + ' ' + end_title\n      plt.suptitle(figure_title, fontsize=20)\n\n      # list of arranged dataframes\n      dfs = {}\n\n      for col_num in range(len(columns)):\n          column = columns[col_num]\n          plot_id = col_num + 1\n\n          # group by column name or multiIndex name\n          if group in df.columns.tolist():\n              grouped = df.groupby(group)\n          else:\n              grouped = df.groupby(level=group)\n\n          names, vals, xs = [], [] ,[]\n\n          if type(column) is tuple:\n              column_title = column[0]\n          else:\n              column_title = column\n\n          for i, (name, subdf) in enumerate(grouped):\n\n              names.append(name)\n\n              inst_ser = subdf[column]\n\n              column_name = column_title + '-' + str(name)\n\n              inst_ser.name = column_name\n              vals.append(inst_ser)\n\n              np.random.seed(rand_seed)\n              xs.append(np.random.normal(i+1, 0.04, subdf.shape[0]))\n\n          ax = plt.subplot(num_row, num_col, plot_id)\n\n          plt.boxplot(vals, labels=names)\n\n          ngroup = len(vals)\n\n          clevels = np.linspace(0., 1., ngroup)\n\n          for x, val, clevel in zip(xs, vals, clevels):\n\n              plt.subplot(num_row, num_col, plot_id)\n              plt.scatter(x, val, c=dot_color, alpha=alpha)\n\n\n          df_arranged = pd.concat(vals, axis=1)\n\n          # anova\n          anova_data = [df_arranged[col].dropna() for col in df_arranged]\n          f_val, pval = stats.f_oneway(*anova_data)\n\n          if pval &lt; 0.01:\n              ax.set_title(column_title + ' P-val: ' + '{:.2e}'.format(pval))\n          else:\n              pval = round(pval * 100000)/100000\n              ax.set_title(column_title + ' P-val: ' + str(pval))\n\n          dfs[column] = df_arranged\n\n      return dfs\n\n  @staticmethod\n  def rank_cols_by_anova_pval(df, group, columns=False, rand_seed=100, alpha=0.5, dot_color='red', num_row=None, num_col=1,\n                       figsize=(10,10)):\n\n      from scipy import stats\n      import numpy as np\n      import pandas as pd\n\n      # import matplotlib.pyplot as plt\n      # %matplotlib inline\n\n      if columns == False:\n          columns = df.columns.tolist()\n\n      # plt.figure(figsize=figsize)\n\n      # list of arranged dataframes\n      dfs = {}\n\n      pval_list = []\n\n      for col_num in range(len(columns)):\n          column = columns[col_num]\n          plot_id = col_num + 1\n\n          # group by column name or multiIndex name\n          if group in df.columns.tolist():\n              grouped = df.groupby(group)\n          else:\n              grouped = df.groupby(level=group)\n\n          names, vals, xs = [], [] ,[]\n\n          if type(column) is tuple:\n              column_title = column[0]\n          else:\n              column_title = column\n\n          for i, (name, subdf) in enumerate(grouped):\n              names.append(name)\n\n              inst_ser = subdf[column]\n\n              column_name = column_title + '-' + str(name)\n\n              inst_ser.name = column_name\n              vals.append(inst_ser)\n\n              np.random.seed(rand_seed)\n              xs.append(np.random.normal(i+1, 0.04, subdf.shape[0]))\n\n\n          ngroup = len(vals)\n\n          df_arranged = pd.concat(vals, axis=1)\n\n          # anova\n          anova_data = [df_arranged[col].dropna() for col in df_arranged]\n          f_val, pval = stats.f_oneway(*anova_data)\n\n          pval_list.append(pval)\n\n      pval_ser = pd.Series(data=pval_list, index=columns)\n      pval_ser = pval_ser.sort_values(ascending=True)\n\n      return pval_ser\n\n\n  def row_tuple_to_multiindex(self, df):\n\n      import pandas as pd\n\n      from copy import deepcopy\n      df_mi = deepcopy(df)\n      rows = df_mi.index.tolist()\n      titles = []\n      for inst_part in rows[0]:\n\n          if ': ' in inst_part:\n              inst_title = inst_part.split(': ')[0]\n          else:\n              inst_title = 'Name'\n          titles.append(inst_title)\n\n      new_rows = []\n      for inst_row in rows:\n          inst_row = list(inst_row)\n          new_row = []\n          for inst_part in inst_row:\n              if ': ' in inst_part:\n                  inst_part = inst_part.split(': ')[1]\n              new_row.append(inst_part)\n          new_row = tuple(new_row)\n          new_rows.append(new_row)\n\n      df_mi.index = new_rows\n\n      df_mi.index = pd.MultiIndex.from_tuples(df_mi.index, names=titles)\n\n      return df_mi\n\n  def set_cat_colors(self, cat_colors, axis, cat_index, cat_title=False):\n      for inst_ct in cat_colors:\n          if cat_title != False:\n              cat_name = cat_title + ': ' + inst_ct\n          else:\n              cat_name = inst_ct\n\n          inst_color = cat_colors[inst_ct]\n          self.set_cat_color(axis=axis, cat_index=cat_index, cat_name=cat_name, inst_color=inst_color)\n\n  def set_manual_category(self, col=None, row=None, preferred_cats=None):\n    '''\n    This method is used to tell Clustergrammer2 that the user wants to define\n    a manual category interactively using the dendrogram.\n    '''\n\n    self.dat['manual_category'] = {}\n    self.dat['manual_category']['col'] = col\n    self.dat['manual_category']['row'] = row\n\n    if preferred_cats is not None:\n      pref_cats = []\n      for inst_row in preferred_cats.index.tolist():\n          inst_dict = {}\n          inst_dict['name'] = inst_row\n          inst_dict['color'] = preferred_cats.loc[inst_row, 'color']\n          pref_cats.append(inst_dict)\n\n      if col is not None:\n        self.dat['manual_category']['col_cats'] = pref_cats\n\n      if row is not None:\n        self.dat['manual_category']['row_cats'] = pref_cats\n\n  def ds_to_original_meta(self, axis):\n    clusters = self.meta_ds_col.index.tolist()\n\n    man_cat_title = self.dat['manual_category'][axis]\n\n    for inst_cluster in clusters:\n\n        # get the manual category from the downsampled data\n        inst_man_cat = self.meta_ds_col.loc[inst_cluster, man_cat_title]\n\n        # find original labels that are assigned to this cluster\n        found_labels = self.meta_col[self.meta_col[self.ds_name] == inst_cluster].index.tolist()\n\n        # update manual category\n        self.meta_col.loc[found_labels, man_cat_title] = inst_man_cat\n\n  def get_manual_category(self, tmp):\n\n\n    for axis in ['col']:\n\n      try:\n      ###########################################################\n\n        export_dict = {}\n\n        inst_nodes = self.dat['nodes'][axis]\n        # print('get get_manual_category', len(inst_nodes))\n\n        cat_title = self.dat['manual_category'][axis]\n\n        # Category Names\n        try:\n        ###########################################################\n\n          export_dict[cat_title] = pd.Series(json.loads(self.widget_instance.manual_cat)[axis][cat_title])\n\n          if hasattr(self, 'meta_cat') == True:\n\n            if axis == 'row':\n              if self.is_downsampled == False:\n                self.meta_row.loc[inst_nodes, cat_title] = export_dict[cat_title]\n              else:\n                self.meta_ds_row.loc[inst_nodes, cat_title] = export_dict[cat_title]\n                self.ds_to_original_meta(axis)\n\n            elif axis == 'col':\n              if self.is_downsampled == False:\n                # print('&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; ')\n                # print(export_dict[cat_title])\n\n                # print('.. .. .. .. .. .. .. .. .. .. .. .. ')\n                # print(self.meta_col)\n\n                # # for some reason this is breaking when trying to sync metadata\n                # # switching to slower row based syncing\n                # self.meta_col.loc[inst_nodes, cat_title] = export_dict[cat_title]\n\n                # manually looping through rows in metadata works\n                for inst_row in export_dict[cat_title].index.tolist():\n                  self.meta_col.loc[inst_row, cat_title] = export_dict[cat_title][inst_row]\n\n                # print('&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;')\n                # print(self.meta_col)\n\n              else:\n                self.meta_ds_col.loc[inst_nodes, cat_title] = export_dict[cat_title]\n                self.ds_to_original_meta(axis)\n\n\n        except:\n          print('unable to load', axis ,' category, please check title')\n\n        # Category Colors\n        #######################\n        export_dict['cat_colors'] = json.loads(self.widget_instance.manual_cat)['global_cat_colors']\n\n        # # drop title from category colors\n        # export_dict['cat_colors'] = {}\n        # for inst_cat in ini_new_colors:\n        #   if (': ' in inst_cat):\n        #     export_dict['cat_colors'][inst_cat.split(': ')[1]] = ini_new_colors[inst_cat]\n        #   else:\n        #     export_dict['cat_colors'][inst_cat] = ini_new_colors[inst_cat]\n\n        # if hasattr(self, 'meta_cat') == False:\n        #   return export_dict\n\n      except:\n          # print('failed to parse manual_category')\n          pass\n\n\n  @staticmethod\n  def umi_norm(df):\n      # umi norm\n      barcode_umi_sum = df.sum()\n      df_umi = df.div(barcode_umi_sum)\n      return df_umi\n\n  @staticmethod\n  def make_df_from_cols(cols):\n    inst_col = cols[0]\n\n    cat_titles = []\n    for inst_info in inst_col[1:]:\n        inst_title = inst_info.split(': ')[0]\n        cat_titles.append(inst_title)\n\n    clean_cols = []\n    for inst_col in cols:\n        inst_clean = []\n        for inst_info in inst_col:\n            if ': ' in inst_info:\n                inst_clean.append(inst_info.split(': ')[1])\n            else:\n                inst_clean.append(inst_info)\n        clean_cols.append(tuple(inst_clean))\n\n    df_ini = pd.DataFrame(data=clean_cols).set_index(0)\n    mat = df_ini.values\n    rows = df_ini.index.tolist()\n\n    df_meta = pd.DataFrame(data=mat, index=rows, columns=cat_titles)\n\n    return df_meta\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.add_cats","title":"<code>add_cats(axis, cat_data)</code>","text":"<p>Add categories to rows or columns using cat_data array of objects. Each object in cat_data is a dictionary with one key (category title) and value (rows/column names) that have this category. Categories will be added onto the existing categories and will be added in the order of the objects in the array.</p> <p>Example <code>cat_data</code>::</p> <pre><code>[\n  {\n    \"title\": \"First Category\",\n    \"cats\": {\n      \"true\": [\n        \"ROS1\",\n        \"AAK1\"\n      ]\n    }\n  },\n  {\n    \"title\": \"Second Category\",\n    \"cats\": {\n      \"something\": [\n        \"PDK4\"\n      ]\n    }\n  }\n]\n</code></pre> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def add_cats(self, axis, cat_data):\n  '''\n  Add categories to rows or columns using cat_data array of objects. Each object in cat_data is a dictionary with one key (category title) and value (rows/column names) that have this category. Categories will be added onto the existing categories and will be added in the order of the objects in the array.\n\n  Example ``cat_data``::\n\n\n      [\n        {\n          \"title\": \"First Category\",\n          \"cats\": {\n            \"true\": [\n              \"ROS1\",\n              \"AAK1\"\n            ]\n          }\n        },\n        {\n          \"title\": \"Second Category\",\n          \"cats\": {\n            \"something\": [\n              \"PDK4\"\n            ]\n          }\n        }\n      ]\n\n\n  '''\n  for inst_data in cat_data:\n    categories.add_cats(self, axis, inst_data)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.assess_prediction","title":"<code>assess_prediction(df_meta, truth, pred)</code>","text":"<p>Generate confusion matrix from y_info</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def assess_prediction(self, df_meta, truth, pred):\n    ''' Generate confusion matrix from y_info '''\n\n    y_info = {}\n    y_info['true'] = df_meta[truth].values.tolist()\n    y_info['pred'] = df_meta[pred].values.tolist()\n\n    sorted_cats = sorted(list(set(y_info['true'] + y_info['pred'])))\n    conf_mat = confusion_matrix(y_info['true'], y_info['pred'], labels=sorted_cats)\n\n    # true columns and pred rows\n    df_conf = pd.DataFrame(conf_mat, index=sorted_cats, columns=sorted_cats).transpose()\n\n    total_correct = np.trace(df_conf)\n    total_pred = df_conf.sum().sum()\n    fraction_correct = total_correct/float(total_pred)\n\n    # calculate ser_correct\n    correct_list = []\n    cat_counts = df_conf.sum(axis=0)\n    all_cols = df_conf.columns.tolist()\n    for inst_cat in all_cols:\n        inst_correct = df_conf.loc[inst_cat, inst_cat] / cat_counts[inst_cat]\n        correct_list.append(inst_correct)\n\n    ser_correct = pd.Series(data=correct_list, index=all_cols)\n\n    return df_conf, ser_correct, fraction_correct\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.clip","title":"<code>clip(lower=None, upper=None)</code>","text":"<p>Trim values at input thresholds using pandas function</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def clip(self, lower=None, upper=None):\n  '''\n  Trim values at input thresholds using pandas function\n  '''\n  df = self.export_df()\n  df = df.clip(lower=lower, upper=upper)\n  self.load_df(df)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.cluster","title":"<code>cluster(dist_type='cosine', run_clustering=True, dendro=True, views=[], linkage_type='average', sim_mat=False, filter_sim=0.0, calc_cat_pval=False, run_enrichr=None, enrichrgram=None, clust_library='scipy', min_samples=1, min_cluster_size=2)</code>","text":"<p>The main function performs hierarchical clustering, optionally generates filtered views (e.g. row-filtered views), and generates the : <code>visualization_json</code>.</p> <p>Used to set views equal to ['N_row_sum', 'N_row_var']</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def cluster(self, dist_type='cosine', run_clustering=True,\n               dendro=True, views=[],\n               linkage_type='average', sim_mat=False, filter_sim=0.0,\n               calc_cat_pval=False, run_enrichr=None, enrichrgram=None,\n               clust_library='scipy', min_samples=1, min_cluster_size=2):\n  '''\n  The main function performs hierarchical clustering, optionally generates\n  filtered views (e.g. row-filtered views), and generates the :\n  ``visualization_json``.\n\n  Used to set views equal to ['N_row_sum', 'N_row_var']\n  '''\n  initialize_net.viz(self)\n\n  make_clust_fun.make_clust(self, dist_type=dist_type,\n                                  run_clustering=run_clustering,\n                                  dendro=dendro,\n                                  requested_views=views,\n                                  linkage_type=linkage_type,\n                                  sim_mat=sim_mat,\n                                  filter_sim=filter_sim,\n                                  calc_cat_pval=calc_cat_pval,\n                                  run_enrichr=run_enrichr,\n                                  enrichrgram=enrichrgram,\n                                  clust_library=clust_library,\n                                  min_samples=min_samples,\n                                  min_cluster_size=min_cluster_size)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.dat_to_df","title":"<code>dat_to_df()</code>","text":"<p>Export Pandas DataFrams (will be deprecated).</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def dat_to_df(self):\n  '''\n  Export Pandas DataFrams (will be deprecated).\n  '''\n  return data_formats.dat_to_df(self)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.df_to_dat","title":"<code>df_to_dat(df, define_cat_colors=False)</code>","text":"<p>Load Pandas DataFrame (will be deprecated).</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def df_to_dat(self, df, define_cat_colors=False):\n  '''\n  Load Pandas DataFrame (will be deprecated).\n  '''\n  data_formats.df_to_dat(self, df, define_cat_colors)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.downsample","title":"<code>downsample(df=None, ds_type='kmeans', axis='row', num_samples=100, random_state=1000, ds_name='Downsample', ds_cluster_name='cluster')</code>","text":"<p>Downsample the matrix rows or columns (currently supporting kmeans only). Users can optionally pass in a DataFrame to be downsampled (and this will be incorporated into the network object).</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def downsample(self, df=None, ds_type='kmeans', axis='row', num_samples=100,\n               random_state=1000, ds_name='Downsample',\n               ds_cluster_name='cluster'):\n  '''\n  Downsample the matrix rows or columns (currently supporting kmeans only). Users can optionally pass in a DataFrame to be downsampled (and this will be incorporated into the network object).\n  '''\n  return downsample_fun.main(self, df, ds_type, axis, num_samples, random_state, ds_name, ds_cluster_name)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.enrichrgram","title":"<code>enrichrgram(lib, axis='row')</code>","text":"<p>Add Enrichr gene enrichment results to your visualization (where your rows are genes). Run enrichrgram before clustering to incldue enrichment results as row categories. Enrichrgram can also be run on the front-end using the Enrichr logo at the top left.</p> <p>Set lib to the Enrichr library that you want to use for enrichment analysis. Libraries included:</p> <ul> <li>ChEA_2016</li> <li>KEA_2015</li> <li>ENCODE_TF_ChIP-seq_2015</li> <li>ENCODE_Histone_Modifications_2015</li> <li>Disease_Perturbations_from_GEO_up</li> <li>Disease_Perturbations_from_GEO_down</li> <li>GO_Molecular_Function_2015</li> <li>GO_Biological_Process_2015</li> <li>GO_Cellular_Component_2015</li> <li>Reactome_2016</li> <li>KEGG_2016</li> <li>MGI_Mammalian_Phenotype_Level_4</li> <li>LINCS_L1000_Chem_Pert_up</li> <li>LINCS_L1000_Chem_Pert_down</li> </ul> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def enrichrgram(self, lib, axis='row'):\n  '''\n  Add Enrichr gene enrichment results to your visualization (where your rows\n  are genes). Run enrichrgram before clustering to incldue enrichment results\n  as row categories. Enrichrgram can also be run on the front-end using the\n  Enrichr logo at the top left.\n\n  Set lib to the Enrichr library that you want to use for enrichment analysis.\n  Libraries included:\n\n    * ChEA_2016\n    * KEA_2015\n    * ENCODE_TF_ChIP-seq_2015\n    * ENCODE_Histone_Modifications_2015\n    * Disease_Perturbations_from_GEO_up\n    * Disease_Perturbations_from_GEO_down\n    * GO_Molecular_Function_2015\n    * GO_Biological_Process_2015\n    * GO_Cellular_Component_2015\n    * Reactome_2016\n    * KEGG_2016\n    * MGI_Mammalian_Phenotype_Level_4\n    * LINCS_L1000_Chem_Pert_up\n    * LINCS_L1000_Chem_Pert_down\n\n  '''\n\n  df = self.export_df()\n  df, bar_info = enr_fun.add_enrichr_cats(df, axis, lib)\n  self.load_df(df)\n\n  self.dat['enrichrgram_lib'] = lib\n  self.dat['row_cat_bars'] = bar_info\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.export_df","title":"<code>export_df()</code>","text":"<p>Export Pandas DataFrame/</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def export_df(self):\n  '''\n  Export Pandas DataFrame/\n  '''\n  df = data_formats.dat_to_df(self)\n\n  # drop tuple categories if downsampling\n  if self.is_downsampled:\n    df.columns = self.dat['nodes']['col']\n    df.index = self.dat['nodes']['row']\n\n  return df\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.export_net_json","title":"<code>export_net_json(net_type='viz', indent='no-indent')</code>","text":"<p>Export dat or viz JSON.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def export_net_json(self, net_type='viz', indent='no-indent'):\n  '''\n  Export dat or viz JSON.\n  '''\n  return export_data.export_net_json(self, net_type, indent)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.export_viz_to_widget","title":"<code>export_viz_to_widget(which_viz='viz')</code>","text":"<p>Export viz JSON, for use with clustergrammer_widget. Formerly method was named widget.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def export_viz_to_widget(self, which_viz='viz'):\n  '''\n  Export viz JSON, for use with clustergrammer_widget. Formerly method was\n  named widget.\n  '''\n\n  return export_data.export_net_json(self, which_viz, 'no-indent')\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.filter_N_top","title":"<code>filter_N_top(N_top, rank_type='sum', inst_rc=None, axis=None)</code>","text":"<p>Filter the matrix rows or columns based on sum/variance, and only keep the top N.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def filter_N_top(self, N_top, rank_type='sum', inst_rc=None, axis=None):\n  '''\n  Filter the matrix rows or columns based on sum/variance, and only keep the top\n  N.\n  '''\n\n  if axis is None:\n    axis = inst_rc\n    print('warning inst_rc argument will be deprecated, please use axis')\n\n    if inst_rc is None:\n      print('please provide axis argument')\n\n  inst_df = self.dat_to_df()\n\n  inst_df = run_filter.filter_N_top(inst_rc, inst_df, N_top, rank_type)\n\n  self.df_to_dat(inst_df)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.filter_cat","title":"<code>filter_cat(axis, cat_index, cat_name)</code>","text":"<p>Filter the matrix based on their category. cat_index is the index of the category, the first category has index=1.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def filter_cat(self, axis, cat_index, cat_name):\n  '''\n  Filter the matrix based on their category. cat_index is the index of the category, the first category has index=1.\n  '''\n  run_filter.filter_cat(self, axis, cat_index, cat_name)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.filter_names","title":"<code>filter_names(axis, names)</code>","text":"<p>Filter the visualization using row/column names. The function takes, axis ('row'/'col') and names, a list of strings.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def filter_names(self, axis, names):\n  '''\n  Filter the visualization using row/column names. The function takes, axis ('row'/'col') and names, a list of strings.\n  '''\n  run_filter.filter_names(self, axis, names)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.filter_sum","title":"<code>filter_sum(threshold, take_abs=True, axis=None, inst_rc=None)</code>","text":"<p>Filter a network's rows or columns based on the sum across rows or columns.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def filter_sum(self, threshold, take_abs=True, axis=None, inst_rc=None):\n  '''\n  Filter a network's rows or columns based on the sum across rows or columns.\n  '''\n\n  if axis is None:\n    axis = inst_rc\n    print('warning inst_rc argument will be deprecated, please use axis')\n\n    if inst_rc is None:\n      print('please provide axis argument')\n\n  inst_df = self.dat_to_df()\n  if axis == 'row':\n    inst_df = run_filter.df_filter_row_sum(inst_df, threshold, take_abs)\n  elif axis == 'col':\n    inst_df = run_filter.df_filter_col_sum(inst_df, threshold, take_abs)\n  self.df_to_dat(inst_df)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.filter_threshold","title":"<code>filter_threshold(threshold, num_occur=1, inst_rc=None, axis=None)</code>","text":"<p>Filter the matrix rows or columns based on num_occur values being above a threshold (in absolute value).</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def filter_threshold(self, threshold, num_occur=1, inst_rc=None, axis=None):\n  '''\n  Filter the matrix rows or columns based on num_occur values being above a\n  threshold (in absolute value).\n  '''\n\n  if axis is None:\n    axis = inst_rc\n    print('warning inst_rc argument will be deprecated, please use axis')\n\n    if inst_rc is None:\n      print('please provide axis argument')\n\n  inst_df = self.dat_to_df()\n\n  inst_df = run_filter.filter_threshold(inst_df, axis, threshold,\n    num_occur)\n\n  self.df_to_dat(inst_df)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.generate_signatures","title":"<code>generate_signatures(df_data, df_meta, category_name, pval_cutoff=0.05, num_top_dims=False, verbose=True, equal_var=False)</code>","text":"<p>Generate signatures for column categories T-test is run for each category in a one-vs-all manner. The num_top_dims overrides the P-value cutoff.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def generate_signatures(self, df_data, df_meta, category_name, pval_cutoff=0.05,\n                        num_top_dims=False, verbose=True, equal_var=False):\n\n    '''\n    Generate signatures for column categories\n    T-test is run for each category in a one-vs-all manner. The num_top_dims overrides\n    the P-value cutoff.\n    '''\n\n    df_t = df_data.transpose()\n\n    # remove columns (dimensions) with constant values\n    orig_num_cols = df_t.shape[1]\n    df_t = df_t.loc[:, (df_t != df_t.iloc[0]).any()]\n    if df_t.shape[1] &lt; orig_num_cols:\n      print('dropped columns with constant values')\n\n    # make tuple rows\n    df_t.index = [(x, df_meta.loc[x, category_name]) for x in df_t.index.tolist()]\n    category_level = 1\n\n    df = self.row_tuple_to_multiindex(df_t)\n\n    cell_types = sorted(list(set(df.index.get_level_values(category_level).tolist())))\n\n    keep_genes = []\n    keep_genes_dict = {}\n    gene_pval_dict = {}\n    all_fold_info = {}\n\n    for inst_ct in cell_types:\n\n        inst_ct_mat = df.xs(key=inst_ct, level=category_level)\n        inst_other_mat = df.drop(inst_ct, level=category_level)\n\n        # save mean values and fold change\n        fold_info = {}\n        fold_info['cluster_mean'] = inst_ct_mat.mean()\n        fold_info['other_mean'] = inst_other_mat.mean()\n        fold_info['log2_fold'] = fold_info['cluster_mean']/fold_info['other_mean']\n        fold_info['log2_fold'] = fold_info['log2_fold'].apply(np.log2)\n        all_fold_info[inst_ct] = fold_info\n\n        inst_stats, inst_pvals = ttest_ind(inst_ct_mat, inst_other_mat, axis=0, equal_var=equal_var)\n\n        ser_pval = pd.Series(data=inst_pvals, index=df.columns.tolist()).sort_values()\n\n        if num_top_dims == False:\n            ser_pval_keep = ser_pval[ser_pval &lt; pval_cutoff]\n        else:\n            ser_pval_keep = ser_pval[:num_top_dims]\n\n        gene_pval_dict[inst_ct] = ser_pval_keep\n\n        inst_keep = ser_pval_keep.index.tolist()\n        keep_genes.extend(inst_keep)\n        keep_genes_dict[inst_ct] = inst_keep\n\n    keep_genes = sorted(list(set(keep_genes)))\n\n    df_gbm = df.groupby(level=category_level).mean().transpose()\n    cols = df_gbm.columns.tolist()\n\n    df_sig = df_gbm.loc[keep_genes]\n\n    if len(keep_genes) == 0 and verbose:\n        print('found no informative dimensions')\n\n    df_gene_pval = pd.concat(gene_pval_dict, axis=1, sort=False)\n\n    df_diff = {}\n    for inst_col in df_gene_pval:\n\n        inst_pvals = df_gene_pval[inst_col]\n\n        # nans represent dimensions that did not meet pval or top threshold\n        inst_pvals = inst_pvals.dropna().sort_values()\n\n        inst_genes = inst_pvals.index.tolist()\n\n        # prevent failure if no cells have this category\n        if inst_pvals.shape[0] &gt; 0:\n            rej, pval_corr = smm.multipletests(inst_pvals, 0.05, method='fdr_bh')[:2]\n\n            ser_pval = pd.Series(data=inst_pvals, index=inst_genes, name='P-values')\n            ser_bh_pval = pd.Series(data=pval_corr, index=inst_genes, name='BH P-values')\n            ser_log2_fold = all_fold_info[inst_col]['log2_fold'].loc[inst_genes]\n            ser_log2_fold.name = 'Log2 Fold Change'\n            ser_cluster_mean = all_fold_info[inst_col]['cluster_mean'].loc[inst_genes]\n            ser_cluster_mean.name = 'Cluster Mean'\n            ser_other_mean = all_fold_info[inst_col]['other_mean'].loc[inst_genes]\n            ser_other_mean.name = 'All Other Mean'\n            inst_df = pd.concat([ser_pval, ser_bh_pval, ser_log2_fold, ser_cluster_mean, ser_other_mean], axis=1)\n\n            df_diff[inst_col] = inst_df\n\n    return df_sig, df_diff\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.load_data_file_to_net","title":"<code>load_data_file_to_net(filename)</code>","text":"<p>Load Clustergrammer's dat format (saved as JSON).</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def load_data_file_to_net(self, filename):\n  '''\n  Load Clustergrammer's dat format (saved as JSON).\n  '''\n  inst_dat = self.load_json_to_dict(filename)\n  load_data.load_data_to_net(self, inst_dat)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.load_df","title":"<code>load_df(df_ini, meta_col=None, meta_row=None, col_cats=None, row_cats=None, is_downsampled=False, meta_ds_row=None, meta_ds_col=None)</code>","text":"<p>Load Pandas DataFrame.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def load_df(self, df_ini, meta_col=None, meta_row=None, col_cats=None,\n            row_cats=None, is_downsampled=False, meta_ds_row=None,\n            meta_ds_col=None):\n  '''\n  Load Pandas DataFrame.\n  '''\n  self.reset()\n\n  # load dataframe\n  df = deepcopy(df_ini)\n\n\n  if is_downsampled:\n    if meta_ds_col is not None:\n      self.meta_ds_col = meta_ds_col\n    if meta_ds_row is not None:\n      self.meta_ds_row = meta_ds_row\n\n  # define downsampled status\n  self.is_downsampled = is_downsampled\n  # print('load_df: is_downsampled', is_downsampled)\n\n  if hasattr(self, 'meta_col') == False and hasattr(self, 'meta_row') == False:\n    self.meta_cat = False\n\n  # load metadata\n  if isinstance(meta_col, pd.DataFrame):\n    self.meta_col = meta_col\n\n    if col_cats is None:\n      self.col_cats = meta_col.columns.tolist()\n    else:\n      self.col_cats = col_cats\n\n    self.meta_cat = True\n\n  if isinstance(meta_row, pd.DataFrame):\n    self.meta_row = meta_row\n\n    if row_cats is None:\n      self.row_cats = meta_row.columns.tolist()\n    else:\n      self.row_cats = row_cats\n\n    self.meta_cat = True\n\n  data_formats.df_to_dat(self, df, define_cat_colors=True)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.load_file","title":"<code>load_file(filename)</code>","text":"<p>Load TSV file.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def load_file(self, filename):\n  '''\n  Load TSV file.\n  '''\n  load_data.load_file(self, filename)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.load_file_as_string","title":"<code>load_file_as_string(file_string, filename='')</code>","text":"<p>Load file as a string.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def load_file_as_string(self, file_string, filename=''):\n  '''\n  Load file as a string.\n  '''\n  load_data.load_file_as_string(self, file_string, filename=filename)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.load_gene_exp_to_df","title":"<code>load_gene_exp_to_df(inst_path)</code>  <code>staticmethod</code>","text":"<p>Loads gene expression data from 10x in sparse matrix format and returns a Pandas dataframe</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>@staticmethod\ndef load_gene_exp_to_df(inst_path):\n  '''\n  Loads gene expression data from 10x in sparse matrix format and returns a\n  Pandas dataframe\n  '''\n\n  import pandas as pd\n  from scipy import io\n  from scipy import sparse\n  from ast import literal_eval as make_tuple\n\n  # matrix\n  Matrix = io.mmread( inst_path + 'matrix.mtx')\n  mat = Matrix.todense()\n\n  # genes\n  filename = inst_path + 'genes.tsv'\n  f = open(filename, 'r')\n  lines = f.readlines()\n  f.close()\n\n  # # add unique id to all genes\n  # genes = []\n  # unique_id = 0\n  # for inst_line in lines:\n  #     inst_line = inst_line.strip().split()\n\n  #     if len(inst_line) &gt; 1:\n  #       inst_gene = inst_line[1]\n  #     else:\n  #       inst_gene = inst_line[0]\n\n  #     genes.append(inst_gene + '_' + str(unique_id))\n  #     unique_id = unique_id + 1\n\n  # add unique id only to duplicate genes\n  ini_genes = []\n  for inst_line in lines:\n      inst_line = inst_line.strip().split()\n      if len(inst_line) &gt; 1:\n        inst_gene = inst_line[1]\n      else:\n        inst_gene = inst_line[0]\n      ini_genes.append(inst_gene)\n\n  gene_name_count = pd.Series(ini_genes).value_counts()\n  duplicate_genes = gene_name_count[gene_name_count &gt; 1].index.tolist()\n\n  dup_index = {}\n  genes = []\n  for inst_row in ini_genes:\n\n    # add index to non-unique genes\n    if inst_row in duplicate_genes:\n\n      # calc_non-unque index\n      if inst_row not in dup_index:\n        dup_index[inst_row] = 1\n      else:\n        dup_index[inst_row] = dup_index[inst_row] + 1\n\n      new_row = inst_row + '_' + str(dup_index[inst_row])\n\n    else:\n      new_row = inst_row\n\n    genes.append(new_row)\n\n  # barcodes\n  filename = inst_path + 'barcodes.tsv'\n  f = open(filename, 'r')\n  lines = f.readlines()\n  f.close()\n\n  cell_barcodes = []\n  for inst_bc in lines:\n      inst_bc = inst_bc.strip().split('\\t')\n\n      # remove dash from barcodes if necessary\n      if '-' in inst_bc[0]:\n        inst_bc[0] = inst_bc[0].split('-')[0]\n\n      cell_barcodes.append(inst_bc[0])\n\n  # parse tuples if necessary\n  try:\n      cell_barcodes = [make_tuple(x) for x in cell_barcodes]\n  except:\n      pass\n\n  try:\n      genes = [make_tuple(x) for x in genes]\n  except:\n      pass\n\n  # make dataframe\n  df = pd.DataFrame(mat, index=genes, columns=cell_barcodes)\n\n  return df\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.load_stdin","title":"<code>load_stdin()</code>","text":"<p>Load stdin TSV-formatted string.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def load_stdin(self):\n  '''\n  Load stdin TSV-formatted string.\n  '''\n  load_data.load_stdin(self)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.load_tsv_to_net","title":"<code>load_tsv_to_net(file_buffer, filename=None)</code>","text":"<p>This will load a TSV matrix file buffer; this is exposed so that it will be possible to load data without having to read from a file.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def load_tsv_to_net(self, file_buffer, filename=None):\n  '''\n  This will load a TSV matrix file buffer; this is exposed so that it will\n  be possible to load data without having to read from a file.\n  '''\n  load_data.load_tsv_to_net(self, file_buffer, filename)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.load_vect_post_to_net","title":"<code>load_vect_post_to_net(vect_post)</code>","text":"<p>Load data in the vector format JSON.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def load_vect_post_to_net(self, vect_post):\n  '''\n  Load data in the vector format JSON.\n  '''\n  load_vect_post.main(self, vect_post)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.normalize","title":"<code>normalize(df=None, norm_type='zscore', axis='row', z_clip=None)</code>","text":"<p>Normalize the matrix rows or columns using Z-score (zscore) or Quantile Normalization (qn). Users can optionally pass in a DataFrame to be normalized (and this will be incorporated into the Network object).</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def normalize(self, df=None, norm_type='zscore', axis='row', z_clip=None):\n  '''\n  Normalize the matrix rows or columns using Z-score (zscore) or Quantile Normalization (qn). Users can optionally pass in a DataFrame to be normalized (and this will be incorporated into the Network object).\n  '''\n  normalize_fun.run_norm(self, df, norm_type, axis, z_clip)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.old_confusion_matrix_and_correct_series","title":"<code>old_confusion_matrix_and_correct_series(y_info)</code>","text":"<p>Generate confusion matrix from y_info</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def old_confusion_matrix_and_correct_series(self, y_info):\n    ''' Generate confusion matrix from y_info '''\n\n\n    a = deepcopy(y_info['true'])\n    true_count = dict((i, a.count(i)) for i in set(a))\n\n    a = deepcopy(y_info['pred'])\n    pred_count = dict((i, a.count(i)) for i in set(a))\n\n    sorted_cats = sorted(list(set(y_info['true'] + y_info['pred'])))\n    conf_mat = confusion_matrix(y_info['true'], y_info['pred'], sorted_cats)\n    df_conf = pd.DataFrame(conf_mat, index=sorted_cats, columns=sorted_cats)\n\n    total_correct = np.trace(df_conf)\n    total_pred = df_conf.sum().sum()\n    fraction_correct = total_correct/float(total_pred)\n\n    # calculate ser_correct\n    correct_list = []\n    cat_counts = df_conf.sum(axis=1)\n    all_cols = df_conf.columns.tolist()\n    for inst_cat in all_cols:\n        inst_correct = df_conf[inst_cat].loc[inst_cat] / cat_counts[inst_cat]\n        correct_list.append(inst_correct)\n\n    ser_correct = pd.Series(data=correct_list, index=all_cols)\n\n    populations = {}\n    populations['true'] = true_count\n    populations['pred'] = pred_count\n\n    return df_conf, populations, ser_correct, fraction_correct\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.old_generate_signatures","title":"<code>old_generate_signatures(df_ini, category_level, pval_cutoff=0.05, num_top_dims=False, verbose=True, equal_var=False)</code>","text":"<p>Generate signatures for column categories</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def old_generate_signatures(self, df_ini, category_level, pval_cutoff=0.05,\n                        num_top_dims=False, verbose=True, equal_var=False):\n\n    ''' Generate signatures for column categories '''\n\n    # change this to use category name and set caetgory level to 1 always\n    ###################################\n\n    df_t = df_ini.transpose()\n\n    # remove columns with constant values\n    df_t = df_t.loc[:, (df_t != df_t.iloc[0]).any()]\n\n    df = self.row_tuple_to_multiindex(df_t)\n\n    cell_types = sorted(list(set(df.index.get_level_values(category_level).tolist())))\n\n    keep_genes = []\n    keep_genes_dict = {}\n    gene_pval_dict = {}\n    all_fold_info = {}\n\n    for inst_ct in cell_types:\n\n        inst_ct_mat = df.xs(key=inst_ct, level=category_level)\n        inst_other_mat = df.drop(inst_ct, level=category_level)\n\n        # save mean values and fold change\n        fold_info = {}\n        fold_info['cluster_mean'] = inst_ct_mat.mean()\n        fold_info['other_mean'] = inst_other_mat.mean()\n        fold_info['log2_fold'] = fold_info['cluster_mean']/fold_info['other_mean']\n        fold_info['log2_fold'] = fold_info['log2_fold'].apply(np.log2)\n        all_fold_info[inst_ct] = fold_info\n\n        inst_stats, inst_pvals = ttest_ind(inst_ct_mat, inst_other_mat, axis=0, equal_var=equal_var)\n\n        ser_pval = pd.Series(data=inst_pvals, index=df.columns.tolist()).sort_values()\n\n        if num_top_dims == False:\n            ser_pval_keep = ser_pval[ser_pval &lt; pval_cutoff]\n        else:\n            ser_pval_keep = ser_pval[:num_top_dims]\n\n        gene_pval_dict[inst_ct] = ser_pval_keep\n\n        inst_keep = ser_pval_keep.index.tolist()\n        keep_genes.extend(inst_keep)\n        keep_genes_dict[inst_ct] = inst_keep\n\n    keep_genes = sorted(list(set(keep_genes)))\n\n    df_gbm = df.groupby(level=category_level).mean().transpose()\n    cols = df_gbm.columns.tolist()\n    new_cols = []\n    for inst_col in cols:\n        new_col = (inst_col, category_level + ': ' + inst_col)\n        new_cols.append(new_col)\n    df_gbm.columns = new_cols\n\n    df_sig = df_gbm.loc[keep_genes]\n\n    if len(keep_genes) == 0 and verbose:\n        print('found no informative dimensions')\n\n    df_gene_pval = pd.concat(gene_pval_dict, axis=1, sort=False)\n\n    return df_sig, df_gene_pval, all_fold_info\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.old_predict_cats_from_sigs","title":"<code>old_predict_cats_from_sigs(df_data_ini, df_sig_ini, dist_type='cosine', predict_level='Predict Category', truth_level=1, unknown_thresh=-1)</code>","text":"<p>Predict category using signature</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def old_predict_cats_from_sigs(self, df_data_ini, df_sig_ini, dist_type='cosine', predict_level='Predict Category',\n                           truth_level=1, unknown_thresh=-1):\n    ''' Predict category using signature '''\n\n    keep_rows = df_sig_ini.index.tolist()\n    data_rows = df_data_ini.index.tolist()\n\n    common_rows = list(set(data_rows).intersection(keep_rows))\n\n    df_data = deepcopy(df_data_ini.loc[common_rows])\n    df_sig = deepcopy(df_sig_ini.loc[common_rows])\n\n    # calculate sim_mat of df_data and df_sig\n    cell_types = df_sig.columns.tolist()\n    barcodes = df_data.columns.tolist()\n    sim_mat = 1 - pairwise_distances(df_sig.transpose(), df_data.transpose(), metric=dist_type)\n    df_sim = pd.DataFrame(data=sim_mat, index=cell_types, columns=barcodes).transpose()\n\n    # get the top column value (most similar signature)\n    df_sim_top = df_sim.idxmax(axis=1)\n\n    # get the maximum similarity of a cell to a cell type definition\n    max_sim = df_sim.max(axis=1)\n\n    unknown_cells = max_sim[max_sim &lt; unknown_thresh].index.tolist()\n\n    # assign unknown cells (need category of same name)\n    df_sim_top[unknown_cells] = 'Unknown'\n\n    # add predicted category name to top list\n    top_list = df_sim_top.values\n    top_list = [ predict_level + ': ' + x[0] if type(x) is tuple else predict_level + ': ' + x  for x in top_list]\n\n    # add cell type category to input data\n    df_cat = deepcopy(df_data)\n    cols = df_cat.columns.tolist()\n    new_cols = []\n\n    # check whether the columns have the true category available\n    has_truth = False\n    if type(cols[0]) is tuple:\n        has_truth = True\n\n    if has_truth:\n        new_cols = [tuple(list(a) + [b]) for a,b in zip(cols, top_list)]\n    else:\n        new_cols = [tuple([a] + [b]) for a,b in zip(cols, top_list)]\n\n    # transfer new categories\n    df_cat.columns = new_cols\n\n    # keep track of true and predicted labels\n    y_info = {}\n    y_info['true'] = []\n    y_info['pred'] = []\n\n    if has_truth:\n        y_info['true'] = [x[truth_level].split(': ')[1] for x in cols]\n        y_info['pred'] = [x.split(': ')[1] for x in top_list]\n\n    return df_cat, df_sim.transpose(), y_info\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.predict_cats_from_sigs","title":"<code>predict_cats_from_sigs(df_data_ini, df_meta, df_sig_ini, predict='Predicted Category', dist_type='cosine', unknown_thresh=-1)</code>","text":"<p>Predict category using signature</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def predict_cats_from_sigs(self, df_data_ini, df_meta, df_sig_ini,\n                           predict='Predicted Category', dist_type='cosine',\n                           unknown_thresh=-1):\n    ''' Predict category using signature '''\n\n    keep_rows = df_sig_ini.index.tolist()\n    data_rows = df_data_ini.index.tolist()\n\n    common_rows = list(set(data_rows).intersection(keep_rows))\n\n    df_data = deepcopy(df_data_ini.loc[common_rows])\n    df_sig = deepcopy(df_sig_ini.loc[common_rows])\n\n    # calculate sim_mat of df_data and df_sig\n    cell_types = df_sig.columns.tolist()\n    barcodes = df_data.columns.tolist()\n    sim_mat = 1 - pairwise_distances(df_sig.transpose(), df_data.transpose(), metric=dist_type)\n    df_sim = pd.DataFrame(data=sim_mat, index=cell_types, columns=barcodes).transpose()\n\n    # get the top column value (most similar signature)\n    df_sim_top = df_sim.idxmax(axis=1)\n\n    # get the maximum similarity of a cell to a cell type definition\n    max_sim = df_sim.max(axis=1)\n\n    unknown_cells = max_sim[max_sim &lt; unknown_thresh].index.tolist()\n\n    # assign unknown cells (need category of same name)\n    df_sim_top[unknown_cells] = 'Unknown'\n\n    # add predicted category name to top list\n    # top_list = df_sim_top.values\n    df_sim = df_sim.transpose()\n\n    df_meta[predict] = df_sim_top\n\n    return df_sim, df_meta\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.random_sample","title":"<code>random_sample(num_samples, df=None, replace=False, weights=None, random_state=100, axis='row')</code>","text":"<p>Return random sample of matrix.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def random_sample(self, num_samples, df=None, replace=False, weights=None, random_state=100, axis='row'):\n  '''\n  Return random sample of matrix.\n  '''\n\n  if df is None:\n    df = self.dat_to_df()\n\n  if axis == 'row':\n    axis = 0\n  if axis == 'col':\n    axis = 1\n\n  df = self.export_df()\n  df = df.sample(n=num_samples, replace=replace, weights=weights, random_state=random_state,  axis=axis)\n\n  self.load_df(df)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.reset","title":"<code>reset()</code>","text":"<p>This re-initializes the Network object.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def reset(self):\n  '''\n  This re-initializes the Network object.\n  '''\n  initialize_net.main(self)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.set_manual_category","title":"<code>set_manual_category(col=None, row=None, preferred_cats=None)</code>","text":"<p>This method is used to tell Clustergrammer2 that the user wants to define a manual category interactively using the dendrogram.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def set_manual_category(self, col=None, row=None, preferred_cats=None):\n  '''\n  This method is used to tell Clustergrammer2 that the user wants to define\n  a manual category interactively using the dendrogram.\n  '''\n\n  self.dat['manual_category'] = {}\n  self.dat['manual_category']['col'] = col\n  self.dat['manual_category']['row'] = row\n\n  if preferred_cats is not None:\n    pref_cats = []\n    for inst_row in preferred_cats.index.tolist():\n        inst_dict = {}\n        inst_dict['name'] = inst_row\n        inst_dict['color'] = preferred_cats.loc[inst_row, 'color']\n        pref_cats.append(inst_dict)\n\n    if col is not None:\n      self.dat['manual_category']['col_cats'] = pref_cats\n\n    if row is not None:\n      self.dat['manual_category']['row_cats'] = pref_cats\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.sim_same_and_diff_category_samples","title":"<code>sim_same_and_diff_category_samples(df, cat_index=1, dist_type='cosine', equal_var=False, plot_roc=True, precalc_dist=False, calc_roc=True)</code>","text":"<p>Calculate the similarity of samples from the same and different categories. The cat_index gives the index of the category, where 1 in the first category</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def sim_same_and_diff_category_samples(self, df, cat_index=1, dist_type='cosine',\n                                       equal_var=False, plot_roc=True,\n                                       precalc_dist=False, calc_roc=True):\n    '''\n    Calculate the similarity of samples from the same and different categories. The\n    cat_index gives the index of the category, where 1 in the first category\n    '''\n\n    cols = df.columns.tolist()\n\n    if type(precalc_dist) == bool:\n        # compute distnace between rows (transpose to get cols as rows)\n        dist_arr = 1 - pdist(df.transpose(), metric=dist_type)\n    else:\n        dist_arr = precalc_dist\n\n    # generate sample names with categories\n    sample_combos = list(combinations(range(df.shape[1]),2))\n\n    sample_names = [str(ind) + '_same' if cols[x[0]][cat_index] == cols[x[1]][cat_index] else str(ind) + '_different' for ind, x in enumerate(sample_combos)]\n\n    ser_dist = pd.Series(data=dist_arr, index=sample_names)\n\n    # find same-cat sample comparisons\n    same_cat = [x for x in sample_names if x.split('_')[1] == 'same']\n\n    # find diff-cat sample comparisons\n    diff_cat = [x for x in sample_names if x.split('_')[1] == 'different']\n\n    # make series of same and diff category sample comparisons\n    ser_same = ser_dist[same_cat]\n    ser_same.name = 'Same Category'\n    ser_diff = ser_dist[diff_cat]\n    ser_diff.name = 'Different Category'\n\n    sim_dict = {}\n    roc_data = {}\n    sim_data = {}\n\n    sim_dict['same'] = ser_same\n    sim_dict['diff'] = ser_diff\n\n    pval_dict = {}\n    ttest_stat, pval_dict['ttest'] = ttest_ind(ser_diff, ser_same, equal_var=equal_var)\n\n    ttest_stat, pval_dict['mannwhitney'] = mannwhitneyu(ser_diff, ser_same)\n\n    if calc_roc:\n        # calc AUC\n        true_index = list(np.ones(sim_dict['same'].shape[0]))\n        false_index = list(np.zeros(sim_dict['diff'].shape[0]))\n        y_true = true_index + false_index\n\n        true_val = list(sim_dict['same'].values)\n        false_val = list(sim_dict['diff'].values)\n        y_score = true_val + false_val\n\n        fpr, tpr, thresholds = roc_curve(y_true, y_score)\n\n        inst_auc = auc(fpr, tpr)\n\n        if plot_roc:\n            plt.figure()\n            plt.plot(fpr, tpr)\n            plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n            plt.figure(figsize=(10,10))\n\n            print('AUC', inst_auc)\n\n        roc_data['true'] = y_true\n        roc_data['score'] = y_score\n        roc_data['fpr'] = fpr\n        roc_data['tpr'] = tpr\n        roc_data['thresholds'] = thresholds\n        roc_data['auc'] = inst_auc\n\n    sim_data['sim_dict'] = sim_dict\n    sim_data['pval_dict'] = pval_dict\n    sim_data['roc_data'] = roc_data\n\n    return sim_data\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.swap_nan_for_zero","title":"<code>swap_nan_for_zero()</code>","text":"<p>Swaps all NaN (numpy NaN) instances for zero.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def swap_nan_for_zero(self):\n  '''\n  Swaps all NaN (numpy NaN) instances for zero.\n  '''\n  self.dat['mat'][np.isnan(self.dat['mat'])] = 0\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.widget","title":"<code>widget(which_viz='viz', link_net=None, link_net_js=None, clust_library='scipy', min_samples=1, min_cluster_size=2)</code>","text":"<p>Generate a widget visualization using the widget. The export_viz_to_widget method passes the visualization JSON to the instantiated widget, which is returned and visualized on the front-end.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def widget(self, which_viz='viz', link_net=None, link_net_js=None, clust_library='scipy',\n  min_samples=1, min_cluster_size=2):\n  '''\n  Generate a widget visualization using the widget. The export_viz_to_widget\n  method passes the visualization JSON to the instantiated widget, which is\n  returned and visualized on the front-end.\n  '''\n  # run clustering if necessary\n  if len(self.viz['row_nodes']) == 0:\n    self.cluster(clust_library=clust_library, min_samples=min_samples,\n                 min_cluster_size=min_cluster_size)\n\n    # add manual_category to viz json\n    if 'manual_category' in self.dat:\n      self.viz['manual_category'] = self.dat['manual_category']\n\n    # add pre-z-score data to viz\n    if 'pre_zscore' in self.dat:\n      self.viz['pre_zscore'] = self.dat['pre_zscore']\n\n  self.widget_instance = self.widget_class(network = self.export_viz_to_widget(which_viz))\n\n  # initialize manual category\n  if 'manual_category' in self.dat:\n    manual_cat = {}\n    axis = 'col'\n    manual_cat[axis] = {}\n    manual_cat[axis]['col_cat_colors'] = self.viz['cat_colors'][axis]['cat-0']\n\n    man_cat_name = self.dat['manual_category'][axis]\n    if axis == 'col':\n      manual_cat[axis][man_cat_name] = self.meta_col[man_cat_name].to_dict()\n\n    self.widget_instance.manual_cat = json.dumps(manual_cat)\n\n    self.widget_instance.observe(self.get_manual_category, names='manual_cat')\n\n  # add link (python)\n  if link_net is not None:\n    inst_link = widgets.link(\n                              (self.widget_instance, 'manual_cat'),\n                              (link_net.widget_instance, 'manual_cat')\n                             )\n    self.widget_instance.link = inst_link\n\n  # add jslink (JavaScript)\n  if link_net_js is not None:\n\n    inst_link = widgets.jslink(\n                              (self.widget_instance, 'manual_cat'),\n                              (link_net_js.widget_instance, 'manual_cat')\n                             )\n    self.widget_instance.link = inst_link\n\n  return self.widget_instance\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.widget_df","title":"<code>widget_df()</code>","text":"<p>Export a DataFrame from the front-end visualization. For instance, a user can filter to show only a single cluster using the dendrogram and then get a dataframe of this cluster using the widget_df method.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def widget_df(self):\n  '''\n  Export a DataFrame from the front-end visualization. For instance, a user\n  can filter to show only a single cluster using the dendrogram and then\n  get a dataframe of this cluster using the widget_df method.\n  '''\n\n  if hasattr(self, 'widget_instance') == True:\n\n    if self.widget_instance.mat_string != '':\n\n      tmp_net = deepcopy(Network())\n\n      df_string = self.widget_instance.mat_string\n\n      tmp_net.load_file_as_string(df_string)\n\n      df = tmp_net.export_df()\n\n      return df\n\n    else:\n      return self.export_df()\n\n  else:\n    if hasattr(self, 'widget_class') == True:\n      print('Please make the widget before exporting the widget DataFrame.')\n      print('Do this using the widget method: net.widget()')\n\n    else:\n      print('Can not make widget because Network has no attribute widget_class')\n      print('Please instantiate Network with clustergrammer_widget using: Network(clustergrammer_widget)')\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.write_json_to_file","title":"<code>write_json_to_file(net_type, filename, indent='no-indent')</code>","text":"<p>Save dat or viz as a JSON to file.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def write_json_to_file(self, net_type, filename, indent='no-indent'):\n  '''\n  Save dat or viz as a JSON to file.\n  '''\n  export_data.write_json_to_file(self, net_type, filename, indent)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.Network.write_matrix_to_tsv","title":"<code>write_matrix_to_tsv(filename=None, df=None)</code>","text":"<p>Export data-matrix to file.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def write_matrix_to_tsv(self, filename=None, df=None):\n  '''\n  Export data-matrix to file.\n  '''\n  return export_data.write_matrix_to_tsv(self, filename, df)\n</code></pre>"},{"location":"python/clust/api/#celldega.clust.hc","title":"<code>hc(df, filter_N_top=None, norm_col='total', norm_row='zscore')</code>","text":"<p>This function performs hierarchical clustering on the rows and columns of a DataFrame and returns the visualization JSON for the Celldega-Matrix method. This function is developed using the approaches and code adaptations from the Clustergrammer2 project.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>A Pandas DataFrame.</p> required <code>filter_N_top</code> <code>int</code> <p>The number of top dimensions to keep after filtering.</p> <code>None</code> <code>norm_col</code> <code>str</code> <p>The type of normalization to apply to the columns.</p> <code>'total'</code> <code>norm_row</code> <code>str</code> <p>The type of normalization to apply to the rows.</p> <code>'zscore'</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>The visualization JSON for the Celldega-Matrix method</p> <p>Example: See Landscape-Matrix_Xenium notebook.</p> Source code in <code>src/celldega/clust/__init__.py</code> <pre><code>def hc(df, filter_N_top=None, norm_col='total', norm_row='zscore'):\n\n  \"\"\"\n  This function performs hierarchical clustering on the rows and columns of a\n  DataFrame and returns the visualization JSON for the Celldega-Matrix method.\n  This function is developed using the approaches and code adaptations from the\n  Clustergrammer2 project.\n\n  Args:\n    df (pd.DataFrame): A Pandas DataFrame.\n    filter_N_top (int): The number of top dimensions to keep after filtering.\n    norm_col (str): The type of normalization to apply to the columns.\n    norm_row (str): The type of normalization to apply to the rows.\n\n  Returns:\n    dict: The visualization JSON for the Celldega-Matrix method\n\n\n  Example:\n  See [Landscape-Matrix_Xenium](../../../examples/brief_notebooks/Landscape-Matrix_Xenium) notebook.\n  \"\"\"\n\n  net = Network()\n\n  net.load_df(df)\n\n  if filter_N_top is not None:\n    net.filter_N_top(axis='row', N_top=5000)\n\n  if norm_col == 'total':\n    net.normalize(axis='col', norm_type='umi')\n\n  if norm_row == 'zscore':\n    net.normalize(axis='row', norm_type='zscore')\n\n  net.cluster()\n\n  network = net.viz\n\n  return network\n</code></pre>"},{"location":"python/nbhd/api/","title":"Neighborhood Module API Reference","text":"<p>Module for performing neighborhood analysis.</p>"},{"location":"python/nbhd/api/#celldega.nbhd.alpha_shape_cell_clusters","title":"<code>alpha_shape_cell_clusters(meta_cell, cat='cluster', alphas=[100, 150, 200, 250, 300, 350])</code>","text":"<p>Compute alpha shapes for each cluster in the cell metadata.</p> <p>Parameters: - meta_cell: GeoDataFrame of cell metadata. - cat: Column name in meta_cell containing the cluster labels. - alphas: List of alpha values to compute shapes for.</p> <p>Returns: - GeoDataFrame of alpha shapes.</p> Source code in <code>src/celldega/nbhd/__init__.py</code> <pre><code>def alpha_shape_cell_clusters(meta_cell, cat='cluster', alphas=[100, 150, 200, 250, 300, 350]):\n\n    \"\"\"\n    Compute alpha shapes for each cluster in the cell metadata.\n\n    Parameters:\n    - meta_cell: GeoDataFrame of cell metadata.\n    - cat: Column name in meta_cell containing the cluster labels.\n    - alphas: List of alpha values to compute shapes for.\n\n    Returns:\n    - GeoDataFrame of alpha shapes.\n\n    \"\"\"\n\n    gdf_alpha = gpd.GeoDataFrame()\n\n    for inv_alpha in alphas:\n\n        for inst_cluster in meta_cell[cat].unique():\n\n            inst_clust = meta_cell[meta_cell[cat] == inst_cluster]\n\n            if inst_clust.shape[0]&gt; 3:\n\n                nested_array = inst_clust['geometry'].values\n\n                # Convert to a 2D NumPy array\n                flat_array = np.vstack(nested_array)\n\n                inst_shape = alpha_shape(flat_array, inv_alpha)\n\n                inst_name = inst_cluster + '_' + str(inv_alpha)\n\n                gdf_alpha.loc[inst_name, 'name'] = inst_name\n\n                gdf_alpha.loc[inst_name, 'cat'] = inst_cluster\n\n                gdf_alpha.loc[inst_name, 'geometry'] = inst_shape\n\n                gdf_alpha.loc[inst_name, 'inv_alpha'] = int(inv_alpha)\n\n    gdf_alpha[\"geometry\"] = gdf_alpha[\"geometry\"].apply(lambda geom: _round_coordinates(geom, precision=2))\n\n    gdf_alpha['area'] = gdf_alpha.area\n\n    gdf_alpha = gdf_alpha.loc[gdf_alpha.area.sort_values(ascending=False).index.tolist()]\n\n    return gdf_alpha\n</code></pre>"},{"location":"python/pre/api/","title":"Pre Module API Reference","text":"<p>Module for pre-processing to generate LandscapeFiles from ST data.</p>"},{"location":"python/pre/api/#celldega.pre.calc_meta_gene_data","title":"<code>calc_meta_gene_data(cbg)</code>","text":"<p>Calculate gene metadata from the cell-by-gene matrix</p> <p>Parameters:</p> Name Type Description Default <code>cbg</code> <code>DataFrame</code> <p>A sparse DataFrame with genes as columns and barcodes as rows.</p> required <p>Returns:</p> Type Description <p>pandas.DataFrame: A DataFrame with gene metadata including mean, standard deviation, maximum expression, and proportion of non-zero expression.</p> Source code in <code>src/celldega/pre/landscape.py</code> <pre><code>def calc_meta_gene_data(cbg):\n    \"\"\"\n    Calculate gene metadata from the cell-by-gene matrix\n\n    Args:\n        cbg (pandas.DataFrame): A sparse DataFrame with genes as columns and barcodes as rows.\n\n    Returns:\n        pandas.DataFrame: A DataFrame with gene metadata including mean, standard deviation,\n            maximum expression, and proportion of non-zero expression.\n    \"\"\"\n\n    # Helper function to convert to dense if sparse\n    def convert_to_dense(series):\n        \"\"\"\n        Convert a pandas Series to dense format if it's sparse.\n\n        Parameters\n        ----------\n        series : pandas.Series\n\n        Returns\n        -------\n        pandas.Series\n            Dense Series if input was sparse; original Series otherwise.\n        \"\"\"\n        if pd.api.types.is_sparse(series):\n            return series.sparse.to_dense()\n        return series\n\n    # Ensure cbg is a DataFrame\n    if not isinstance(cbg, pd.DataFrame):\n        raise TypeError(\"cbg must be a pandas DataFrame\")\n\n    # Determine if cbg is sparse\n    is_sparse = pd.api.types.is_sparse(cbg)\n\n    if is_sparse:\n        # Ensure cbg has SparseDtype with float and fill_value=0\n        cbg = cbg.astype(pd.SparseDtype(\"float\", fill_value=0))\n        print(\"cbg is a sparse DataFrame. Proceeding with sparse operations.\")\n    else:\n        print(\"cbg is a dense DataFrame. Proceeding with dense operations.\")\n\n    # Calculate mean expression across tiles\n    print(\"Calculating mean expression\")\n    mean_expression = cbg.mean(axis=0)\n\n    # Calculate variance as the average of the squared deviations\n    print(\"Calculating variance\")\n    num_tiles = cbg.shape[1]\n    variance = cbg.apply(\n        lambda x: ((x - mean_expression[x.name]) ** 2).sum() / num_tiles, axis=0\n    )\n    std_deviation = np.sqrt(variance)\n\n    # Calculate maximum expression\n    max_expression = cbg.max(axis=0)\n\n    # Calculate proportion of tiles with non-zero expression\n    proportion_nonzero = (cbg != 0).sum(axis=0) / len(cbg)\n\n    # Create a DataFrame to hold all these metrics\n    meta_gene = pd.DataFrame(\n        {\n            \"mean\": mean_expression.sparse.to_dense(),\n            \"std\": std_deviation,\n            \"max\": max_expression.sparse.to_dense(),\n            \"non-zero\": proportion_nonzero.sparse.to_dense(),\n        }\n\n    )\n\n    meta_gene_clean = pd.DataFrame(meta_gene.values, index=meta_gene.index.tolist(), columns=meta_gene.columns)\n\n    return meta_gene_clean\n</code></pre>"},{"location":"python/pre/api/#celldega.pre.convert_long_id_to_short","title":"<code>convert_long_id_to_short(df)</code>","text":"<p>Converts a column of long integer cell IDs in a DataFrame to a shorter, hash-based representation.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The DataFrame containing the EntityID.</p> required <p>Returns:     pd.DataFrame: The original DataFrame with an additional column named <code>cell_id</code>                   containing the shortened cell IDs.</p> <p>The function applies a SHA-256 hash to each cell ID, encodes the hash using base64, and truncates it to create a shorter identifier that is added as a new column to the DataFrame.</p> Source code in <code>src/celldega/pre/__init__.py</code> <pre><code>def convert_long_id_to_short(df):\n    \"\"\"\n    Converts a column of long integer cell IDs in a DataFrame to a shorter, hash-based representation.\n\n    Args:\n        df (pd.DataFrame): The DataFrame containing the EntityID.\n    Returns:\n        pd.DataFrame: The original DataFrame with an additional column named `cell_id`\n                      containing the shortened cell IDs.\n\n    The function applies a SHA-256 hash to each cell ID, encodes the hash using base64, and truncates\n    it to create a shorter identifier that is added as a new column to the DataFrame.\n    \"\"\"\n    # Function to hash and encode the cell ID\n    def hash_and_shorten_id(cell_id):\n        # Create a hash of the cell ID\n        cell_id_bytes = str(cell_id).encode('utf-8')\n        hash_object = hashlib.sha256(cell_id_bytes)\n        hash_digest = hash_object.digest()\n\n        # Encode the hash to a base64 string to mix letters and numbers, truncate to 9 characters\n        short_id = base64.urlsafe_b64encode(hash_digest).decode('utf-8')[:9]\n        return short_id\n\n    # Apply the hash_and_shorten_id function to each cell ID in the specified column\n    df['cell_id'] = df['EntityID'].apply(hash_and_shorten_id)\n\n    return df\n</code></pre>"},{"location":"python/pre/api/#celldega.pre.convert_to_jpeg","title":"<code>convert_to_jpeg(image_path, quality=80)</code>","text":"<p>Convert a TIFF image to a JPEG image with a quality of score</p>"},{"location":"python/pre/api/#celldega.pre.convert_to_jpeg--parameters","title":"Parameters","text":"<p>image_path : str     Path to the image file quality : int (default=80)     Quality score for the JPEG image</p>"},{"location":"python/pre/api/#celldega.pre.convert_to_jpeg--returns","title":"Returns","text":"<p>new_image_path : str     Path to the JPEG image file</p> Source code in <code>src/celldega/pre/__init__.py</code> <pre><code>def convert_to_jpeg(image_path, quality=80):\n    \"\"\"\n    Convert a TIFF image to a JPEG image with a quality of score\n\n    Parameters\n    ----------\n    image_path : str\n        Path to the image file\n    quality : int (default=80)\n        Quality score for the JPEG image\n\n    Returns\n    -------\n    new_image_path : str\n        Path to the JPEG image file\n\n    \"\"\"\n\n    # Load the TIFF image\n    image = pyvips.Image.new_from_file(image_path, access=\"sequential\")\n\n    # Save the image as a JPEG with a quality of 80\n    new_image_path = image_path.replace(\".tif\", \".jpeg\")\n    image.jpegsave(new_image_path, Q=quality)\n\n    return new_image_path\n</code></pre>"},{"location":"python/pre/api/#celldega.pre.convert_to_png","title":"<code>convert_to_png(image_path)</code>","text":"<p>Convert a TIFF image to a JPEG image with a quality of score</p>"},{"location":"python/pre/api/#celldega.pre.convert_to_png--parameters","title":"Parameters","text":"<p>image_path : str     Path to the image file quality : int (default=80)     Quality score for the JPEG image</p>"},{"location":"python/pre/api/#celldega.pre.convert_to_png--returns","title":"Returns","text":"<p>new_image_path : str     Path to the JPEG image file</p> Source code in <code>src/celldega/pre/__init__.py</code> <pre><code>def convert_to_png(image_path):\n    \"\"\"\n    Convert a TIFF image to a JPEG image with a quality of score\n\n    Parameters\n    ----------\n    image_path : str\n        Path to the image file\n    quality : int (default=80)\n        Quality score for the JPEG image\n\n    Returns\n    -------\n    new_image_path : str\n        Path to the JPEG image file\n\n    \"\"\"\n\n    # Load the TIFF image\n    image = pyvips.Image.new_from_file(image_path, access=\"sequential\")\n\n    # Save the image as a JPEG with a quality of 80\n    new_image_path = image_path.replace(\".tif\", \".png\")\n    image.pngsave(new_image_path)\n\n    return new_image_path\n</code></pre>"},{"location":"python/pre/api/#celldega.pre.convert_to_webp","title":"<code>convert_to_webp(image_path, quality=100)</code>","text":"<p>Convert a TIFF image to a WEBP image with a specified quality score.</p>"},{"location":"python/pre/api/#celldega.pre.convert_to_webp--parameters","title":"Parameters","text":"<p>image_path : str     Path to the image file quality : int (default=100)     Quality score for the WEBP image (higher is better quality)</p>"},{"location":"python/pre/api/#celldega.pre.convert_to_webp--returns","title":"Returns","text":"<p>new_image_path : str     Path to the WEBP image file</p> Source code in <code>src/celldega/pre/__init__.py</code> <pre><code>def convert_to_webp(image_path, quality=100):\n    \"\"\"\n    Convert a TIFF image to a WEBP image with a specified quality score.\n\n    Parameters\n    ----------\n    image_path : str\n        Path to the image file\n    quality : int (default=100)\n        Quality score for the WEBP image (higher is better quality)\n\n    Returns\n    -------\n    new_image_path : str\n        Path to the WEBP image file\n    \"\"\"\n    # Load the TIFF image\n    image = pyvips.Image.new_from_file(image_path, access=\"sequential\")\n\n    # Save the image as a WEBP with specified quality\n    new_image_path = image_path.replace(\".tif\", \".webp\")\n    image.webpsave(new_image_path, Q=quality)\n\n    return new_image_path\n</code></pre>"},{"location":"python/pre/api/#celldega.pre.get_max_zoom_level","title":"<code>get_max_zoom_level(path_image_pyramid)</code>","text":"<p>Returns the maximum zoom level based on the highest-numbered directory in the specified path_image_pyramid.</p> <p>Parameters:</p> Name Type Description Default <code>path_image_pyramid</code> <code>str</code> <p>The path to the directory containing zoom level directories.</p> required <p>Returns:</p> Name Type Description <code>max_pyramid_zoom</code> <code>int</code> <p>The maximum zoom level.</p> Source code in <code>src/celldega/pre/__init__.py</code> <pre><code>def get_max_zoom_level(path_image_pyramid):\n    \"\"\"\n    Returns the maximum zoom level based on the highest-numbered directory\n    in the specified path_image_pyramid.\n\n    Parameters:\n        path_image_pyramid (str): The path to the directory containing zoom level directories.\n\n    Returns:\n        max_pyramid_zoom (int): The maximum zoom level.\n    \"\"\"\n    # List all entries in the path_image_pyramid that are directories and can be converted to integers\n    zoom_levels = [\n        entry\n        for entry in os.listdir(path_image_pyramid)\n        if os.path.isdir(os.path.join(path_image_pyramid, entry)) and entry.isdigit()\n    ]\n\n    # Convert to integer and find the maximum value\n    max_pyramid_zoom = max(map(int, zoom_levels)) if zoom_levels else None\n\n    return max_pyramid_zoom\n</code></pre>"},{"location":"python/pre/api/#celldega.pre.make_cell_boundary_tiles","title":"<code>make_cell_boundary_tiles(technology, path_cell_boundaries, path_meta_cell_micron, path_transformation_matrix, path_output, coarse_tile_factor=20, tile_size=250, tile_bounds=None, image_scale=1, max_workers=8)</code>","text":"<p>Processes cell boundary data and divides it into spatial tiles based on the provided technology. Reads cell boundary data, applies affine transformations, and divides the data into coarse and fine tiles. The resulting tiles are saved as Parquet files, each containing the geometries of cells in that tile.</p>"},{"location":"python/pre/api/#celldega.pre.make_cell_boundary_tiles--parameters","title":"Parameters","text":"<p>technology : str     The technology used to generate the cell boundary data, e.g., \"MERSCOPE\", \"Xenium\", or \"custom\". path_cell_boundaries : str     Path to the file containing the cell boundaries (Parquet format). path_meta_cell_micron : str     Path to the file containing cell metadata (CSV format). path_transformation_matrix : str     Path to the file containing the transformation matrix (CSV format). path_output : str     Directory path where the output files (Parquet files) for each tile will be saved. coarse_tile_factor  : int, optional, default=20.     scaling factor of each coarse-grain tile comparing to the fine tile size. tile_size : int, optional, default=500     Size of each fine-grain tile in microns. tile_bounds : dict, optional     Dictionary containing the minimum and maximum bounds for x and y coordinates. image_scale : float, optional, default=1     Scale factor to apply to the geometry data. max_workers : int, optional, default=8     Maximum number of parallel workers for processing tiles.</p>"},{"location":"python/pre/api/#celldega.pre.make_cell_boundary_tiles--returns","title":"Returns","text":"<p>None</p> Source code in <code>src/celldega/pre/boundary_tile.py</code> <pre><code>def make_cell_boundary_tiles(\n    technology,\n    path_cell_boundaries,\n    path_meta_cell_micron,\n    path_transformation_matrix,\n    path_output,\n    coarse_tile_factor=20,\n    tile_size=250,\n    tile_bounds=None,\n    image_scale=1,\n    max_workers=8\n):\n\n\n    \"\"\"\n    Processes cell boundary data and divides it into spatial tiles based on the provided technology.\n    Reads cell boundary data, applies affine transformations, and divides the data into coarse and fine tiles.\n    The resulting tiles are saved as Parquet files, each containing the geometries of cells in that tile.\n\n    Parameters\n    ----------\n    technology : str\n        The technology used to generate the cell boundary data, e.g., \"MERSCOPE\", \"Xenium\", or \"custom\".\n    path_cell_boundaries : str\n        Path to the file containing the cell boundaries (Parquet format).\n    path_meta_cell_micron : str\n        Path to the file containing cell metadata (CSV format).\n    path_transformation_matrix : str\n        Path to the file containing the transformation matrix (CSV format).\n    path_output : str\n        Directory path where the output files (Parquet files) for each tile will be saved.\n    coarse_tile_factor  : int, optional, default=20.\n        scaling factor of each coarse-grain tile comparing to the fine tile size.\n    tile_size : int, optional, default=500\n        Size of each fine-grain tile in microns.\n    tile_bounds : dict, optional\n        Dictionary containing the minimum and maximum bounds for x and y coordinates.\n    image_scale : float, optional, default=1\n        Scale factor to apply to the geometry data.\n    max_workers : int, optional, default=8\n        Maximum number of parallel workers for processing tiles.\n\n    Returns\n    -------\n    None\n    \"\"\"\n\n    def numpy_affine_transform(coords, matrix):\n        \"\"\"Apply affine transformation to numpy coordinates.\"\"\"\n        # Homogeneous coordinates for affine transformation\n        coords = np.hstack([coords, np.ones((coords.shape[0], 1))])\n        transformed_coords = coords @ matrix.T\n        return transformed_coords[:, :2]  # Drop the homogeneous coordinate\n\n    def batch_transform_geometries(geometries, transformation_matrix, scale):\n        \"\"\"\n        Batch transform geometries using numpy for optimized performance.\n        \"\"\"\n        # Extract affine transformation parameters into a 3x3 matrix for numpy\n        affine_matrix = np.array([\n            [transformation_matrix[0, 0], transformation_matrix[0, 1], transformation_matrix[0, 2]],\n            [transformation_matrix[1, 0], transformation_matrix[1, 1], transformation_matrix[1, 2]],\n            [0, 0, 1]\n        ])\n\n        transformed_geometries = []\n\n        for polygon in geometries:\n            # Extract coordinates and transform them\n            if isinstance(polygon, MultiPolygon):\n                polygon = next(polygon.geoms)  # Use the first geometry\n\n            # Transform the exterior of the polygon\n            exterior_coords = np.array(polygon.exterior.coords)\n\n            # Apply the affine transformation and scale\n            transformed_coords = numpy_affine_transform(exterior_coords, affine_matrix) / scale\n\n            # Append the result to the transformed_geometries list\n            transformed_geometries.append([transformed_coords.tolist()])\n\n        return transformed_geometries\n\n\n    def filter_and_save_fine_boundary(coarse_tile, fine_i, fine_j, fine_tile_x_min, fine_tile_x_max, fine_tile_y_min, fine_tile_y_max, path_output):\n        cell_ids = coarse_tile.index.values\n\n        tile_filter = (\n            (coarse_tile[\"center_x\"] &gt;= fine_tile_x_min) &amp; (coarse_tile[\"center_x\"] &lt; fine_tile_x_max) &amp;\n            (coarse_tile[\"center_y\"] &gt;= fine_tile_y_min) &amp; (coarse_tile[\"center_y\"] &lt; fine_tile_y_max)\n        )\n        filtered_indices = np.where(tile_filter)[0]\n\n        keep_cells = cell_ids[filtered_indices]\n        fine_tile_cells = coarse_tile.loc[keep_cells, [\"GEOMETRY\"]]\n        fine_tile_cells = fine_tile_cells.assign(name=fine_tile_cells.index)\n\n        if not fine_tile_cells.empty:\n            filename = f\"{path_output}/cell_tile_{fine_i}_{fine_j}.parquet\"\n            fine_tile_cells.to_parquet(filename)\n\n    def process_fine_boundaries(coarse_tile, i, j, coarse_tile_x_min, coarse_tile_x_max, coarse_tile_y_min, coarse_tile_y_max, tile_size, path_output, x_min, y_min, n_fine_tiles_x, n_fine_tiles_y):\n        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n            futures = []\n            for fine_i in range(n_fine_tiles_x):\n                fine_tile_x_min = x_min + fine_i * tile_size\n                fine_tile_x_max = fine_tile_x_min + tile_size\n\n                if not (fine_tile_x_min &gt;= coarse_tile_x_min and fine_tile_x_max &lt;= coarse_tile_x_max):\n                    continue\n\n                for fine_j in range(n_fine_tiles_y):\n                    fine_tile_y_min = y_min + fine_j * tile_size\n                    fine_tile_y_max = fine_tile_y_min + tile_size\n\n                    if not (fine_tile_y_min &gt;= coarse_tile_y_min and fine_tile_y_max &lt;= coarse_tile_y_max):\n                        continue\n\n                    futures.append(executor.submit(\n                        filter_and_save_fine_boundary, coarse_tile, fine_i, fine_j, fine_tile_x_min, fine_tile_x_max, fine_tile_y_min, fine_tile_y_max, path_output\n                    ))\n\n            for future in futures:\n                future.result()\n\n    tile_size_x = tile_size\n    tile_size_y = tile_size\n\n    transformation_matrix = pd.read_csv(path_transformation_matrix, header=None, sep=\" \").values\n\n    # Load cell boundary data based on the technology\n    if technology == \"MERSCOPE\":\n        df_meta = pd.read_parquet(f\"{path_output.replace('cell_segmentation','cell_metadata.parquet')}\")\n        entity_to_cell_id_dict = pd.Series(df_meta.index.values, index=df_meta.EntityID).to_dict()\n        cells_orig = gpd.read_parquet(path_cell_boundaries)\n        cells_orig['cell_id'] = cells_orig['EntityID'].map(entity_to_cell_id_dict)\n        cells_orig = cells_orig[cells_orig[\"ZIndex\"] == 1]\n\n        # Correct cell_id issues with meta_cell\n        meta_cell = pd.read_csv(path_meta_cell_micron)\n        meta_cell['cell_id'] = meta_cell['EntityID'].map(entity_to_cell_id_dict)\n        cells_orig.index = meta_cell[meta_cell[\"cell_id\"].isin(cells_orig['cell_id'])].index\n\n        # Correct 'MultiPolygon' to 'Polygon'\n        cells_orig[\"geometry\"] = cells_orig[\"Geometry\"].apply(\n            lambda x: list(x.geoms)[0] if isinstance(x, MultiPolygon) else x\n        )\n\n        cells_orig.set_index('cell_id', inplace=True)\n\n    elif technology == \"Xenium\":\n        xenium_cells = pd.read_parquet(path_cell_boundaries)\n        grouped = xenium_cells.groupby(\"cell_id\")[[\"vertex_x\", \"vertex_y\"]].agg(lambda x: x.tolist())\n        grouped[\"geometry\"] = grouped.apply(lambda row: Polygon(zip(row[\"vertex_x\"], row[\"vertex_y\"])), axis=1)\n        cells_orig = gpd.GeoDataFrame(grouped, geometry=\"geometry\")[[\"geometry\"]]\n\n    elif technology == \"custom\":\n        cells_orig = gpd.read_parquet(path_cell_boundaries)\n\n    # Transform geometries\n    cells_orig[\"GEOMETRY\"] = batch_transform_geometries(cells_orig[\"geometry\"], transformation_matrix, image_scale)\n\n    # Convert transformed geometries to polygons and calculate centroids\n    cells_orig[\"polygon\"] = cells_orig[\"GEOMETRY\"].apply(lambda x: Polygon(x[0]))\n    gdf_cells = gpd.GeoDataFrame(geometry=cells_orig[\"polygon\"])\n    gdf_cells[\"center_x\"] = gdf_cells.geometry.centroid.x\n    gdf_cells[\"center_y\"] = gdf_cells.geometry.centroid.y\n    gdf_cells[\"GEOMETRY\"] = cells_orig[\"GEOMETRY\"]\n\n    # Ensure the output directory exists\n    if not os.path.exists(path_output):\n        os.makedirs(path_output)\n\n    # Calculate tile bounds and fine/coarse tiles\n    x_min, x_max = tile_bounds[\"x_min\"], tile_bounds[\"x_max\"]\n    y_min, y_max = tile_bounds[\"y_min\"], tile_bounds[\"y_max\"]\n    n_fine_tiles_x = int(np.ceil((x_max - x_min) / tile_size))\n    n_fine_tiles_y = int(np.ceil((y_max - y_min) / tile_size))\n    n_coarse_tiles_x = int(np.ceil((x_max - x_min) / (coarse_tile_factor * tile_size)))\n    n_coarse_tiles_y = int(np.ceil((y_max - y_min) / (coarse_tile_factor * tile_size)))\n\n    # Process coarse tiles in parallel\n    for i in tqdm(range(n_coarse_tiles_x), desc=\"Processing coarse tiles\"):\n        coarse_tile_x_min = x_min + i * (coarse_tile_factor * tile_size)\n        coarse_tile_x_max = coarse_tile_x_min + (coarse_tile_factor * tile_size)\n\n        for j in range(n_coarse_tiles_y):\n            coarse_tile_y_min = y_min + j * (coarse_tile_factor * tile_size)\n            coarse_tile_y_max = coarse_tile_y_min + (coarse_tile_factor * tile_size)\n\n            coarse_tile = gdf_cells[\n                (gdf_cells[\"center_x\"] &gt;= coarse_tile_x_min) &amp; (gdf_cells[\"center_x\"] &lt; coarse_tile_x_max) &amp;\n                (gdf_cells[\"center_y\"] &gt;= coarse_tile_y_min) &amp; (gdf_cells[\"center_y\"] &lt; coarse_tile_y_max)\n            ]\n            if not coarse_tile.empty:\n                process_fine_boundaries(coarse_tile, i, j, coarse_tile_x_min, coarse_tile_x_max, coarse_tile_y_min, coarse_tile_y_max, tile_size, path_output, x_min, y_min, n_fine_tiles_x, n_fine_tiles_y)\n</code></pre>"},{"location":"python/pre/api/#celldega.pre.make_deepzoom_pyramid","title":"<code>make_deepzoom_pyramid(image_path, output_path, pyramid_name, tile_size=512, overlap=0, suffix='.jpeg')</code>","text":"<p>Create a DeepZoom image pyramid from a JPEG image</p>"},{"location":"python/pre/api/#celldega.pre.make_deepzoom_pyramid--parameters","title":"Parameters","text":"<p>image_path : str     Path to the JPEG image file tile_size : int (default=512)     Tile size for the DeepZoom pyramid overlap : int (default=0)     Overlap size for the DeepZoom pyramid suffix : str (default='jpeg')     Suffix for the DeepZoom pyramid tiles</p>"},{"location":"python/pre/api/#celldega.pre.make_deepzoom_pyramid--returns","title":"Returns","text":"<p>None</p> Source code in <code>src/celldega/pre/__init__.py</code> <pre><code>def make_deepzoom_pyramid(\n    image_path, output_path, pyramid_name, tile_size=512, overlap=0, suffix=\".jpeg\"\n):\n    \"\"\"\n    Create a DeepZoom image pyramid from a JPEG image\n\n    Parameters\n    ----------\n    image_path : str\n        Path to the JPEG image file\n    tile_size : int (default=512)\n        Tile size for the DeepZoom pyramid\n    overlap : int (default=0)\n        Overlap size for the DeepZoom pyramid\n    suffix : str (default='jpeg')\n        Suffix for the DeepZoom pyramid tiles\n\n    Returns\n    -------\n    None\n\n    \"\"\"\n\n    # Define the output path\n    output_path = Path(output_path)\n\n    # Load the JPEG image\n    image = pyvips.Image.new_from_file(image_path, access=\"sequential\")\n\n    # check if the output path exists and create it if it does not\n    output_path.mkdir(parents=True, exist_ok=True)\n\n    # append the pyramid name to the output path\n    output_path = output_path / pyramid_name\n\n    # Save the image as a DeepZoom image pyramid\n    image.dzsave(output_path, tile_size=tile_size, overlap=overlap, suffix=suffix)\n</code></pre>"},{"location":"python/pre/api/#celldega.pre.make_meta_cell_image_coord","title":"<code>make_meta_cell_image_coord(technology, path_transformation_matrix, path_meta_cell_micron, path_meta_cell_image, image_scale)</code>","text":"<p>Apply an affine transformation to the cell coordinates in microns and save the transformed coordinates in pixels</p>"},{"location":"python/pre/api/#celldega.pre.make_meta_cell_image_coord--parameters","title":"Parameters","text":"<p>technology : str     The technology used to generate the data, Xenium and MERSCOPE are supported. path_transformation_matrix : str     Path to the transformation matrix file path_meta_cell_micron : str     Path to the meta cell file with coordinates in microns path_meta_cell_image : str     Path to save the meta cell file with coordinates in pixels</p>"},{"location":"python/pre/api/#celldega.pre.make_meta_cell_image_coord--returns","title":"Returns","text":"<p>None</p>"},{"location":"python/pre/api/#celldega.pre.make_meta_cell_image_coord--examples","title":"Examples","text":"<p>make_meta_cell_image_coord( ...     technology='Xenium', ...     path_transformation_matrix='data/transformation_matrix.txt', ...     path_meta_cell_micron='data/meta_cell_micron.csv', ...     path_meta_cell_image='data/meta_cell_image.parquet' ... )</p> Source code in <code>src/celldega/pre/__init__.py</code> <pre><code>def make_meta_cell_image_coord(\n    technology,\n    path_transformation_matrix,\n    path_meta_cell_micron,\n    path_meta_cell_image,\n    image_scale\n):\n    \"\"\"\n    Apply an affine transformation to the cell coordinates in microns and save\n    the transformed coordinates in pixels\n\n    Parameters\n    ----------\n    technology : str\n        The technology used to generate the data, Xenium and MERSCOPE are supported.\n    path_transformation_matrix : str\n        Path to the transformation matrix file\n    path_meta_cell_micron : str\n        Path to the meta cell file with coordinates in microns\n    path_meta_cell_image : str\n        Path to save the meta cell file with coordinates in pixels\n\n    Returns\n    -------\n    None\n\n    Examples\n    --------\n    &gt;&gt;&gt; make_meta_cell_image_coord(\n    ...     technology='Xenium',\n    ...     path_transformation_matrix='data/transformation_matrix.txt',\n    ...     path_meta_cell_micron='data/meta_cell_micron.csv',\n    ...     path_meta_cell_image='data/meta_cell_image.parquet'\n    ... )\n\n    \"\"\"\n\n    transformation_matrix = pd.read_csv(\n        path_transformation_matrix, header=None, sep=\" \"\n    ).values\n\n    if technology == \"MERSCOPE\":\n        meta_cell = pd.read_csv(path_meta_cell_micron, usecols=[\"EntityID\", \"center_x\", \"center_y\"])\n        meta_cell = convert_long_id_to_short(meta_cell)\n        meta_cell[\"name\"] =  meta_cell[\"cell_id\"]\n        meta_cell = meta_cell.set_index('cell_id')\n    elif technology == \"Xenium\":\n        usecols = [\"cell_id\", \"x_centroid\", \"y_centroid\"]\n        meta_cell = pd.read_csv(path_meta_cell_micron, index_col=0, usecols=usecols)\n        meta_cell.columns = [\"center_x\", \"center_y\"]\n        meta_cell[\"name\"] = pd.Series(meta_cell.index, index=meta_cell.index)\n\n    # Adding a ones column to accommodate for affine transformation\n    meta_cell[\"ones\"] = 1\n\n    # Preparing the data for matrix multiplication\n    points = meta_cell[[\"center_x\", \"center_y\", \"ones\"]].values\n\n    # Applying the transformation matrix\n    transformed_points = np.dot(transformation_matrix, points.T).T\n\n    # Updating the DataFrame with transformed coordinates\n    meta_cell[\"center_x\"] = transformed_points[:, 0]\n    meta_cell[\"center_y\"] = transformed_points[:, 1]\n\n    # Dropping the ones column as it's no longer needed\n    meta_cell.drop(columns=[\"ones\"], inplace=True)\n\n    meta_cell[\"center_x\"] = meta_cell[\"center_x\"] / image_scale\n    meta_cell[\"center_y\"] = meta_cell[\"center_y\"] / image_scale\n\n    meta_cell[\"geometry\"] = meta_cell.apply(\n        lambda row: [row[\"center_x\"], row[\"center_y\"]], axis=1\n    )\n\n    if technology == \"MERSCOPE\":\n        meta_cell = meta_cell[[\"name\", \"geometry\", \"EntityID\"]]\n    else:\n        meta_cell = meta_cell[[\"name\", \"geometry\"]]\n\n\n    meta_cell.to_parquet(path_meta_cell_image)\n</code></pre>"},{"location":"python/pre/api/#celldega.pre.make_meta_gene","title":"<code>make_meta_gene(technology, path_cbg, path_output)</code>","text":"<p>Create a DataFrame with genes and their assigned colors</p>"},{"location":"python/pre/api/#celldega.pre.make_meta_gene--parameters","title":"Parameters","text":"<p>technology : str     The technology used to generate the data, Xenium and MERSCOPE are supported. path_cbg : str     Path to the cell-by-gene matrix data (the data format can vary based on technology) path_output : str     Path to save the meta gene file</p>"},{"location":"python/pre/api/#celldega.pre.make_meta_gene--returns","title":"Returns","text":"<p>None</p>"},{"location":"python/pre/api/#celldega.pre.make_meta_gene--examples","title":"Examples","text":"<p>make_meta_gene( ...     technology='Xenium', ...     path_cbg='data/', ...     path_output='data/meta_gene.parquet' ... )</p> Source code in <code>src/celldega/pre/__init__.py</code> <pre><code>def make_meta_gene(technology, path_cbg, path_output):\n    \"\"\"\n    Create a DataFrame with genes and their assigned colors\n\n    Parameters\n    ----------\n    technology : str\n        The technology used to generate the data, Xenium and MERSCOPE are supported.\n    path_cbg : str\n        Path to the cell-by-gene matrix data (the data format can vary based on technology)\n    path_output : str\n        Path to save the meta gene file\n\n    Returns\n    -------\n    None\n\n    Examples\n    --------\n    &gt;&gt;&gt; make_meta_gene(\n    ...     technology='Xenium',\n    ...     path_cbg='data/',\n    ...     path_output='data/meta_gene.parquet'\n    ... )\n    \"\"\"\n\n    if technology == \"MERSCOPE\":\n        cbg = pd.read_csv(path_cbg, index_col=0)\n        genes = cbg.columns.tolist()\n    elif technology == \"Xenium\":\n        # genes = pd.read_csv(path_cbg + 'features.tsv.gz', sep='\\t', header=None)[1].values.tolist()\n        cbg = read_cbg_mtx(path_cbg)\n        genes = cbg.columns.tolist()\n\n    # Get all categorical color palettes from Matplotlib and flatten them into a single list of colors\n    palettes = [plt.get_cmap(name).colors for name in plt.colormaps() if \"tab\" in name]\n    flat_colors = [color for palette in palettes for color in palette]\n\n    # Convert RGB tuples to hex codes\n    flat_colors_hex = [to_hex(color) for color in flat_colors]\n\n    # Use modular arithmetic to assign a color to each gene, white for genes with \"Blank\"\n    colors = [\n        flat_colors_hex[i % len(flat_colors_hex)] if \"Blank\" not in gene else \"#FFFFFF\"\n        for i, gene in enumerate(genes)\n    ]\n\n    # Create a DataFrame with genes and their assigned colors\n    ser_color = pd.Series(colors, index=genes)\n\n    # calculate gene expression metadata\n    meta_gene = calc_meta_gene_data(cbg)\n    meta_gene['color'] = ser_color\n\n    # Identify sparse columns\n    sparse_cols = [col for col in meta_gene.columns if pd.api.types.is_sparse(meta_gene[col])]\n\n    # Convert sparse columns to dense\n    for col in sparse_cols:\n        meta_gene[col] = meta_gene[col].sparse.to_dense()\n\n    meta_gene.to_parquet(path_output)\n</code></pre>"},{"location":"python/pre/api/#celldega.pre.make_trx_tiles","title":"<code>make_trx_tiles(technology, path_trx, path_transformation_matrix, path_trx_tiles, coarse_tile_factor=10, tile_size=250, chunk_size=1000000, verbose=False, image_scale=1, max_workers=8)</code>","text":"<p>Processes transcript data by dividing it into coarse-grain and fine-grain tiles, applying transformations, and saving the results in a parallelized manner.</p>"},{"location":"python/pre/api/#celldega.pre.make_trx_tiles--parameters","title":"Parameters","text":"<p>technology : str     The technology used for generating the transcript data (e.g., \"MERSCOPE\" or \"Xenium\"). path_trx : str     Path to the file containing the transcript data. path_transformation_matrix : str     Path to the file containing the transformation matrix (CSV file). path_trx_tiles : str     Directory path where the output files (Parquet files) for each tile will be saved. coarse_tile_factor : int, optional     Scaling factor of each coarse-grain tile comparing to the fine tile size. tile_size : int, optional     Size of each fine-grain tile in microns (default is 250). chunk_size : int, optional     Number of rows to process per chunk for memory efficiency (default is 1000000). verbose : bool, optional     Flag to enable verbose output (default is False). image_scale : float, optional     Scale factor to apply to the transcript coordinates (default is 0.5). max_workers : int, optional     Maximum number of parallel workers for processing tiles (default is 8).</p>"},{"location":"python/pre/api/#celldega.pre.make_trx_tiles--returns","title":"Returns","text":"<p>dict     A dictionary containing the bounds of the processed data in both x and y directions.</p> Source code in <code>src/celldega/pre/trx_tile.py</code> <pre><code>def make_trx_tiles(\n    technology,\n    path_trx,\n    path_transformation_matrix,\n    path_trx_tiles,\n    coarse_tile_factor=10,\n    tile_size=250,\n    chunk_size=1000000,\n    verbose=False,\n    image_scale=1,\n    max_workers=8\n):\n    \"\"\"\n    Processes transcript data by dividing it into coarse-grain and fine-grain tiles,\n    applying transformations, and saving the results in a parallelized manner.\n\n    Parameters\n    ----------\n    technology : str\n        The technology used for generating the transcript data (e.g., \"MERSCOPE\" or \"Xenium\").\n    path_trx : str\n        Path to the file containing the transcript data.\n    path_transformation_matrix : str\n        Path to the file containing the transformation matrix (CSV file).\n    path_trx_tiles : str\n        Directory path where the output files (Parquet files) for each tile will be saved.\n    coarse_tile_factor : int, optional\n        Scaling factor of each coarse-grain tile comparing to the fine tile size.\n    tile_size : int, optional\n        Size of each fine-grain tile in microns (default is 250).\n    chunk_size : int, optional\n        Number of rows to process per chunk for memory efficiency (default is 1000000).\n    verbose : bool, optional\n        Flag to enable verbose output (default is False).\n    image_scale : float, optional\n        Scale factor to apply to the transcript coordinates (default is 0.5).\n    max_workers : int, optional\n        Maximum number of parallel workers for processing tiles (default is 8).\n\n    Returns\n    -------\n    dict\n        A dictionary containing the bounds of the processed data in both x and y directions.\n    \"\"\"\n\n    def process_coarse_tile(trx, i, j, coarse_tile_x_min, coarse_tile_x_max, coarse_tile_y_min, coarse_tile_y_max, tile_size, path_trx_tiles, x_min, y_min, n_fine_tiles_x, n_fine_tiles_y, max_workers):\n        # Filter the entire dataset for the current coarse tile\n        coarse_tile = trx.filter(\n            (pl.col(\"transformed_x\") &gt;= coarse_tile_x_min) &amp; (pl.col(\"transformed_x\") &lt; coarse_tile_x_max) &amp;\n            (pl.col(\"transformed_y\") &gt;= coarse_tile_y_min) &amp; (pl.col(\"transformed_y\") &lt; coarse_tile_y_max)\n        )\n\n        if not coarse_tile.is_empty():\n            # Now process fine tiles using global fine tile indices\n            process_fine_tiles(coarse_tile, i, j, coarse_tile_x_min, coarse_tile_x_max, coarse_tile_y_min, coarse_tile_y_max, tile_size, path_trx_tiles, x_min, y_min, n_fine_tiles_x, n_fine_tiles_y, max_workers)   \n\n\n    def process_fine_tiles(coarse_tile, coarse_i, coarse_j, coarse_tile_x_min, coarse_tile_x_max, coarse_tile_y_min, coarse_tile_y_max, tile_size, path_trx_tiles, x_min, y_min, n_fine_tiles_x, n_fine_tiles_y, max_workers=8):\n\n        # Use ThreadPoolExecutor for parallel processing of fine-grain tiles within the coarse tile\n        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n            futures = []\n\n            # Iterate over fine-grain tiles within the global bounds\n            for fine_i in range(n_fine_tiles_x):\n                fine_tile_x_min = x_min + fine_i * tile_size\n                fine_tile_x_max = fine_tile_x_min + tile_size\n\n                # Process only if the fine tile falls within the current coarse tile's bounds\n                if not (fine_tile_x_min &gt;= coarse_tile_x_min and fine_tile_x_max &lt;= coarse_tile_x_max):\n                    continue\n\n                for fine_j in range(n_fine_tiles_y):\n                    fine_tile_y_min = y_min + fine_j * tile_size\n                    fine_tile_y_max = fine_tile_y_min + tile_size\n\n                    # Process only if the fine tile falls within the current coarse tile's bounds\n                    if not (fine_tile_y_min &gt;= coarse_tile_y_min and fine_tile_y_max &lt;= coarse_tile_y_max):\n                        continue\n\n                    # Submit the task for each fine tile to process in parallel\n                    futures.append(executor.submit(\n                        filter_and_save_fine_tile, coarse_tile, coarse_i, coarse_j, fine_i, fine_j, \n                        fine_tile_x_min, fine_tile_x_max, fine_tile_y_min, fine_tile_y_max, path_trx_tiles\n                    ))\n\n            # Wait for all futures to complete\n            for future in concurrent.futures.as_completed(futures):\n                future.result()  # Raise exceptions if any occurred during execution\n\n\n    def filter_and_save_fine_tile(coarse_tile, coarse_i, coarse_j, fine_i, fine_j, fine_tile_x_min, fine_tile_x_max, fine_tile_y_min, fine_tile_y_max, path_trx_tiles):\n\n        # Filter the coarse tile for the current fine tile's boundaries\n        fine_tile_trx = coarse_tile.filter(\n            (pl.col(\"transformed_x\") &gt;= fine_tile_x_min) &amp; (pl.col(\"transformed_x\") &lt; fine_tile_x_max) &amp;\n            (pl.col(\"transformed_y\") &gt;= fine_tile_y_min) &amp; (pl.col(\"transformed_y\") &lt; fine_tile_y_max)\n        )\n\n        if not fine_tile_trx.is_empty():\n            # Add geometry column as a list of [x, y] pairs\n            fine_tile_trx = fine_tile_trx.with_columns(\n                pl.concat_list([pl.col(\"transformed_x\"), pl.col(\"transformed_y\")]).alias(\"geometry\")\n            ).drop(['transformed_x', 'transformed_y'])\n\n            # Define the filename based on fine tile coordinates\n            filename = f\"{path_trx_tiles}/transcripts_tile_{fine_i}_{fine_j}.parquet\"\n\n            # Save the filtered DataFrame to a Parquet file\n            fine_tile_trx.to_pandas().to_parquet(filename)\n\n\n    # Load transformation matrix\n    transformation_matrix = np.loadtxt(path_transformation_matrix)\n\n    # Load the transcript data based on the technology using Polars\n    if technology == \"MERSCOPE\":\n        trx_ini = pl.read_csv(path_trx, columns=[\"gene\", \"global_x\", \"global_y\"])\n        trx_ini = trx_ini.with_columns([\n            pl.col(\"global_x\").alias(\"x\"),\n            pl.col(\"global_y\").alias(\"y\"),\n            pl.col(\"gene\").alias(\"name\")\n        ]).select([\"name\", \"x\", \"y\"])\n\n    elif technology == \"Xenium\":\n        trx_ini = pl.read_parquet(path_trx).select([\n            pl.col(\"feature_name\").alias(\"name\"),\n            pl.col(\"x_location\").alias(\"x\"),\n            pl.col(\"y_location\").alias(\"y\")\n        ])\n\n    # Process the data in chunks and apply transformations\n    all_chunks = []\n\n    for start_row in tqdm(range(0, trx_ini.height, chunk_size), desc=\"Processing chunks\"):\n        chunk = trx_ini.slice(start_row, chunk_size)\n\n        # Apply transformation matrix to the coordinates\n        points = np.hstack([chunk.select([\"x\", \"y\"]).to_numpy(), np.ones((chunk.height, 1))])\n        transformed_points = np.dot(points, transformation_matrix.T)[:, :2]\n\n        # Create new transformed columns and drop original x, y columns\n        transformed_chunk = chunk.with_columns([\n            (pl.Series(transformed_points[:, 0]) * image_scale).round(2).alias(\"transformed_x\"),\n            (pl.Series(transformed_points[:, 1]) * image_scale).round(2).alias(\"transformed_y\")\n        ]).drop([\"x\", \"y\"])\n        all_chunks.append(transformed_chunk)\n\n    # Concatenate all chunks after processing\n    trx = pl.concat(all_chunks)\n\n    # Ensure the output directory exists\n    if not os.path.exists(path_trx_tiles):\n        os.makedirs(path_trx_tiles)\n\n    # Get min and max x, y values\n    x_min, x_max = trx.select([\n        pl.col(\"transformed_x\").min().alias(\"x_min\"),\n        pl.col(\"transformed_x\").max().alias(\"x_max\")\n    ]).row(0)\n\n    y_min, y_max = trx.select([\n        pl.col(\"transformed_y\").min().alias(\"y_min\"),\n        pl.col(\"transformed_y\").max().alias(\"y_max\")\n    ]).row(0)\n\n    # Calculate the number of fine-grain tiles globally\n    n_fine_tiles_x = int(np.ceil((x_max - x_min) / tile_size))\n    n_fine_tiles_y = int(np.ceil((y_max - y_min) / tile_size))\n\n    # Calculate the number of coarse-grain tiles\n    n_coarse_tiles_x = int(np.ceil((x_max - x_min) / (coarse_tile_factor * tile_size)))\n    n_coarse_tiles_y = int(np.ceil((y_max - y_min) / (coarse_tile_factor * tile_size)))\n\n    # Use ThreadPoolExecutor for parallel processing of coarse-grain tiles\n    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n        futures = []\n        for i in range(n_coarse_tiles_x):\n            coarse_tile_x_min = x_min + i * (coarse_tile_factor * tile_size)\n            coarse_tile_x_max = coarse_tile_x_min + (coarse_tile_factor * tile_size)\n\n            for j in range(n_coarse_tiles_y):\n                coarse_tile_y_min = y_min + j * (coarse_tile_factor * tile_size)\n                coarse_tile_y_max = coarse_tile_y_min + (coarse_tile_factor * tile_size)\n\n                # Submit each coarse tile for parallel processing\n                futures.append(executor.submit(\n                    process_coarse_tile, trx, i, j, coarse_tile_x_min, coarse_tile_x_max, coarse_tile_y_min, coarse_tile_y_max, tile_size, path_trx_tiles, x_min, y_min, n_fine_tiles_x, n_fine_tiles_y, max_workers\n                ))\n\n        # Wait for all coarse tiles to complete\n        for future in tqdm(concurrent.futures.as_completed(futures), desc=\"Processing coarse tiles\", unit=\"tile\"):\n            future.result()  # Raise exceptions if any occurred during execution\n\n    # Return the tile bounds\n    tile_bounds = {\n        \"x_min\": x_min,\n        \"x_max\": x_max,\n        \"y_min\": y_min,\n        \"y_max\": y_max,\n    }\n\n    return tile_bounds\n</code></pre>"},{"location":"python/pre/api/#celldega.pre.read_cbg_mtx","title":"<code>read_cbg_mtx(base_path)</code>","text":"<p>Read the cell-by-gene matrix from the mtx files.</p>"},{"location":"python/pre/api/#celldega.pre.read_cbg_mtx--parameters","title":"Parameters","text":"<p>base_path : str     The base path to the directory containing the mtx files.</p>"},{"location":"python/pre/api/#celldega.pre.read_cbg_mtx--returns","title":"Returns","text":"<p>cbg : pandas.DataFrame     A sparse DataFrame with genes as columns and barcodes as rows.</p> Source code in <code>src/celldega/pre/landscape.py</code> <pre><code>def read_cbg_mtx(base_path):\n    \"\"\"\n    Read the cell-by-gene matrix from the mtx files.\n\n    Parameters\n    ----------\n    base_path : str\n        The base path to the directory containing the mtx files.\n\n    Returns\n    -------\n    cbg : pandas.DataFrame\n        A sparse DataFrame with genes as columns and barcodes as rows.\n    \"\"\"\n    print(\"Reading mtx file from \", base_path)\n\n    # File paths\n    barcodes_path = os.path.join(base_path, \"barcodes.tsv.gz\")\n    features_path = os.path.join(base_path, \"features.tsv.gz\")\n    matrix_path = os.path.join(base_path, \"matrix.mtx.gz\")\n\n    # Read barcodes and features\n    barcodes = pd.read_csv(barcodes_path, header=None, compression=\"gzip\")\n    features = pd.read_csv(features_path, header=None, compression=\"gzip\", sep=\"\\t\")\n\n    # Read the gene expression matrix and transpose it\n    # Transpose and convert to CSC format for fast column slicing\n    matrix = mmread(matrix_path).transpose().tocsc()\n\n    # Create a sparse DataFrame with genes as columns and barcodes as rows\n    cbg = pd.DataFrame.sparse.from_spmatrix(\n        matrix, index=barcodes[0], columns=features[1]\n    )\n    cbg = cbg.rename_axis('__index_level_0__', axis='columns')\n\n    return cbg\n</code></pre>"},{"location":"python/pre/api/#celldega.pre.reduce_image_size","title":"<code>reduce_image_size(image_path, scale_image=0.5, path_landscape_files='')</code>","text":""},{"location":"python/pre/api/#celldega.pre.reduce_image_size--parameters","title":"Parameters","text":"<p>image_path : str     Path to the image file scale_image : float (default=0.5)     Scale factor for the image resize</p>"},{"location":"python/pre/api/#celldega.pre.reduce_image_size--returns","title":"Returns","text":"<p>new_image_path : str     Path to the resized image file</p> Source code in <code>src/celldega/pre/__init__.py</code> <pre><code>def reduce_image_size(image_path, scale_image=0.5, path_landscape_files=\"\"):\n    \"\"\"\n\n    Parameters\n    ----------\n    image_path : str\n        Path to the image file\n    scale_image : float (default=0.5)\n        Scale factor for the image resize\n\n    Returns\n    -------\n    new_image_path : str\n        Path to the resized image file\n    \"\"\"\n\n    image = pyvips.Image.new_from_file(image_path, access=\"sequential\")\n\n    resized_image = image.resize(scale_image)\n\n    new_image_name = image_path.split(\"/\")[-1].replace(\".tif\", \"_downsize.tif\")\n    new_image_path = f\"{path_landscape_files}/{new_image_name}\"\n    resized_image.write_to_file(new_image_path)\n\n    return new_image_path\n</code></pre>"},{"location":"python/pre/api/#celldega.pre.save_cbg_gene_parquets","title":"<code>save_cbg_gene_parquets(base_path, cbg, verbose=False)</code>","text":"<p>Save the cell-by-gene matrix as gene-specific Parquet files.</p>"},{"location":"python/pre/api/#celldega.pre.save_cbg_gene_parquets--parameters","title":"Parameters","text":"<p>base_path : str     The base path to the parent directory containing the landscape_files directory. cbg : pandas.DataFrame     A sparse DataFrame with genes as columns and barcodes as rows. verbose : bool, optional     Whether to print progress information, by default False.</p>"},{"location":"python/pre/api/#celldega.pre.save_cbg_gene_parquets--returns","title":"Returns","text":"<p>None</p> Source code in <code>src/celldega/pre/landscape.py</code> <pre><code>def save_cbg_gene_parquets(base_path, cbg, verbose=False):\n    \"\"\"\n    Save the cell-by-gene matrix as gene-specific Parquet files.\n\n    Parameters\n    ----------\n    base_path : str\n        The base path to the parent directory containing the landscape_files directory.\n    cbg : pandas.DataFrame\n        A sparse DataFrame with genes as columns and barcodes as rows.\n    verbose : bool, optional\n        Whether to print progress information, by default False.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    output_dir = os.path.join(base_path, \"cbg\")\n    os.makedirs(output_dir, exist_ok=True)\n\n    for index, gene in enumerate(cbg.columns):\n        if verbose and index % 100 == 0:\n            print(f\"Processing gene {index}: {gene}\")\n\n        # Extract the column as a DataFrame as a copy\n        col_df = cbg[[gene]].copy()\n\n        # Convert to dense and integer type\n        col_df = col_df.sparse.to_dense().astype(int)\n\n        # Create a DataFrame necessary to prevent error in to_parquet\n        inst_df = pd.DataFrame(\n            col_df.values, columns=[gene], index=col_df.index.tolist()\n        )\n\n        # Replace 0 with NA and drop rows where all values are NA\n        inst_df.replace(0, pd.NA, inplace=True)\n        inst_df.dropna(how=\"all\", inplace=True)\n\n        # Save to Parquet if DataFrame is not empty\n        if not inst_df.empty:\n            output_path = os.path.join(output_dir, f\"{gene}.parquet\")\n            inst_df.to_parquet(output_path)\n</code></pre>"},{"location":"python/pre/api/#celldega.pre.save_landscape_parameters","title":"<code>save_landscape_parameters(technology, path_landscape_files, image_name='dapi_files', tile_size=1000, image_info={}, image_format='.webp')</code>","text":"<p>Save the landscape parameters to a JSON file.</p> Source code in <code>src/celldega/pre/__init__.py</code> <pre><code>def save_landscape_parameters(\n    technology, path_landscape_files, image_name=\"dapi_files\", tile_size=1000, image_info={}, image_format='.webp'\n):\n    \"\"\"\n    Save the landscape parameters to a JSON file.\n    \"\"\"\n\n    path_image_pyramid = f\"{path_landscape_files}/pyramid_images/{image_name}\"\n\n    print(path_image_pyramid)\n\n    max_pyramid_zoom = get_max_zoom_level(path_image_pyramid)\n\n    landscape_parameters = {\n        \"technology\": technology,\n        \"max_pyramid_zoom\": max_pyramid_zoom,\n        \"tile_size\": tile_size,\n        \"image_info\": image_info,\n        \"image_format\": image_format\n    }\n\n    path_landscape_parameters = f\"{path_landscape_files}/landscape_parameters.json\"\n\n    with open(path_landscape_parameters, \"w\") as file:\n        json.dump(landscape_parameters, file, indent=4)\n</code></pre>"},{"location":"python/viz/api/","title":"Viz Module API Reference","text":""},{"location":"python/viz/api/#widget-classes","title":"Widget Classes","text":"<p>Module for visualization</p>"},{"location":"python/viz/api/#celldega.viz.Landscape","title":"<code>Landscape</code>","text":"<p>               Bases: <code>AnyWidget</code></p> <p>A widget for interactive visualization of spatial omics data. This widget currently supports iST (Xenium and MERSCOPE) and sST (Visium HD data)</p> <p>Parameters:</p> Name Type Description Default <code>ini_x</code> <code>float</code> <p>The initial x-coordinate of the view.</p> required <code>ini_y</code> <code>float</code> <p>The initial y-coordinate of the view.</p> required <code>ini_zoom</code> <code>float</code> <p>The initial zoom level of the view.</p> required <code>token</code> <code>str</code> <p>The token traitlet.</p> required <code>base_url</code> <code>str</code> <p>The base URL for the widget.</p> required <code>dataset_name</code> <code>str</code> <p>The name of the dataset to visualize. This will show up in the user interface bar.</p> required <p>Attributes:</p> Name Type Description <code>component</code> <code>str</code> <p>The name of the component.</p> <code>technology</code> <code>str</code> <p>The technology used.</p> <code>base_url</code> <code>str</code> <p>The base URL for the widget.</p> <code>token</code> <code>str</code> <p>The token traitlet.</p> <code>ini_x</code> <code>float</code> <p>The initial x-coordinate of the view.</p> <code>ini_y</code> <code>float</code> <p>The initial y-coordinate of the view.</p> <code>ini_z</code> <code>float</code> <p>The initial z-coordinate of the view.</p> <code>ini_zoom</code> <code>float</code> <p>The initial zoom level of the view.</p> <code>dataset_name</code> <code>str</code> <p>The name of the dataset to visualize.</p> <code>update_trigger</code> <code>dict</code> <p>The dictionary to trigger updates.</p> <code>cell_clusters</code> <code>dict</code> <p>The dictionary containing cell cluster information.</p> <p>Returns:</p> Name Type Description <code>Landscape</code> <p>A widget for visualizing a 'landscape' view of spatial omics data.</p> Source code in <code>src/celldega/viz/widget.py</code> <pre><code>class Landscape(anywidget.AnyWidget):\n    \"\"\"\n    A widget for interactive visualization of spatial omics data. This widget\n    currently supports iST (Xenium and MERSCOPE) and sST (Visium HD data)\n\n    Args:\n        ini_x (float): The initial x-coordinate of the view.\n        ini_y (float): The initial y-coordinate of the view.\n        ini_zoom (float): The initial zoom level of the view.\n        token (str): The token traitlet.\n        base_url (str): The base URL for the widget.\n        dataset_name (str, optional): The name of the dataset to visualize. This will show up in the user interface bar.\n\n    Attributes:\n        component (str): The name of the component.\n        technology (str): The technology used.\n        base_url (str): The base URL for the widget.\n        token (str): The token traitlet.\n        ini_x (float): The initial x-coordinate of the view.\n        ini_y (float): The initial y-coordinate of the view.\n        ini_z (float): The initial z-coordinate of the view.\n        ini_zoom (float): The initial zoom level of the view.\n        dataset_name (str): The name of the dataset to visualize.\n        update_trigger (dict): The dictionary to trigger updates.\n        cell_clusters (dict): The dictionary containing cell cluster information.\n\n    Returns:\n        Landscape: A widget for visualizing a 'landscape' view of spatial omics data.\n    \"\"\"\n    _esm = pathlib.Path(__file__).parent / \"../static\" / \"widget.js\"\n    _css = pathlib.Path(__file__).parent / \"../static\" / \"widget.css\"\n    component = traitlets.Unicode(\"Landscape\").tag(sync=True)\n\n    technology = traitlets.Unicode(\"sst\").tag(sync=True)\n    base_url = traitlets.Unicode(\"\").tag(sync=True)\n    token = traitlets.Unicode(\"\").tag(sync=True)\n    ini_x = traitlets.Float().tag(sync=True)\n    ini_y = traitlets.Float().tag(sync=True)\n    ini_z = traitlets.Float().tag(sync=True)\n    ini_zoom = traitlets.Float(0).tag(sync=True)\n    square_tile_size = traitlets.Float(1.4).tag(sync=True)\n    dataset_name = traitlets.Unicode(\"\").tag(sync=True)\n    region = traitlets.Dict({}).tag(sync=True)\n    nbhd = traitlets.Dict({}).tag(sync=True)\n\n    meta_cell = traitlets.Dict({}).tag(sync=True)\n    meta_cluster = traitlets.Dict({}).tag(sync=True)\n    umap = traitlets.Dict({}).tag(sync=True)\n    landscape_state = traitlets.Unicode(\"spatial\").tag(sync=True)\n\n    update_trigger = traitlets.Dict().tag(sync=True)\n    cell_clusters = traitlets.Dict().tag(sync=True)\n\n    width = traitlets.Int(0).tag(sync=True)\n    height = traitlets.Int(800).tag(sync=True)\n\n    def trigger_update(self, new_value):\n        # This method updates the update_trigger traitlet with a new value\n        # You can pass any information necessary for the update, or just a timestamp\n        self.update_trigger = new_value\n\n    def update_cell_clusters(self, new_clusters):\n        # Convert the new_clusters to a JSON serializable format if necessary\n        self.cell_clusters = new_clusters\n</code></pre>"},{"location":"python/viz/api/#celldega.viz.Matrix","title":"<code>Matrix</code>","text":"<p>               Bases: <code>AnyWidget</code></p> <p>A widget for interactive visualization of a hierarchically clustered matrix.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int</code> <p>The value traitlet.</p> required <code>component</code> <code>str</code> <p>The component traitlet.</p> required <code>network</code> <code>dict</code> <p>The network traitlet.</p> required <code>click_info</code> <code>dict</code> <p>The click_info traitlet.</p> required <p>Attributes:</p> Name Type Description <code>component</code> <code>str</code> <p>The name of the component.</p> <code>network</code> <code>dict</code> <p>The network dictionary.</p> <code>click_info</code> <code>dict</code> <p>The click_info dictionary.</p> <p>Returns:</p> Name Type Description <code>Matrix</code> <p>A widget for visualizing a hierarchically clustered matrix.</p> Source code in <code>src/celldega/viz/widget.py</code> <pre><code>class Matrix(anywidget.AnyWidget):\n    \"\"\"\n    A widget for interactive visualization of a hierarchically clustered matrix.\n\n    Args:\n        value (int): The value traitlet.\n        component (str): The component traitlet.\n        network (dict): The network traitlet.\n        click_info (dict): The click_info traitlet.\n\n    Attributes:\n        component (str): The name of the component.\n        network (dict): The network dictionary.\n        click_info (dict): The click_info dictionary.\n\n    Returns:\n        Matrix: A widget for visualizing a hierarchically clustered matrix.\n    \"\"\"\n\n    _esm = pathlib.Path(__file__).parent / \"../static\" / \"widget.js\"\n    _css = pathlib.Path(__file__).parent / \"../static\" / \"widget.css\"\n    value = traitlets.Int(0).tag(sync=True)\n    component = traitlets.Unicode(\"Matrix\").tag(sync=True)\n\n    network = traitlets.Dict({}).tag(sync=True)\n\n    width = traitlets.Int(600).tag(sync=True)\n    height = traitlets.Int(600).tag(sync=True)\n    click_info = traitlets.Dict({}).tag(sync=True)\n</code></pre>"},{"location":"python/viz/api/#celldega.viz.landscape_matrix","title":"<code>landscape_matrix(landscape, mat, width='600px', height='700px')</code>","text":"<p>Display a <code>Landscape</code> widget and a <code>Matrix</code> widget side by side.</p> <p>Parameters:</p> Name Type Description Default <code>landscape</code> <code>Landscape</code> <p>A <code>Landscape</code> widget.</p> required <code>mat</code> <code>Matrix</code> <p>A <code>Matrix</code> widget.</p> required <code>width</code> <code>str</code> <p>The width of the widgets.</p> <code>'600px'</code> <code>height</code> <code>str</code> <p>The height of the widgets.</p> <code>'700px'</code> <p>Returns:</p> Type Description <p>Visualization display</p> <p>Example: See example Landscape-Matrix_Xenium notebook</p> Source code in <code>src/celldega/viz/__init__.py</code> <pre><code>def landscape_matrix(landscape, mat, width='600px', height='700px'):\n    \"\"\"\n    Display a `Landscape` widget and a `Matrix` widget side by side.\n\n    Args:\n        landscape (Landscape): A `Landscape` widget.\n        mat (Matrix): A `Matrix` widget.\n        width (str): The width of the widgets.\n        height (str): The height of the widgets.\n\n    Returns:\n        Visualization display\n\n    Example:\n    See example [Landscape-Matrix_Xenium](../../../examples/brief_notebooks/Landscape-Matrix_Xenium) notebook\n    \"\"\"\n\n    # Use `jslink` to directly link `click_info` from `mat` to `trigger_value` in `landscape_ist`\n    jslink((mat, 'click_info'), (landscape, 'update_trigger'))\n\n    # Set layouts for the widgets\n    mat.layout = Layout(width=width)  # Adjust as needed\n    landscape.layout = Layout(width=width, height=height)  # Adjust as needed\n\n    # Display widgets side by side\n    widgets_side_by_side = HBox([landscape, mat])\n\n    display(widgets_side_by_side)\n</code></pre>"},{"location":"technologies/","title":"Technologies","text":"<p>Celldega utilizes a suite of complementary technologies to develop an efficient web-based spatial-omics analysis and visualization toolkit.</p>"},{"location":"technologies/#visualization-technologies","title":"Visualization Technologies","text":"<p>Spatial transcriptomics (ST) datasets can be very large and difficult for researchers to analyze and visualize collaboratively. Additionally, visualization that is linked to analysis is key to extracting biological insights. To address these issues, we built the Celldega <code>viz</code> module to help researchers interactively visualize large ST datasets within notebook-based workflows on the cloud (e.g., Terra.bio).</p> <p>The Celldega Landscape visualization method (see Gallery) utilizes novel vector tiling approaches to enable interactive visualization of large ST datasets in a notebook environment or as a stand-alone webpage. This approach allows Celldega to visualize larger datasets than currently available open-source tools (e.g., datasets with hundreds of millions of transcripts). We also utilize modern web image data formats (WebP) to reduce the data storage burden for interactive visualization. The resulting LandscapeFiles data format serves as a compact and highly performant visualization-specific data format.</p>"},{"location":"technologies/#terrabio","title":"Terra.bio","text":"<p>Terra.bio is a cloud-based compute and data storage platform that is being developed by the Broad Institute of MIT and Harvard. We are utilizing Terra.bio to help Spatial Technology Platform clients access, analyze, and visualize their ST data.</p>"},{"location":"technologies/#jupyter-widget","title":"Jupyter Widget","text":"<p>We utilize the Jupyter Widget ecosystem to build interactive spatial and data visualizations that enable users to perform two way communication between JavaScript (front-end) and Python (back-end). We are utilizing the AnyWidget implementation to build our custom widgets.</p>"},{"location":"technologies/#deckgl","title":"Deck.gl","text":"<p>Celldega uses the GPU-powered data visualization library deck.gl to create high-performance spatial- and data-visualizations.</p>"},{"location":"technologies/#apache-parquet","title":"Apache Parquet","text":"<p>Celldega uses the Apache Parquet file format for storing vectorized spatial data and metadata. This file format in combination with the JavaScript library ParquetWASM and Apache Arrow in memory representation is used to build Celldega's high-performance vector tiling spatial visualization functionality (see GeoArrow and GeoParquet in deck.gl).</p>"},{"location":"technologies/#parquetwasm-and-apache-arrow","title":"ParquetWASM and Apache Arrow","text":"<p>ParquetWASM is a JavaScript library for reading Parquet files into Apache Arrow memory and utilizes Web Assembly (WASM) to run Rust in a browser environment. The Apache Arrow in-memory format is a columnar in-memory format that is used for storing data from Apache Parquet files and efficiently passing to deck.gl. For more information please see GeoArrow and GeoParquet in deck.gl.</p>"},{"location":"technologies/#webp","title":"WebP","text":"<p>A modern image format developed by Google, offering efficient lossless compression and designed specifically for the web.</p>"},{"location":"technologies/#deep-zoom","title":"Deep Zoom","text":"<p>We utilize the Deep Zoom image schema, developed by Microsoft, to enable efficient visualization of large multi-channel microscopy images. Deep Zoom tile images are stored using the WebP image format.</p>"},{"location":"technologies/#clustergrammer-visualization-approaches","title":"Clustergrammer Visualization Approaches","text":"<p>The Celldega Matrix visualization builds upon the visualization approaches developed in the Clustergrammer project. This enables users to interactively explore high-dimensional datasets (e.g., single-cell gene expression data) alongside spatial data (e.g., cell distributions within a tissue).</p>"},{"location":"technologies/#data-analysis-technologies","title":"Data Analysis Technologies","text":""},{"location":"technologies/#scanpy-and-squidpy","title":"Scanpy and Squidpy","text":"<p>Celldega is built to interface with the AnnData and SpatialData objects, which enables users to easily import analysis results from Scanpy and Squidpy, respectively, into Celldega for downstream analysis and/or visuaization.</p>"},{"location":"technologies/#geopandas","title":"GeoPandas","text":"<p>Celldega uses GeoPandas for efficient spatial operations and storing collections of spatial objects (e.g., neighborhood multi-polygons) as GeoDataFrames.</p>"},{"location":"technologies/#libpysal-python-spatial-analysis-library-core","title":"LibPySal: Python Spatial Analysis Library Core","text":"<p>Celldega uses the Python Spatial Analysis Library (libpysal) for spatial analysis - namely for calculating alpha shape cell type neighborhoods.</p>"},{"location":"technologies/#clustergrammer-data-analysis-approaches","title":"Clustergrammer Data Analysis Approaches","text":"<p>The Celldega Cluster module build upon the hierarchical clustering approaches developed in the Clustergrammer project. This enables users to perform hierarchical clustering on observations (e.g., single cells) and measurements (e.g., genes) and easily visualize these two orthogonal clustering results interactively using Celldega's Matrix visualization method.</p>"}]}